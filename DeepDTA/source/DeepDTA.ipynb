{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":216,"status":"ok","timestamp":1651590595873,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"},"user_tz":300},"id":"Xs22x0M_voz0","outputId":"908c62ce-f443-4bec-88aa-9385ad8ada0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'drive/MyDrive/DL4H_Spring2022/DeepDTA/source/'\n","/content/drive/MyDrive/DL4H_Spring2022/DeepDTA/source\n"]}],"source":["%cd drive/MyDrive/DL4H_Spring2022/DeepDTA/source/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":146,"status":"ok","timestamp":1651580136618,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"},"user_tz":300},"id":"1TzHAo4jy7aD","outputId":"93c979fa-df0d-4037-ea2b-ac9476417bd3"},"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow 1.x selected.\n"]}],"source":["%tensorflow_version 1.x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":633},"executionInfo":{"elapsed":11808,"status":"ok","timestamp":1651580125858,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"},"user_tz":300},"id":"gKx1882yl8tU","outputId":"79edfb68-c6e5-44e2-c7e3-020102e9efa1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting h5py==2.10.0\n","  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 32.1 MB/s \n","\u001b[?25hCollecting numpy>=1.7\n","  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n","\u001b[K     |████████████████████████████████| 15.7 MB 49.6 MB/s \n","\u001b[?25hCollecting six\n","  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Installing collected packages: six, numpy, h5py\n","  Attempting uninstall: six\n","    Found existing installation: six 1.15.0\n","    Uninstalling six-1.15.0:\n","      Successfully uninstalled six-1.15.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lucid 0.3.10 requires umap-learn, which is not installed.\n","tensorflow 1.15.2 requires gast==0.2.2, but you have gast 0.5.3 which is incompatible.\n","lucid 0.3.10 requires numpy<=1.19, but you have numpy 1.21.6 which is incompatible.\n","kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\n","google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed h5py-2.10.0 numpy-1.21.6 six-1.16.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy","six"]}}},"metadata":{}}],"source":["pip install 'h5py==2.10.0' --force-reinstall"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":214,"status":"ok","timestamp":1651580145906,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"},"user_tz":300},"id":"-jfEsExzv6We","outputId":"75c601c3-8d50-4c21-95ba-21fc1758b812"},"outputs":[{"output_type":"stream","name":"stdout","text":["total 24186\n","-rwx------ 1 root root     2797 Apr  9 19:05 arguments.py\n","-rwx------ 1 root root    10869 Apr  9 19:05 auc.jar\n","-rwx------ 1 root root 24452560 Apr 15 01:51 combined_davis.h5\n","drwx------ 4 root root     4096 Apr  9 19:08 data\n","-rwx------ 1 root root     5356 Apr  9 19:05 datahelper.py\n","-rwx------ 1 root root   245510 May  3 12:15 DeepDTA.ipynb\n","-rwx------ 1 root root     2099 Apr  9 19:05 emetrics.py\n","drwx------ 3 root root     4096 May  3 12:14 figures\n","-rwx------ 1 root root      513 May  3 11:49 go.sh\n","drwx------ 8 root root     4096 May  3 12:03 logs\n","drwx------ 3 root root     4096 May  3 12:04 pretrained\n","drwx------ 2 root root     4096 Apr  9 19:24 __pycache__\n","-rwx------ 1 root root    23370 May  3 12:01 run_experiments.py\n"]}],"source":["!ls -l"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":113,"status":"ok","timestamp":1651580141144,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"},"user_tz":300},"id":"EJkMGNQsT4CI","outputId":"39d592e9-0b1a-4c56-b373-ccc15e326383"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DL4H_Spring2022/DeepDTA\n"]}],"source":["%cd .."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sscXM6hww35Q"},"outputs":[],"source":["!chmod -R 777 source/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":124,"status":"ok","timestamp":1651580143229,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"},"user_tz":300},"id":"Mb-MNJ4gvAOn","outputId":"2be6ecc6-913c-4748-bb8b-7848b3c2f28e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DL4H_Spring2022/DeepDTA/source\n"]}],"source":["%cd source"]},{"cell_type":"markdown","source":["## Baseline"],"metadata":{"id":"B4a-z-bOFWD5"}},{"cell_type":"markdown","source":["### Davis"],"metadata":{"id":"_1SqPLZQFS14"}},{"cell_type":"code","source":["!./go.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"67JxL8gI5FUh","executionInfo":{"status":"ok","timestamp":1650460156686,"user_tz":300,"elapsed":205036,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"}},"outputId":"eefbc974-1a3e-4d9f-e1be-09dce93faa67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From run_experiments.py:16: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","Using TensorFlow backend.\n","WARNING:tensorflow:From run_experiments.py:19: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","2022-04-20 13:05:56.860130: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n","2022-04-20 13:05:56.860474: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558992a392c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2022-04-20 13:05:56.860511: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2022-04-20 13:05:56.865641: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2022-04-20 13:05:57.069579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-20 13:05:57.070546: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558992a39800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2022-04-20 13:05:57.070584: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n","2022-04-20 13:05:57.072286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-20 13:05:57.073140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2022-04-20 13:05:57.090733: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-04-20 13:05:57.279967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-04-20 13:05:57.339539: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2022-04-20 13:05:57.368482: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2022-04-20 13:05:57.597466: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2022-04-20 13:05:57.648690: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2022-04-20 13:05:58.058956: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-20 13:05:58.059155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-20 13:05:58.060030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-20 13:05:58.060767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2022-04-20 13:05:58.063746: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-04-20 13:05:58.067452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-20 13:05:58.067490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2022-04-20 13:05:58.067518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2022-04-20 13:05:58.068676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-20 13:05:58.069629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-20 13:05:58.070439: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-04-20 13:05:58.070500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","Read data/davis/ start\n","68\n","442\n","logs/1650459959.964129/\n","Reading data/davis/ start\n","val set 5010\n","train set 20036\n","val set 5009\n","train set 20037\n","val set 5009\n","train set 20037\n","val set 5009\n","train set 20037\n","val set 5009\n","train set 20037\n","[[0, 0, 0, 0, 0]]\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From run_experiments.py:435: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n","\n","WARNING:tensorflow:From run_experiments.py:440: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 85)           0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 1200)         0                                            \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1)            86          input_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1)            1201        input_2[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 2)            0           dense_1[0][0]                    \n","                                                                 dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 1024)         3072        concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 1024)         0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 1024)         1049600     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 1024)         0           dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 512)          524800      dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 1)            513         dense_5[0][0]                    \n","==================================================================================================\n","Total params: 1,579,272\n","Trainable params: 1,579,272\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 20036 samples, validate on 5010 samples\n","Epoch 1/100\n","2022-04-20 13:06:06.393852: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","20036/20036 [==============================] - 2s 101us/step - loss: 4.4657 - cindex_score: 0.5590 - val_loss: 1.6915 - val_cindex_score: 0.5760\n","Epoch 2/100\n","20036/20036 [==============================] - 1s 48us/step - loss: 1.2869 - cindex_score: 0.5662 - val_loss: 1.4715 - val_cindex_score: 0.5812\n","Epoch 3/100\n","20036/20036 [==============================] - 1s 48us/step - loss: 1.0851 - cindex_score: 0.5778 - val_loss: 1.3041 - val_cindex_score: 0.5890\n","Epoch 4/100\n","20036/20036 [==============================] - 1s 47us/step - loss: 1.0108 - cindex_score: 0.5835 - val_loss: 1.1093 - val_cindex_score: 0.6006\n","Epoch 5/100\n","20036/20036 [==============================] - 1s 47us/step - loss: 0.9332 - cindex_score: 0.5914 - val_loss: 1.2947 - val_cindex_score: 0.6056\n","Epoch 6/100\n","20036/20036 [==============================] - 1s 47us/step - loss: 0.9104 - cindex_score: 0.5983 - val_loss: 1.1812 - val_cindex_score: 0.6076\n","Epoch 7/100\n","20036/20036 [==============================] - 1s 47us/step - loss: 0.8991 - cindex_score: 0.6036 - val_loss: 1.0744 - val_cindex_score: 0.6209\n","Epoch 8/100\n","20036/20036 [==============================] - 1s 45us/step - loss: 0.8466 - cindex_score: 0.6090 - val_loss: 1.1541 - val_cindex_score: 0.6262\n","Epoch 9/100\n","20036/20036 [==============================] - 1s 45us/step - loss: 0.8528 - cindex_score: 0.6168 - val_loss: 1.1050 - val_cindex_score: 0.6312\n","Epoch 10/100\n","20036/20036 [==============================] - 1s 44us/step - loss: 0.8220 - cindex_score: 0.6181 - val_loss: 1.0792 - val_cindex_score: 0.6398\n","Epoch 11/100\n","20036/20036 [==============================] - 1s 44us/step - loss: 0.8089 - cindex_score: 0.6285 - val_loss: 1.0634 - val_cindex_score: 0.6489\n","Epoch 12/100\n","20036/20036 [==============================] - 1s 44us/step - loss: 0.7981 - cindex_score: 0.6366 - val_loss: 0.9728 - val_cindex_score: 0.6547\n","Epoch 13/100\n","20036/20036 [==============================] - 1s 44us/step - loss: 0.7807 - cindex_score: 0.6452 - val_loss: 0.8176 - val_cindex_score: 0.6622\n","Epoch 14/100\n","20036/20036 [==============================] - 1s 43us/step - loss: 0.7653 - cindex_score: 0.6538 - val_loss: 0.8493 - val_cindex_score: 0.6684\n","Epoch 15/100\n","20036/20036 [==============================] - 1s 44us/step - loss: 0.7578 - cindex_score: 0.6589 - val_loss: 0.8900 - val_cindex_score: 0.6717\n","Epoch 16/100\n","20036/20036 [==============================] - 1s 44us/step - loss: 0.7383 - cindex_score: 0.6695 - val_loss: 0.8505 - val_cindex_score: 0.6785\n","Epoch 17/100\n","20036/20036 [==============================] - 1s 43us/step - loss: 0.7278 - cindex_score: 0.6739 - val_loss: 0.7832 - val_cindex_score: 0.6851\n","Epoch 18/100\n","20036/20036 [==============================] - 1s 45us/step - loss: 0.7201 - cindex_score: 0.6788 - val_loss: 0.7568 - val_cindex_score: 0.6926\n","Epoch 19/100\n","20036/20036 [==============================] - 1s 45us/step - loss: 0.7018 - cindex_score: 0.6857 - val_loss: 0.7273 - val_cindex_score: 0.7021\n","Epoch 20/100\n","20036/20036 [==============================] - 1s 43us/step - loss: 0.6940 - cindex_score: 0.6911 - val_loss: 0.6941 - val_cindex_score: 0.7049\n","Epoch 21/100\n","20036/20036 [==============================] - 1s 42us/step - loss: 0.6761 - cindex_score: 0.6969 - val_loss: 0.8329 - val_cindex_score: 0.7113\n","Epoch 22/100\n","20036/20036 [==============================] - 1s 44us/step - loss: 0.6667 - cindex_score: 0.7003 - val_loss: 0.6681 - val_cindex_score: 0.7116\n","Epoch 23/100\n","20036/20036 [==============================] - 1s 43us/step - loss: 0.6571 - cindex_score: 0.7050 - val_loss: 0.6527 - val_cindex_score: 0.7155\n","Epoch 24/100\n","20036/20036 [==============================] - 1s 43us/step - loss: 0.6557 - cindex_score: 0.7078 - val_loss: 0.6318 - val_cindex_score: 0.7229\n","Epoch 25/100\n","20036/20036 [==============================] - 1s 43us/step - loss: 0.6470 - cindex_score: 0.7140 - val_loss: 0.6175 - val_cindex_score: 0.7252\n","Epoch 26/100\n","20036/20036 [==============================] - 1s 43us/step - loss: 0.6415 - cindex_score: 0.7157 - val_loss: 0.6362 - val_cindex_score: 0.7264\n","Epoch 27/100\n","20036/20036 [==============================] - 1s 43us/step - loss: 0.6327 - cindex_score: 0.7209 - val_loss: 0.6551 - val_cindex_score: 0.7290\n","Epoch 28/100\n","20036/20036 [==============================] - 1s 43us/step - loss: 0.6289 - cindex_score: 0.7219 - val_loss: 0.6707 - val_cindex_score: 0.7291\n","Epoch 29/100\n","20036/20036 [==============================] - 1s 44us/step - loss: 0.6258 - cindex_score: 0.7243 - val_loss: 0.6398 - val_cindex_score: 0.7331\n","Epoch 30/100\n","20036/20036 [==============================] - 1s 43us/step - loss: 0.6231 - cindex_score: 0.7263 - val_loss: 0.6452 - val_cindex_score: 0.7331\n","Epoch 31/100\n","20036/20036 [==============================] - 1s 42us/step - loss: 0.6185 - cindex_score: 0.7280 - val_loss: 0.6361 - val_cindex_score: 0.7354\n","Epoch 32/100\n","20036/20036 [==============================] - 1s 42us/step - loss: 0.6161 - cindex_score: 0.7276 - val_loss: 0.6435 - val_cindex_score: 0.7384\n","Epoch 33/100\n","20036/20036 [==============================] - 1s 45us/step - loss: 0.6178 - cindex_score: 0.7277 - val_loss: 0.6276 - val_cindex_score: 0.7361\n","Epoch 34/100\n","20036/20036 [==============================] - 1s 43us/step - loss: 0.6171 - cindex_score: 0.7318 - val_loss: 0.6654 - val_cindex_score: 0.7362\n","Epoch 35/100\n","20036/20036 [==============================] - 1s 43us/step - loss: 0.6152 - cindex_score: 0.7310 - val_loss: 0.6619 - val_cindex_score: 0.7363\n","Epoch 36/100\n","20036/20036 [==============================] - 1s 42us/step - loss: 0.6100 - cindex_score: 0.7341 - val_loss: 0.6744 - val_cindex_score: 0.7374\n","Epoch 37/100\n","20036/20036 [==============================] - 1s 42us/step - loss: 0.6109 - cindex_score: 0.7323 - val_loss: 0.6817 - val_cindex_score: 0.7391\n","Epoch 38/100\n","20036/20036 [==============================] - 1s 41us/step - loss: 0.6096 - cindex_score: 0.7344 - val_loss: 0.6711 - val_cindex_score: 0.7401\n","Epoch 39/100\n","20036/20036 [==============================] - 1s 43us/step - loss: 0.6094 - cindex_score: 0.7331 - val_loss: 0.6678 - val_cindex_score: 0.7417\n","Epoch 40/100\n","20036/20036 [==============================] - 1s 42us/step - loss: 0.5998 - cindex_score: 0.7392 - val_loss: 0.6370 - val_cindex_score: 0.7435\n","Epoch 00040: early stopping\n","run_experiments.py:456: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:469: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:483: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","[[0, 0, 0, 0, 0]]\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            (None, 85)           0                                            \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            (None, 1200)         0                                            \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 1)            86          input_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 1)            1201        input_4[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 2)            0           dense_7[0][0]                    \n","                                                                 dense_8[0][0]                    \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 1024)         3072        concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 1024)         0           dense_9[0][0]                    \n","__________________________________________________________________________________________________\n","dense_10 (Dense)                (None, 1024)         1049600     dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 1024)         0           dense_10[0][0]                   \n","__________________________________________________________________________________________________\n","dense_11 (Dense)                (None, 512)          524800      dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","dense_12 (Dense)                (None, 1)            513         dense_11[0][0]                   \n","==================================================================================================\n","Total params: 1,579,272\n","Trainable params: 1,579,272\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Train on 20036 samples, validate on 5010 samples\n","Epoch 1/100\n","20036/20036 [==============================] - 1s 65us/step - loss: 3.5500 - cindex_score: 0.5445 - val_loss: 1.0807 - val_cindex_score: 0.5619\n","Epoch 2/100\n","20036/20036 [==============================] - 1s 49us/step - loss: 1.0287 - cindex_score: 0.5716 - val_loss: 1.2158 - val_cindex_score: 0.5878\n","Epoch 3/100\n","20036/20036 [==============================] - 1s 47us/step - loss: 0.9354 - cindex_score: 0.5871 - val_loss: 1.0285 - val_cindex_score: 0.5986\n","Epoch 4/100\n","20036/20036 [==============================] - 1s 48us/step - loss: 0.8817 - cindex_score: 0.5975 - val_loss: 1.1058 - val_cindex_score: 0.6101\n","Epoch 5/100\n","20036/20036 [==============================] - 1s 47us/step - loss: 0.8525 - cindex_score: 0.5999 - val_loss: 1.0721 - val_cindex_score: 0.6166\n","Epoch 6/100\n","20036/20036 [==============================] - 1s 47us/step - loss: 0.8387 - cindex_score: 0.6101 - val_loss: 1.1572 - val_cindex_score: 0.6234\n","Epoch 7/100\n","20036/20036 [==============================] - 1s 47us/step - loss: 0.8254 - cindex_score: 0.6143 - val_loss: 1.1510 - val_cindex_score: 0.6303\n","Epoch 8/100\n","20036/20036 [==============================] - 1s 48us/step - loss: 0.8096 - cindex_score: 0.6232 - val_loss: 1.0864 - val_cindex_score: 0.6374\n","Epoch 9/100\n","20036/20036 [==============================] - 1s 47us/step - loss: 0.8026 - cindex_score: 0.6238 - val_loss: 1.0700 - val_cindex_score: 0.6412\n","Epoch 10/100\n","20036/20036 [==============================] - 1s 47us/step - loss: 0.7877 - cindex_score: 0.6312 - val_loss: 1.0998 - val_cindex_score: 0.6473\n","Epoch 11/100\n","20036/20036 [==============================] - 1s 46us/step - loss: 0.7819 - cindex_score: 0.6356 - val_loss: 1.1417 - val_cindex_score: 0.6504\n","Epoch 12/100\n","20036/20036 [==============================] - 1s 50us/step - loss: 0.7770 - cindex_score: 0.6420 - val_loss: 1.0850 - val_cindex_score: 0.6547\n","Epoch 13/100\n","20036/20036 [==============================] - 1s 49us/step - loss: 0.7614 - cindex_score: 0.6463 - val_loss: 1.0219 - val_cindex_score: 0.6594\n","Epoch 14/100\n","20036/20036 [==============================] - 1s 48us/step - loss: 0.7636 - cindex_score: 0.6478 - val_loss: 0.9832 - val_cindex_score: 0.6621\n","Epoch 15/100\n","20036/20036 [==============================] - 1s 47us/step - loss: 0.7573 - cindex_score: 0.6498 - val_loss: 1.0376 - val_cindex_score: 0.6654\n","Epoch 16/100\n","20036/20036 [==============================] - 1s 48us/step - loss: 0.7529 - cindex_score: 0.6551 - val_loss: 1.0395 - val_cindex_score: 0.6683\n","Epoch 17/100\n","20036/20036 [==============================] - 1s 47us/step - loss: 0.7461 - cindex_score: 0.6591 - val_loss: 1.0680 - val_cindex_score: 0.6696\n","Epoch 18/100\n","20036/20036 [==============================] - 1s 58us/step - loss: 0.7428 - cindex_score: 0.6594 - val_loss: 1.1208 - val_cindex_score: 0.6704\n","Epoch 19/100\n","20036/20036 [==============================] - 1s 46us/step - loss: 0.7433 - cindex_score: 0.6612 - val_loss: 1.0585 - val_cindex_score: 0.6753\n","Epoch 20/100\n","20036/20036 [==============================] - 1s 46us/step - loss: 0.7389 - cindex_score: 0.6650 - val_loss: 0.9320 - val_cindex_score: 0.6770\n","Epoch 21/100\n","20036/20036 [==============================] - 1s 45us/step - loss: 0.7286 - cindex_score: 0.6671 - val_loss: 1.0460 - val_cindex_score: 0.6795\n","Epoch 22/100\n","20036/20036 [==============================] - 1s 47us/step - loss: 0.7354 - cindex_score: 0.6693 - val_loss: 0.9599 - val_cindex_score: 0.6809\n","Epoch 23/100\n","20036/20036 [==============================] - 1s 49us/step - loss: 0.7235 - cindex_score: 0.6716 - val_loss: 0.8902 - val_cindex_score: 0.6837\n","Epoch 24/100\n","20036/20036 [==============================] - 1s 49us/step - loss: 0.7247 - cindex_score: 0.6698 - val_loss: 0.9029 - val_cindex_score: 0.6855\n","Epoch 25/100\n","20036/20036 [==============================] - 1s 50us/step - loss: 0.7217 - cindex_score: 0.6740 - val_loss: 0.9412 - val_cindex_score: 0.6857\n","Epoch 26/100\n","20036/20036 [==============================] - 1s 50us/step - loss: 0.7179 - cindex_score: 0.6796 - val_loss: 1.0183 - val_cindex_score: 0.6884\n","Epoch 27/100\n","20036/20036 [==============================] - 1s 47us/step - loss: 0.7248 - cindex_score: 0.6801 - val_loss: 1.1235 - val_cindex_score: 0.6927\n","Epoch 28/100\n","20036/20036 [==============================] - 1s 48us/step - loss: 0.7117 - cindex_score: 0.6857 - val_loss: 0.8321 - val_cindex_score: 0.6971\n","Epoch 29/100\n","20036/20036 [==============================] - 1s 48us/step - loss: 0.7006 - cindex_score: 0.6942 - val_loss: 0.8687 - val_cindex_score: 0.6981\n","Epoch 30/100\n","20036/20036 [==============================] - 1s 49us/step - loss: 0.6924 - cindex_score: 0.6976 - val_loss: 0.8760 - val_cindex_score: 0.7000\n","Epoch 31/100\n","20036/20036 [==============================] - 1s 48us/step - loss: 0.6854 - cindex_score: 0.7057 - val_loss: 0.8350 - val_cindex_score: 0.7133\n","Epoch 32/100\n","20036/20036 [==============================] - 1s 46us/step - loss: 0.6637 - cindex_score: 0.7160 - val_loss: 0.9480 - val_cindex_score: 0.7215\n","Epoch 33/100\n","20036/20036 [==============================] - 1s 46us/step - loss: 0.6540 - cindex_score: 0.7228 - val_loss: 1.0155 - val_cindex_score: 0.7297\n","Epoch 34/100\n","20036/20036 [==============================] - 1s 47us/step - loss: 0.6454 - cindex_score: 0.7322 - val_loss: 0.8302 - val_cindex_score: 0.7395\n","Epoch 35/100\n","20036/20036 [==============================] - 1s 46us/step - loss: 0.6250 - cindex_score: 0.7337 - val_loss: 0.8897 - val_cindex_score: 0.7416\n","Epoch 36/100\n","20036/20036 [==============================] - 1s 47us/step - loss: 0.6245 - cindex_score: 0.7339 - val_loss: 0.8430 - val_cindex_score: 0.7403\n","Epoch 37/100\n","20036/20036 [==============================] - 1s 46us/step - loss: 0.6263 - cindex_score: 0.7366 - val_loss: 0.7701 - val_cindex_score: 0.7385\n","Epoch 38/100\n","20036/20036 [==============================] - 1s 46us/step - loss: 0.6213 - cindex_score: 0.7408 - val_loss: 0.7761 - val_cindex_score: 0.7482\n","Epoch 39/100\n","20036/20036 [==============================] - 1s 46us/step - loss: 0.6020 - cindex_score: 0.7432 - val_loss: 0.8221 - val_cindex_score: 0.7459\n","Epoch 40/100\n","20036/20036 [==============================] - 1s 63us/step - loss: 0.6092 - cindex_score: 0.7455 - val_loss: 0.7629 - val_cindex_score: 0.7455\n","Epoch 41/100\n","20036/20036 [==============================] - 1s 45us/step - loss: 0.6023 - cindex_score: 0.7477 - val_loss: 0.7988 - val_cindex_score: 0.7539\n","Epoch 42/100\n","20036/20036 [==============================] - 1s 45us/step - loss: 0.6071 - cindex_score: 0.7464 - val_loss: 0.8124 - val_cindex_score: 0.7424\n","Epoch 43/100\n","20036/20036 [==============================] - 1s 46us/step - loss: 0.6003 - cindex_score: 0.7511 - val_loss: 0.7236 - val_cindex_score: 0.7546\n","Epoch 44/100\n","20036/20036 [==============================] - 1s 46us/step - loss: 0.5973 - cindex_score: 0.7548 - val_loss: 0.7984 - val_cindex_score: 0.7600\n","Epoch 45/100\n","20036/20036 [==============================] - 1s 53us/step - loss: 0.5948 - cindex_score: 0.7556 - val_loss: 0.7930 - val_cindex_score: 0.7529\n","Epoch 46/100\n","20036/20036 [==============================] - 1s 48us/step - loss: 0.5927 - cindex_score: 0.7570 - val_loss: 0.7804 - val_cindex_score: 0.7611\n","Epoch 47/100\n","20036/20036 [==============================] - 1s 46us/step - loss: 0.5894 - cindex_score: 0.7605 - val_loss: 0.7877 - val_cindex_score: 0.7653\n","Epoch 48/100\n","20036/20036 [==============================] - 1s 45us/step - loss: 0.5914 - cindex_score: 0.7589 - val_loss: 0.7641 - val_cindex_score: 0.7676\n","Epoch 49/100\n","20036/20036 [==============================] - 1s 46us/step - loss: 0.5943 - cindex_score: 0.7598 - val_loss: 0.7271 - val_cindex_score: 0.7641\n","Epoch 50/100\n","20036/20036 [==============================] - 1s 44us/step - loss: 0.5855 - cindex_score: 0.7628 - val_loss: 0.8234 - val_cindex_score: 0.7673\n","Epoch 51/100\n","20036/20036 [==============================] - 1s 44us/step - loss: 0.5817 - cindex_score: 0.7656 - val_loss: 0.7166 - val_cindex_score: 0.7718\n","Epoch 52/100\n","20036/20036 [==============================] - 1s 44us/step - loss: 0.5815 - cindex_score: 0.7640 - val_loss: 0.7609 - val_cindex_score: 0.7666\n","Epoch 53/100\n","20036/20036 [==============================] - 1s 44us/step - loss: 0.5766 - cindex_score: 0.7694 - val_loss: 0.7141 - val_cindex_score: 0.7673\n","Epoch 54/100\n","20036/20036 [==============================] - 1s 45us/step - loss: 0.5729 - cindex_score: 0.7703 - val_loss: 0.7262 - val_cindex_score: 0.7704\n","Epoch 55/100\n","20036/20036 [==============================] - 1s 44us/step - loss: 0.5666 - cindex_score: 0.7716 - val_loss: 0.6817 - val_cindex_score: 0.7715\n","Epoch 56/100\n","20036/20036 [==============================] - 1s 44us/step - loss: 0.5745 - cindex_score: 0.7694 - val_loss: 0.6425 - val_cindex_score: 0.7685\n","Epoch 57/100\n","20036/20036 [==============================] - 1s 44us/step - loss: 0.5705 - cindex_score: 0.7737 - val_loss: 0.7184 - val_cindex_score: 0.7758\n","Epoch 58/100\n","20036/20036 [==============================] - 1s 43us/step - loss: 0.5654 - cindex_score: 0.7737 - val_loss: 0.6289 - val_cindex_score: 0.7638\n","Epoch 59/100\n","20036/20036 [==============================] - 1s 46us/step - loss: 0.5720 - cindex_score: 0.7734 - val_loss: 0.6669 - val_cindex_score: 0.7662\n","Epoch 60/100\n","20036/20036 [==============================] - 1s 43us/step - loss: 0.5712 - cindex_score: 0.7711 - val_loss: 0.6198 - val_cindex_score: 0.7752\n","Epoch 61/100\n","20036/20036 [==============================] - 1s 44us/step - loss: 0.5736 - cindex_score: 0.7714 - val_loss: 0.6217 - val_cindex_score: 0.7692\n","Epoch 62/100\n","20036/20036 [==============================] - 1s 44us/step - loss: 0.5707 - cindex_score: 0.7711 - val_loss: 0.6398 - val_cindex_score: 0.7676\n","Epoch 63/100\n","20036/20036 [==============================] - 1s 43us/step - loss: 0.5777 - cindex_score: 0.7696 - val_loss: 0.6058 - val_cindex_score: 0.7722\n","Epoch 64/100\n","20036/20036 [==============================] - 1s 45us/step - loss: 0.5733 - cindex_score: 0.7735 - val_loss: 0.6269 - val_cindex_score: 0.7680\n","Epoch 65/100\n","20036/20036 [==============================] - 1s 43us/step - loss: 0.5694 - cindex_score: 0.7746 - val_loss: 0.6487 - val_cindex_score: 0.7645\n","Epoch 66/100\n","20036/20036 [==============================] - 1s 44us/step - loss: 0.5719 - cindex_score: 0.7769 - val_loss: 0.6279 - val_cindex_score: 0.7657\n","Epoch 67/100\n","20036/20036 [==============================] - 1s 45us/step - loss: 0.5762 - cindex_score: 0.7706 - val_loss: 0.6270 - val_cindex_score: 0.7699\n","Epoch 68/100\n","20036/20036 [==============================] - 1s 45us/step - loss: 0.5734 - cindex_score: 0.7768 - val_loss: 0.6477 - val_cindex_score: 0.7610\n","Epoch 69/100\n","20036/20036 [==============================] - 1s 45us/step - loss: 0.5752 - cindex_score: 0.7740 - val_loss: 0.6458 - val_cindex_score: 0.7624\n","Epoch 70/100\n","20036/20036 [==============================] - 1s 44us/step - loss: 0.5696 - cindex_score: 0.7771 - val_loss: 0.6569 - val_cindex_score: 0.7637\n","Epoch 71/100\n","20036/20036 [==============================] - 1s 44us/step - loss: 0.5708 - cindex_score: 0.7757 - val_loss: 0.6420 - val_cindex_score: 0.7640\n","Epoch 72/100\n","20036/20036 [==============================] - 1s 45us/step - loss: 0.5682 - cindex_score: 0.7757 - val_loss: 0.6414 - val_cindex_score: 0.7638\n","Epoch 73/100\n","20036/20036 [==============================] - 1s 46us/step - loss: 0.5720 - cindex_score: 0.7737 - val_loss: 0.6353 - val_cindex_score: 0.7704\n","Epoch 74/100\n","20036/20036 [==============================] - 1s 68us/step - loss: 0.5653 - cindex_score: 0.7797 - val_loss: 0.6461 - val_cindex_score: 0.7649\n","Epoch 75/100\n","20036/20036 [==============================] - 1s 61us/step - loss: 0.5734 - cindex_score: 0.7759 - val_loss: 0.6534 - val_cindex_score: 0.7580\n","Epoch 76/100\n","20036/20036 [==============================] - 1s 54us/step - loss: 0.5818 - cindex_score: 0.7734 - val_loss: 0.6540 - val_cindex_score: 0.7692\n","Epoch 77/100\n","20036/20036 [==============================] - 1s 48us/step - loss: 0.5615 - cindex_score: 0.7797 - val_loss: 0.6737 - val_cindex_score: 0.7714\n","Epoch 78/100\n","20036/20036 [==============================] - 1s 45us/step - loss: 0.5611 - cindex_score: 0.7796 - val_loss: 0.6849 - val_cindex_score: 0.7713\n","Epoch 00078: early stopping\n","run_experiments.py:456: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:469: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:483: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n"]}]},{"cell_type":"markdown","source":["### KIBA"],"metadata":{"id":"9mPCu0-eFehx"}},{"cell_type":"code","source":["!./go.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gYaYe2jfvteN","executionInfo":{"status":"ok","timestamp":1651581454344,"user_tz":300,"elapsed":1297178,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"}},"outputId":"aa3dfead-7087-48f4-97c5-1fc5adad5082"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From run_experiments.py:16: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","Using TensorFlow backend.\n","WARNING:tensorflow:From run_experiments.py:19: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","2022-05-03 12:15:58.653984: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n","2022-05-03 12:15:58.654135: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x24412c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2022-05-03 12:15:58.654165: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2022-05-03 12:15:58.655846: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2022-05-03 12:15:58.881619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 12:15:58.882355: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2441640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2022-05-03 12:15:58.882391: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2022-05-03 12:15:58.882560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 12:15:58.883118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2022-05-03 12:15:58.883397: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-05-03 12:15:58.884950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-05-03 12:15:58.885795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2022-05-03 12:15:58.886095: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2022-05-03 12:15:58.887540: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2022-05-03 12:15:58.888229: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2022-05-03 12:15:58.891244: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-05-03 12:15:58.891353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 12:15:58.891997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 12:15:58.892490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2022-05-03 12:15:58.892551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-05-03 12:15:58.893922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-05-03 12:15:58.893981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2022-05-03 12:15:58.893997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2022-05-03 12:15:58.894151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 12:15:58.895053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 12:15:58.896736: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-05-03 12:15:58.896794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","Read data/kiba/ start\n","2111\n","229\n","logs/1651580159.583232/\n","Reading data/kiba/ start\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","[[0, 0, 0, 0, 0]]\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From run_experiments.py:436: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n","\n","WARNING:tensorflow:From run_experiments.py:441: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1)            101         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1)            1001        input_2[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 2)            0           dense_1[0][0]                    \n","                                                                 dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 1024)         3072        concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 1024)         0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 1024)         1049600     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 1024)         0           dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 512)          524800      dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 1)            513         dense_5[0][0]                    \n","==================================================================================================\n","Total params: 1,579,087\n","Trainable params: 1,579,087\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 78836 samples, validate on 19709 samples\n","Epoch 1/100\n","2022-05-03 12:16:02.178205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","78836/78836 [==============================] - 2s 27us/step - loss: 2.5321 - cindex_score: 0.5234 - val_loss: 2.6028 - val_cindex_score: 0.5491\n","Epoch 2/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.9363 - cindex_score: 0.5660 - val_loss: 1.3238 - val_cindex_score: 0.6039\n","Epoch 3/100\n","78836/78836 [==============================] - 2s 20us/step - loss: 0.8134 - cindex_score: 0.5965 - val_loss: 1.3847 - val_cindex_score: 0.6379\n","Epoch 4/100\n","78836/78836 [==============================] - 2s 20us/step - loss: 0.7430 - cindex_score: 0.6156 - val_loss: 2.6005 - val_cindex_score: 0.6528\n","Epoch 5/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.7337 - cindex_score: 0.6281 - val_loss: 2.0053 - val_cindex_score: 0.6619\n","Epoch 6/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.7080 - cindex_score: 0.6340 - val_loss: 2.0152 - val_cindex_score: 0.6691\n","Epoch 7/100\n","78836/78836 [==============================] - 2s 20us/step - loss: 0.7062 - cindex_score: 0.6371 - val_loss: 1.9126 - val_cindex_score: 0.6720\n","Epoch 8/100\n","78836/78836 [==============================] - 2s 20us/step - loss: 0.6926 - cindex_score: 0.6404 - val_loss: 2.3000 - val_cindex_score: 0.6753\n","Epoch 9/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6906 - cindex_score: 0.6422 - val_loss: 1.8393 - val_cindex_score: 0.6746\n","Epoch 10/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6885 - cindex_score: 0.6432 - val_loss: 1.8069 - val_cindex_score: 0.6763\n","Epoch 11/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.7000 - cindex_score: 0.6438 - val_loss: 1.4634 - val_cindex_score: 0.6753\n","Epoch 12/100\n","78836/78836 [==============================] - 2s 20us/step - loss: 0.6815 - cindex_score: 0.6471 - val_loss: 1.3903 - val_cindex_score: 0.6766\n","Epoch 13/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6751 - cindex_score: 0.6478 - val_loss: 1.4497 - val_cindex_score: 0.6785\n","Epoch 14/100\n","78836/78836 [==============================] - 2s 23us/step - loss: 0.6723 - cindex_score: 0.6495 - val_loss: 1.3401 - val_cindex_score: 0.6786\n","Epoch 15/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6657 - cindex_score: 0.6503 - val_loss: 1.2607 - val_cindex_score: 0.6796\n","Epoch 16/100\n","78836/78836 [==============================] - 2s 20us/step - loss: 0.6692 - cindex_score: 0.6514 - val_loss: 1.4826 - val_cindex_score: 0.6819\n","Epoch 17/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6631 - cindex_score: 0.6524 - val_loss: 1.4216 - val_cindex_score: 0.6819\n","Epoch 18/100\n","78836/78836 [==============================] - 2s 20us/step - loss: 0.6595 - cindex_score: 0.6541 - val_loss: 1.3401 - val_cindex_score: 0.6838\n","Epoch 19/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6583 - cindex_score: 0.6553 - val_loss: 1.3498 - val_cindex_score: 0.6833\n","Epoch 20/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6512 - cindex_score: 0.6578 - val_loss: 1.4242 - val_cindex_score: 0.6857\n","Epoch 21/100\n","78836/78836 [==============================] - 2s 20us/step - loss: 0.6467 - cindex_score: 0.6602 - val_loss: 1.3985 - val_cindex_score: 0.6871\n","Epoch 22/100\n","78836/78836 [==============================] - 2s 20us/step - loss: 0.6469 - cindex_score: 0.6609 - val_loss: 1.4059 - val_cindex_score: 0.6882\n","Epoch 23/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6393 - cindex_score: 0.6642 - val_loss: 1.3122 - val_cindex_score: 0.6897\n","Epoch 24/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6391 - cindex_score: 0.6657 - val_loss: 1.4259 - val_cindex_score: 0.6914\n","Epoch 25/100\n","78836/78836 [==============================] - 2s 20us/step - loss: 0.6352 - cindex_score: 0.6658 - val_loss: 1.6713 - val_cindex_score: 0.6919\n","Epoch 26/100\n","78836/78836 [==============================] - 2s 20us/step - loss: 0.6343 - cindex_score: 0.6655 - val_loss: 1.4012 - val_cindex_score: 0.6934\n","Epoch 27/100\n","78836/78836 [==============================] - 2s 20us/step - loss: 0.6355 - cindex_score: 0.6675 - val_loss: 1.6798 - val_cindex_score: 0.6932\n","Epoch 28/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6284 - cindex_score: 0.6684 - val_loss: 1.3926 - val_cindex_score: 0.6942\n","Epoch 29/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6279 - cindex_score: 0.6692 - val_loss: 1.4813 - val_cindex_score: 0.6937\n","Epoch 30/100\n","78836/78836 [==============================] - 2s 20us/step - loss: 0.6250 - cindex_score: 0.6698 - val_loss: 1.5018 - val_cindex_score: 0.6939\n","Epoch 00030: early stopping\n","run_experiments.py:457: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:470: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:484: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","[[0, 0, 0, 0, 0]]\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 1)            101         input_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 1)            1001        input_4[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 2)            0           dense_7[0][0]                    \n","                                                                 dense_8[0][0]                    \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 1024)         3072        concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 1024)         0           dense_9[0][0]                    \n","__________________________________________________________________________________________________\n","dense_10 (Dense)                (None, 1024)         1049600     dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 1024)         0           dense_10[0][0]                   \n","__________________________________________________________________________________________________\n","dense_11 (Dense)                (None, 512)          524800      dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","dense_12 (Dense)                (None, 1)            513         dense_11[0][0]                   \n","==================================================================================================\n","Total params: 1,579,087\n","Trainable params: 1,579,087\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Train on 78836 samples, validate on 19709 samples\n","Epoch 1/100\n","78836/78836 [==============================] - 2s 26us/step - loss: 3.0282 - cindex_score: 0.5400 - val_loss: 1.4467 - val_cindex_score: 0.5645\n","Epoch 2/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.9217 - cindex_score: 0.5740 - val_loss: 1.5948 - val_cindex_score: 0.6113\n","Epoch 3/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.7992 - cindex_score: 0.5964 - val_loss: 2.0497 - val_cindex_score: 0.6394\n","Epoch 4/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.7625 - cindex_score: 0.6108 - val_loss: 1.5830 - val_cindex_score: 0.6525\n","Epoch 5/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.7387 - cindex_score: 0.6204 - val_loss: 2.1024 - val_cindex_score: 0.6639\n","Epoch 6/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.7277 - cindex_score: 0.6266 - val_loss: 2.4265 - val_cindex_score: 0.6695\n","Epoch 7/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.7118 - cindex_score: 0.6319 - val_loss: 2.3371 - val_cindex_score: 0.6731\n","Epoch 8/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.7039 - cindex_score: 0.6362 - val_loss: 2.0099 - val_cindex_score: 0.6760\n","Epoch 9/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6956 - cindex_score: 0.6394 - val_loss: 1.7426 - val_cindex_score: 0.6766\n","Epoch 10/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6882 - cindex_score: 0.6412 - val_loss: 1.8129 - val_cindex_score: 0.6786\n","Epoch 11/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6838 - cindex_score: 0.6423 - val_loss: 1.7337 - val_cindex_score: 0.6803\n","Epoch 12/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6783 - cindex_score: 0.6454 - val_loss: 1.9632 - val_cindex_score: 0.6816\n","Epoch 13/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6923 - cindex_score: 0.6460 - val_loss: 1.4241 - val_cindex_score: 0.6813\n","Epoch 14/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6767 - cindex_score: 0.6476 - val_loss: 1.4796 - val_cindex_score: 0.6818\n","Epoch 15/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6704 - cindex_score: 0.6488 - val_loss: 1.5384 - val_cindex_score: 0.6847\n","Epoch 16/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6707 - cindex_score: 0.6498 - val_loss: 1.3969 - val_cindex_score: 0.6844\n","Epoch 17/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6632 - cindex_score: 0.6520 - val_loss: 1.4163 - val_cindex_score: 0.6851\n","Epoch 18/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6636 - cindex_score: 0.6516 - val_loss: 1.5098 - val_cindex_score: 0.6867\n","Epoch 19/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6594 - cindex_score: 0.6545 - val_loss: 1.3315 - val_cindex_score: 0.6864\n","Epoch 20/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6552 - cindex_score: 0.6557 - val_loss: 1.6256 - val_cindex_score: 0.6896\n","Epoch 21/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6534 - cindex_score: 0.6572 - val_loss: 1.5135 - val_cindex_score: 0.6895\n","Epoch 22/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6534 - cindex_score: 0.6572 - val_loss: 1.3983 - val_cindex_score: 0.6905\n","Epoch 23/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6502 - cindex_score: 0.6599 - val_loss: 1.5457 - val_cindex_score: 0.6904\n","Epoch 24/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6479 - cindex_score: 0.6609 - val_loss: 1.5922 - val_cindex_score: 0.6914\n","Epoch 25/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6429 - cindex_score: 0.6623 - val_loss: 1.4906 - val_cindex_score: 0.6926\n","Epoch 26/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6392 - cindex_score: 0.6628 - val_loss: 1.6491 - val_cindex_score: 0.6925\n","Epoch 27/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6380 - cindex_score: 0.6653 - val_loss: 1.7450 - val_cindex_score: 0.6955\n","Epoch 28/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6360 - cindex_score: 0.6659 - val_loss: 1.7030 - val_cindex_score: 0.6948\n","Epoch 29/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6288 - cindex_score: 0.6683 - val_loss: 1.6506 - val_cindex_score: 0.6975\n","Epoch 30/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6256 - cindex_score: 0.6679 - val_loss: 1.6647 - val_cindex_score: 0.6972\n","Epoch 31/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6271 - cindex_score: 0.6680 - val_loss: 1.4469 - val_cindex_score: 0.6991\n","Epoch 32/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6242 - cindex_score: 0.6707 - val_loss: 1.2088 - val_cindex_score: 0.6986\n","Epoch 33/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6241 - cindex_score: 0.6705 - val_loss: 1.5328 - val_cindex_score: 0.6995\n","Epoch 34/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6221 - cindex_score: 0.6717 - val_loss: 1.6098 - val_cindex_score: 0.7006\n","Epoch 35/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6204 - cindex_score: 0.6720 - val_loss: 1.7153 - val_cindex_score: 0.7000\n","Epoch 36/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6185 - cindex_score: 0.6720 - val_loss: 1.6924 - val_cindex_score: 0.7017\n","Epoch 37/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6200 - cindex_score: 0.6731 - val_loss: 1.5858 - val_cindex_score: 0.7011\n","Epoch 38/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6143 - cindex_score: 0.6740 - val_loss: 1.5921 - val_cindex_score: 0.7020\n","Epoch 39/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6140 - cindex_score: 0.6742 - val_loss: 1.5921 - val_cindex_score: 0.7018\n","Epoch 40/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6130 - cindex_score: 0.6748 - val_loss: 1.6351 - val_cindex_score: 0.7027\n","Epoch 41/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6144 - cindex_score: 0.6747 - val_loss: 1.5121 - val_cindex_score: 0.7025\n","Epoch 42/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6121 - cindex_score: 0.6743 - val_loss: 1.7313 - val_cindex_score: 0.7017\n","Epoch 43/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6117 - cindex_score: 0.6753 - val_loss: 1.7554 - val_cindex_score: 0.7027\n","Epoch 44/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6103 - cindex_score: 0.6771 - val_loss: 1.6164 - val_cindex_score: 0.7030\n","Epoch 45/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6108 - cindex_score: 0.6775 - val_loss: 1.5165 - val_cindex_score: 0.7017\n","Epoch 46/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6087 - cindex_score: 0.6767 - val_loss: 1.7105 - val_cindex_score: 0.7034\n","Epoch 47/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6072 - cindex_score: 0.6775 - val_loss: 1.5674 - val_cindex_score: 0.7026\n","Epoch 00047: early stopping\n","run_experiments.py:457: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:470: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:484: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n"]}]},{"cell_type":"markdown","source":["## Single Protein"],"metadata":{"id":"JAJBegd_I-C4"}},{"cell_type":"markdown","source":["### Davis"],"metadata":{"id":"kDFlt_dcJAME"}},{"cell_type":"code","source":["!./go.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZUDVckHQJGA8","executionInfo":{"status":"ok","timestamp":1650463225082,"user_tz":300,"elapsed":2091192,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"}},"outputId":"3f67fa01-72dc-4647-decd-97ac24cd4832"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From run_experiments.py:16: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","Using TensorFlow backend.\n","WARNING:tensorflow:From run_experiments.py:19: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","2022-04-20 13:25:35.763855: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n","2022-04-20 13:25:35.764029: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e9fc8932c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2022-04-20 13:25:35.764063: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2022-04-20 13:25:35.765713: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2022-04-20 13:25:35.883315: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-20 13:25:35.884220: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e9fc893800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2022-04-20 13:25:35.884255: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n","2022-04-20 13:25:35.884480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-20 13:25:35.885181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2022-04-20 13:25:35.885561: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-04-20 13:25:35.887394: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-04-20 13:25:35.888392: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2022-04-20 13:25:35.888689: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2022-04-20 13:25:35.890424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2022-04-20 13:25:35.891586: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2022-04-20 13:25:35.895609: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-20 13:25:35.895713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-20 13:25:35.896455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-20 13:25:35.897127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2022-04-20 13:25:35.897196: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-04-20 13:25:35.898385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-20 13:25:35.898441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2022-04-20 13:25:35.898460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2022-04-20 13:25:35.898625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-20 13:25:35.899350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-20 13:25:35.900059: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-04-20 13:25:35.900112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","Read data/davis/ start\n","68\n","442\n","logs/1650461136.796049/\n","Reading data/davis/ start\n","val set 5010\n","train set 20036\n","val set 5009\n","train set 20037\n","val set 5009\n","train set 20037\n","val set 5009\n","train set 20037\n","val set 5009\n","train set 20037\n","[[0, 0, 0, 0, 0]]\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From run_experiments.py:435: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n","\n","WARNING:tensorflow:From run_experiments.py:440: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            (None, 1200)         0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 1200, 128)    3328        input_2[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_1 (Conv1D)               (None, 1193, 32)     32800       embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_2 (Conv1D)               (None, 1186, 64)     16448       conv1d_1[0][0]                   \n","__________________________________________________________________________________________________\n","input_1 (InputLayer)            (None, 85)           0                                            \n","__________________________________________________________________________________________________\n","conv1d_3 (Conv1D)               (None, 1179, 96)     49248       conv1d_2[0][0]                   \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1)            86          input_1[0][0]                    \n","__________________________________________________________________________________________________\n","global_max_pooling1d_1 (GlobalM (None, 96)           0           conv1d_3[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 97)           0           dense_1[0][0]                    \n","                                                                 global_max_pooling1d_1[0][0]     \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1024)         100352      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 1024)         1049600     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 1024)         0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 512)          524800      dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 1)            513         dense_4[0][0]                    \n","==================================================================================================\n","Total params: 1,777,175\n","Trainable params: 1,777,175\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 20036 samples, validate on 5010 samples\n","Epoch 1/100\n","2022-04-20 13:25:39.339571: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-04-20 13:25:39.517834: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","20036/20036 [==============================] - 17s 825us/step - loss: 2.2709 - cindex_score: 0.5503 - val_loss: 0.9720 - val_cindex_score: 0.6346\n","Epoch 2/100\n","20036/20036 [==============================] - 13s 643us/step - loss: 0.8123 - cindex_score: 0.5998 - val_loss: 0.7840 - val_cindex_score: 0.6606\n","Epoch 3/100\n","20036/20036 [==============================] - 13s 643us/step - loss: 0.7901 - cindex_score: 0.6225 - val_loss: 0.7209 - val_cindex_score: 0.6716\n","Epoch 4/100\n","20036/20036 [==============================] - 13s 647us/step - loss: 0.7778 - cindex_score: 0.6391 - val_loss: 0.7226 - val_cindex_score: 0.6747\n","Epoch 5/100\n","20036/20036 [==============================] - 13s 649us/step - loss: 0.7749 - cindex_score: 0.6540 - val_loss: 0.7067 - val_cindex_score: 0.6979\n","Epoch 6/100\n","20036/20036 [==============================] - 13s 650us/step - loss: 0.7555 - cindex_score: 0.6671 - val_loss: 0.6838 - val_cindex_score: 0.7155\n","Epoch 7/100\n","20036/20036 [==============================] - 13s 652us/step - loss: 0.7388 - cindex_score: 0.6835 - val_loss: 0.6640 - val_cindex_score: 0.7276\n","Epoch 8/100\n","20036/20036 [==============================] - 13s 650us/step - loss: 0.7228 - cindex_score: 0.6971 - val_loss: 0.6526 - val_cindex_score: 0.7347\n","Epoch 9/100\n","20036/20036 [==============================] - 13s 649us/step - loss: 0.6990 - cindex_score: 0.7115 - val_loss: 0.6218 - val_cindex_score: 0.7422\n","Epoch 10/100\n","20036/20036 [==============================] - 13s 652us/step - loss: 0.6765 - cindex_score: 0.7212 - val_loss: 0.6261 - val_cindex_score: 0.7426\n","Epoch 11/100\n","20036/20036 [==============================] - 13s 649us/step - loss: 0.6744 - cindex_score: 0.7248 - val_loss: 0.6148 - val_cindex_score: 0.7412\n","Epoch 12/100\n","20036/20036 [==============================] - 13s 650us/step - loss: 0.6582 - cindex_score: 0.7279 - val_loss: 0.6080 - val_cindex_score: 0.7487\n","Epoch 13/100\n","20036/20036 [==============================] - 13s 647us/step - loss: 0.6439 - cindex_score: 0.7334 - val_loss: 0.6021 - val_cindex_score: 0.7498\n","Epoch 14/100\n","20036/20036 [==============================] - 13s 651us/step - loss: 0.6499 - cindex_score: 0.7324 - val_loss: 0.5990 - val_cindex_score: 0.7556\n","Epoch 15/100\n","20036/20036 [==============================] - 13s 647us/step - loss: 0.6340 - cindex_score: 0.7345 - val_loss: 0.5990 - val_cindex_score: 0.7549\n","Epoch 16/100\n","20036/20036 [==============================] - 13s 650us/step - loss: 0.6344 - cindex_score: 0.7412 - val_loss: 0.5746 - val_cindex_score: 0.7669\n","Epoch 17/100\n","20036/20036 [==============================] - 13s 648us/step - loss: 0.6283 - cindex_score: 0.7419 - val_loss: 0.5777 - val_cindex_score: 0.7658\n","Epoch 18/100\n","20036/20036 [==============================] - 13s 652us/step - loss: 0.6242 - cindex_score: 0.7465 - val_loss: 0.5710 - val_cindex_score: 0.7684\n","Epoch 19/100\n","20036/20036 [==============================] - 13s 649us/step - loss: 0.6132 - cindex_score: 0.7482 - val_loss: 0.5605 - val_cindex_score: 0.7731\n","Epoch 20/100\n","20036/20036 [==============================] - 13s 649us/step - loss: 0.6084 - cindex_score: 0.7511 - val_loss: 0.5807 - val_cindex_score: 0.7669\n","Epoch 21/100\n","20036/20036 [==============================] - 13s 647us/step - loss: 0.6237 - cindex_score: 0.7482 - val_loss: 0.5672 - val_cindex_score: 0.7714\n","Epoch 22/100\n","20036/20036 [==============================] - 13s 649us/step - loss: 0.6024 - cindex_score: 0.7556 - val_loss: 0.5621 - val_cindex_score: 0.7766\n","Epoch 23/100\n","20036/20036 [==============================] - 13s 645us/step - loss: 0.5985 - cindex_score: 0.7585 - val_loss: 0.5845 - val_cindex_score: 0.7761\n","Epoch 24/100\n","20036/20036 [==============================] - 13s 647us/step - loss: 0.6033 - cindex_score: 0.7592 - val_loss: 0.5693 - val_cindex_score: 0.7783\n","Epoch 25/100\n","20036/20036 [==============================] - 13s 647us/step - loss: 0.5915 - cindex_score: 0.7602 - val_loss: 0.5649 - val_cindex_score: 0.7791\n","Epoch 26/100\n","20036/20036 [==============================] - 13s 650us/step - loss: 0.5760 - cindex_score: 0.7661 - val_loss: 0.5696 - val_cindex_score: 0.7809\n","Epoch 27/100\n","20036/20036 [==============================] - 13s 646us/step - loss: 0.5811 - cindex_score: 0.7670 - val_loss: 0.5545 - val_cindex_score: 0.7814\n","Epoch 28/100\n","20036/20036 [==============================] - 13s 648us/step - loss: 0.5705 - cindex_score: 0.7676 - val_loss: 0.5502 - val_cindex_score: 0.7814\n","Epoch 29/100\n","20036/20036 [==============================] - 13s 645us/step - loss: 0.5494 - cindex_score: 0.7748 - val_loss: 0.5583 - val_cindex_score: 0.7844\n","Epoch 30/100\n","20036/20036 [==============================] - 13s 648us/step - loss: 0.5668 - cindex_score: 0.7712 - val_loss: 0.5390 - val_cindex_score: 0.7857\n","Epoch 31/100\n","20036/20036 [==============================] - 13s 645us/step - loss: 0.5460 - cindex_score: 0.7755 - val_loss: 0.5704 - val_cindex_score: 0.7744\n","Epoch 32/100\n","20036/20036 [==============================] - 13s 646us/step - loss: 0.5479 - cindex_score: 0.7769 - val_loss: 0.5430 - val_cindex_score: 0.7836\n","Epoch 33/100\n","20036/20036 [==============================] - 13s 646us/step - loss: 0.5466 - cindex_score: 0.7759 - val_loss: 0.5716 - val_cindex_score: 0.7720\n","Epoch 34/100\n","20036/20036 [==============================] - 13s 648us/step - loss: 0.5438 - cindex_score: 0.7775 - val_loss: 0.5417 - val_cindex_score: 0.7798\n","Epoch 35/100\n","20036/20036 [==============================] - 13s 645us/step - loss: 0.5367 - cindex_score: 0.7798 - val_loss: 0.5439 - val_cindex_score: 0.7789\n","Epoch 36/100\n","20036/20036 [==============================] - 13s 647us/step - loss: 0.5397 - cindex_score: 0.7782 - val_loss: 0.5400 - val_cindex_score: 0.7827\n","Epoch 37/100\n","20036/20036 [==============================] - 13s 645us/step - loss: 0.5220 - cindex_score: 0.7809 - val_loss: 0.5384 - val_cindex_score: 0.7836\n","Epoch 38/100\n","20036/20036 [==============================] - 13s 648us/step - loss: 0.5357 - cindex_score: 0.7780 - val_loss: 0.5647 - val_cindex_score: 0.7728\n","Epoch 39/100\n","20036/20036 [==============================] - 13s 646us/step - loss: 0.5358 - cindex_score: 0.7755 - val_loss: 0.5506 - val_cindex_score: 0.7812\n","Epoch 40/100\n","20036/20036 [==============================] - 13s 646us/step - loss: 0.5229 - cindex_score: 0.7844 - val_loss: 0.5701 - val_cindex_score: 0.7770\n","Epoch 41/100\n","20036/20036 [==============================] - 13s 646us/step - loss: 0.5187 - cindex_score: 0.7833 - val_loss: 0.5542 - val_cindex_score: 0.7749\n","Epoch 42/100\n","20036/20036 [==============================] - 13s 648us/step - loss: 0.5278 - cindex_score: 0.7801 - val_loss: 0.5671 - val_cindex_score: 0.7688\n","Epoch 43/100\n","20036/20036 [==============================] - 13s 645us/step - loss: 0.5500 - cindex_score: 0.7721 - val_loss: 0.5276 - val_cindex_score: 0.7827\n","Epoch 44/100\n","20036/20036 [==============================] - 13s 648us/step - loss: 0.5039 - cindex_score: 0.7859 - val_loss: 0.5538 - val_cindex_score: 0.7847\n","Epoch 45/100\n","20036/20036 [==============================] - 13s 647us/step - loss: 0.4945 - cindex_score: 0.7886 - val_loss: 0.5282 - val_cindex_score: 0.7827\n","Epoch 46/100\n","20036/20036 [==============================] - 13s 650us/step - loss: 0.4850 - cindex_score: 0.7917 - val_loss: 0.5339 - val_cindex_score: 0.7859\n","Epoch 47/100\n","20036/20036 [==============================] - 13s 646us/step - loss: 0.4815 - cindex_score: 0.7922 - val_loss: 0.5874 - val_cindex_score: 0.7815\n","Epoch 48/100\n","20036/20036 [==============================] - 13s 648us/step - loss: 0.4842 - cindex_score: 0.7903 - val_loss: 0.5359 - val_cindex_score: 0.7808\n","Epoch 49/100\n","20036/20036 [==============================] - 13s 646us/step - loss: 0.4817 - cindex_score: 0.7938 - val_loss: 0.5462 - val_cindex_score: 0.7760\n","Epoch 50/100\n","20036/20036 [==============================] - 13s 647us/step - loss: 0.4780 - cindex_score: 0.7931 - val_loss: 0.5545 - val_cindex_score: 0.7724\n","Epoch 51/100\n","20036/20036 [==============================] - 13s 645us/step - loss: 0.4782 - cindex_score: 0.7934 - val_loss: 0.5284 - val_cindex_score: 0.7787\n","Epoch 52/100\n","20036/20036 [==============================] - 13s 646us/step - loss: 0.4764 - cindex_score: 0.7980 - val_loss: 0.5379 - val_cindex_score: 0.7807\n","Epoch 53/100\n","20036/20036 [==============================] - 13s 646us/step - loss: 0.4664 - cindex_score: 0.7973 - val_loss: 0.5697 - val_cindex_score: 0.7805\n","Epoch 54/100\n","20036/20036 [==============================] - 13s 647us/step - loss: 0.4632 - cindex_score: 0.7970 - val_loss: 0.5427 - val_cindex_score: 0.7745\n","Epoch 55/100\n","20036/20036 [==============================] - 13s 645us/step - loss: 0.4686 - cindex_score: 0.7964 - val_loss: 0.5215 - val_cindex_score: 0.7823\n","Epoch 56/100\n","20036/20036 [==============================] - 13s 646us/step - loss: 0.4744 - cindex_score: 0.7901 - val_loss: 0.5320 - val_cindex_score: 0.7757\n","Epoch 57/100\n","20036/20036 [==============================] - 13s 643us/step - loss: 0.4571 - cindex_score: 0.7997 - val_loss: 0.5507 - val_cindex_score: 0.7627\n","Epoch 58/100\n","20036/20036 [==============================] - 13s 648us/step - loss: 0.4510 - cindex_score: 0.7958 - val_loss: 0.5536 - val_cindex_score: 0.7652\n","Epoch 59/100\n","20036/20036 [==============================] - 13s 645us/step - loss: 0.4516 - cindex_score: 0.7995 - val_loss: 0.5840 - val_cindex_score: 0.7551\n","Epoch 60/100\n","20036/20036 [==============================] - 13s 645us/step - loss: 0.4596 - cindex_score: 0.7963 - val_loss: 0.5464 - val_cindex_score: 0.7775\n","Epoch 61/100\n","20036/20036 [==============================] - 13s 644us/step - loss: 0.4568 - cindex_score: 0.7968 - val_loss: 0.5662 - val_cindex_score: 0.7595\n","Epoch 62/100\n","20036/20036 [==============================] - 13s 647us/step - loss: 0.4440 - cindex_score: 0.7998 - val_loss: 0.5347 - val_cindex_score: 0.7702\n","Epoch 63/100\n","20036/20036 [==============================] - 13s 645us/step - loss: 0.4633 - cindex_score: 0.7970 - val_loss: 0.6353 - val_cindex_score: 0.7534\n","Epoch 64/100\n","20036/20036 [==============================] - 13s 647us/step - loss: 0.4534 - cindex_score: 0.7970 - val_loss: 0.5063 - val_cindex_score: 0.7797\n","Epoch 65/100\n","20036/20036 [==============================] - 13s 646us/step - loss: 0.4717 - cindex_score: 0.7914 - val_loss: 0.5259 - val_cindex_score: 0.7841\n","Epoch 66/100\n","20036/20036 [==============================] - 13s 650us/step - loss: 0.4581 - cindex_score: 0.7980 - val_loss: 0.5459 - val_cindex_score: 0.7863\n","Epoch 67/100\n","20036/20036 [==============================] - 13s 646us/step - loss: 0.4508 - cindex_score: 0.7985 - val_loss: 0.5397 - val_cindex_score: 0.7803\n","Epoch 68/100\n","20036/20036 [==============================] - 13s 647us/step - loss: 0.4617 - cindex_score: 0.7929 - val_loss: 0.5146 - val_cindex_score: 0.7858\n","Epoch 69/100\n","20036/20036 [==============================] - 13s 647us/step - loss: 0.4471 - cindex_score: 0.7955 - val_loss: 0.5520 - val_cindex_score: 0.7855\n","Epoch 70/100\n","20036/20036 [==============================] - 13s 648us/step - loss: 0.4513 - cindex_score: 0.7977 - val_loss: 0.5088 - val_cindex_score: 0.7843\n","Epoch 71/100\n","20036/20036 [==============================] - 13s 645us/step - loss: 0.4654 - cindex_score: 0.7923 - val_loss: 0.5160 - val_cindex_score: 0.7842\n","Epoch 72/100\n","20036/20036 [==============================] - 13s 647us/step - loss: 0.4776 - cindex_score: 0.7933 - val_loss: 0.5890 - val_cindex_score: 0.7767\n","Epoch 73/100\n","20036/20036 [==============================] - 13s 645us/step - loss: 0.4593 - cindex_score: 0.7956 - val_loss: 0.5704 - val_cindex_score: 0.7670\n","Epoch 74/100\n","20036/20036 [==============================] - 13s 649us/step - loss: 0.4526 - cindex_score: 0.7997 - val_loss: 0.5802 - val_cindex_score: 0.7648\n","Epoch 75/100\n","20036/20036 [==============================] - 13s 646us/step - loss: 0.4517 - cindex_score: 0.7968 - val_loss: 0.5716 - val_cindex_score: 0.7790\n","Epoch 76/100\n","20036/20036 [==============================] - 13s 648us/step - loss: 0.4491 - cindex_score: 0.7960 - val_loss: 0.5716 - val_cindex_score: 0.7826\n","Epoch 77/100\n","20036/20036 [==============================] - 13s 647us/step - loss: 0.4296 - cindex_score: 0.8017 - val_loss: 0.5455 - val_cindex_score: 0.7719\n","Epoch 78/100\n","20036/20036 [==============================] - 13s 650us/step - loss: 0.4492 - cindex_score: 0.7996 - val_loss: 0.5484 - val_cindex_score: 0.7756\n","Epoch 79/100\n","20036/20036 [==============================] - 13s 645us/step - loss: 0.4707 - cindex_score: 0.7960 - val_loss: 0.5340 - val_cindex_score: 0.7725\n","Epoch 00079: early stopping\n","run_experiments.py:456: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:469: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:483: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","[[0, 0, 0, 0, 0]]\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            (None, 1200)         0                                            \n","__________________________________________________________________________________________________\n","embedding_2 (Embedding)         (None, 1200, 128)    3328        input_4[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_4 (Conv1D)               (None, 1193, 32)     32800       embedding_2[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_5 (Conv1D)               (None, 1186, 64)     16448       conv1d_4[0][0]                   \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            (None, 85)           0                                            \n","__________________________________________________________________________________________________\n","conv1d_6 (Conv1D)               (None, 1179, 96)     49248       conv1d_5[0][0]                   \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 1)            86          input_3[0][0]                    \n","__________________________________________________________________________________________________\n","global_max_pooling1d_2 (GlobalM (None, 96)           0           conv1d_6[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 97)           0           dense_6[0][0]                    \n","                                                                 global_max_pooling1d_2[0][0]     \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 1024)         100352      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 1024)         0           dense_7[0][0]                    \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 1024)         1049600     dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 512)          524800      dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","dense_10 (Dense)                (None, 1)            513         dense_9[0][0]                    \n","==================================================================================================\n","Total params: 1,777,175\n","Trainable params: 1,777,175\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Train on 20036 samples, validate on 5010 samples\n","Epoch 1/100\n","20036/20036 [==============================] - 13s 667us/step - loss: 3.6293 - cindex_score: 0.5695 - val_loss: 0.7510 - val_cindex_score: 0.6277\n","Epoch 2/100\n","20036/20036 [==============================] - 13s 643us/step - loss: 0.8177 - cindex_score: 0.6088 - val_loss: 0.7482 - val_cindex_score: 0.6446\n","Epoch 3/100\n","20036/20036 [==============================] - 13s 647us/step - loss: 0.7800 - cindex_score: 0.6252 - val_loss: 0.8298 - val_cindex_score: 0.6496\n","Epoch 4/100\n","20036/20036 [==============================] - 13s 646us/step - loss: 0.7703 - cindex_score: 0.6421 - val_loss: 0.8076 - val_cindex_score: 0.6590\n","Epoch 5/100\n","20036/20036 [==============================] - 13s 647us/step - loss: 0.7570 - cindex_score: 0.6490 - val_loss: 0.7113 - val_cindex_score: 0.6734\n","Epoch 6/100\n","20036/20036 [==============================] - 13s 646us/step - loss: 0.7485 - cindex_score: 0.6602 - val_loss: 0.6916 - val_cindex_score: 0.6779\n","Epoch 7/100\n","20036/20036 [==============================] - 13s 649us/step - loss: 0.7340 - cindex_score: 0.6706 - val_loss: 0.7114 - val_cindex_score: 0.6892\n","Epoch 8/100\n","20036/20036 [==============================] - 13s 647us/step - loss: 0.7279 - cindex_score: 0.6806 - val_loss: 0.6862 - val_cindex_score: 0.7011\n","Epoch 9/100\n","20036/20036 [==============================] - 13s 648us/step - loss: 0.7006 - cindex_score: 0.6904 - val_loss: 0.6717 - val_cindex_score: 0.7076\n","Epoch 10/100\n","20036/20036 [==============================] - 13s 647us/step - loss: 0.6866 - cindex_score: 0.7017 - val_loss: 0.7067 - val_cindex_score: 0.7212\n","Epoch 11/100\n","20036/20036 [==============================] - 13s 649us/step - loss: 0.6836 - cindex_score: 0.7122 - val_loss: 0.6829 - val_cindex_score: 0.7319\n","Epoch 12/100\n","20036/20036 [==============================] - 13s 648us/step - loss: 0.6638 - cindex_score: 0.7253 - val_loss: 0.6468 - val_cindex_score: 0.7378\n","Epoch 13/100\n","20036/20036 [==============================] - 13s 650us/step - loss: 0.6414 - cindex_score: 0.7364 - val_loss: 0.6205 - val_cindex_score: 0.7530\n","Epoch 14/100\n","20036/20036 [==============================] - 13s 650us/step - loss: 0.6470 - cindex_score: 0.7433 - val_loss: 0.6576 - val_cindex_score: 0.7606\n","Epoch 15/100\n","20036/20036 [==============================] - 13s 655us/step - loss: 0.6229 - cindex_score: 0.7542 - val_loss: 0.6398 - val_cindex_score: 0.7636\n","Epoch 16/100\n","20036/20036 [==============================] - 13s 654us/step - loss: 0.6104 - cindex_score: 0.7560 - val_loss: 0.5924 - val_cindex_score: 0.7710\n","Epoch 17/100\n","20036/20036 [==============================] - 13s 654us/step - loss: 0.5980 - cindex_score: 0.7642 - val_loss: 0.6315 - val_cindex_score: 0.7662\n","Epoch 18/100\n","20036/20036 [==============================] - 13s 651us/step - loss: 0.5906 - cindex_score: 0.7634 - val_loss: 0.6077 - val_cindex_score: 0.7644\n","Epoch 19/100\n","20036/20036 [==============================] - 13s 654us/step - loss: 0.5930 - cindex_score: 0.7681 - val_loss: 0.6481 - val_cindex_score: 0.7669\n","Epoch 20/100\n","20036/20036 [==============================] - 13s 652us/step - loss: 0.5857 - cindex_score: 0.7693 - val_loss: 0.6157 - val_cindex_score: 0.7803\n","Epoch 21/100\n","20036/20036 [==============================] - 13s 650us/step - loss: 0.5807 - cindex_score: 0.7724 - val_loss: 0.6167 - val_cindex_score: 0.7713\n","Epoch 22/100\n","20036/20036 [==============================] - 13s 651us/step - loss: 0.5815 - cindex_score: 0.7747 - val_loss: 0.5845 - val_cindex_score: 0.7775\n","Epoch 23/100\n","20036/20036 [==============================] - 13s 655us/step - loss: 0.5686 - cindex_score: 0.7774 - val_loss: 0.5840 - val_cindex_score: 0.7760\n","Epoch 24/100\n","20036/20036 [==============================] - 13s 654us/step - loss: 0.5552 - cindex_score: 0.7802 - val_loss: 0.5519 - val_cindex_score: 0.7853\n","Epoch 25/100\n","20036/20036 [==============================] - 13s 653us/step - loss: 0.5558 - cindex_score: 0.7767 - val_loss: 0.5499 - val_cindex_score: 0.7833\n","Epoch 26/100\n","20036/20036 [==============================] - 13s 653us/step - loss: 0.5496 - cindex_score: 0.7800 - val_loss: 0.5972 - val_cindex_score: 0.7763\n","Epoch 27/100\n","20036/20036 [==============================] - 13s 655us/step - loss: 0.5462 - cindex_score: 0.7833 - val_loss: 0.5400 - val_cindex_score: 0.7852\n","Epoch 28/100\n","20036/20036 [==============================] - 13s 653us/step - loss: 0.5450 - cindex_score: 0.7841 - val_loss: 0.5332 - val_cindex_score: 0.7827\n","Epoch 29/100\n","20036/20036 [==============================] - 13s 653us/step - loss: 0.5344 - cindex_score: 0.7842 - val_loss: 0.5399 - val_cindex_score: 0.7832\n","Epoch 30/100\n","20036/20036 [==============================] - 13s 652us/step - loss: 0.5309 - cindex_score: 0.7842 - val_loss: 0.5770 - val_cindex_score: 0.7777\n","Epoch 31/100\n","20036/20036 [==============================] - 13s 655us/step - loss: 0.5313 - cindex_score: 0.7871 - val_loss: 0.5206 - val_cindex_score: 0.7900\n","Epoch 32/100\n","20036/20036 [==============================] - 13s 652us/step - loss: 0.5299 - cindex_score: 0.7867 - val_loss: 0.5257 - val_cindex_score: 0.7873\n","Epoch 33/100\n","20036/20036 [==============================] - 13s 653us/step - loss: 0.5255 - cindex_score: 0.7824 - val_loss: 0.5257 - val_cindex_score: 0.7858\n","Epoch 34/100\n","20036/20036 [==============================] - 13s 652us/step - loss: 0.5167 - cindex_score: 0.7862 - val_loss: 0.5205 - val_cindex_score: 0.7809\n","Epoch 35/100\n","20036/20036 [==============================] - 13s 656us/step - loss: 0.5090 - cindex_score: 0.7914 - val_loss: 0.5116 - val_cindex_score: 0.7894\n","Epoch 36/100\n","20036/20036 [==============================] - 13s 653us/step - loss: 0.5170 - cindex_score: 0.7887 - val_loss: 0.5176 - val_cindex_score: 0.7905\n","Epoch 37/100\n","20036/20036 [==============================] - 13s 653us/step - loss: 0.5046 - cindex_score: 0.7914 - val_loss: 0.5348 - val_cindex_score: 0.7908\n","Epoch 38/100\n","20036/20036 [==============================] - 13s 652us/step - loss: 0.5017 - cindex_score: 0.7911 - val_loss: 0.5197 - val_cindex_score: 0.7881\n","Epoch 39/100\n","20036/20036 [==============================] - 13s 654us/step - loss: 0.4956 - cindex_score: 0.7934 - val_loss: 0.5132 - val_cindex_score: 0.7863\n","Epoch 40/100\n","20036/20036 [==============================] - 13s 653us/step - loss: 0.4921 - cindex_score: 0.7946 - val_loss: 0.5103 - val_cindex_score: 0.7870\n","Epoch 41/100\n","20036/20036 [==============================] - 13s 652us/step - loss: 0.5123 - cindex_score: 0.7921 - val_loss: 0.5053 - val_cindex_score: 0.7972\n","Epoch 42/100\n","20036/20036 [==============================] - 13s 652us/step - loss: 0.4918 - cindex_score: 0.7957 - val_loss: 0.5061 - val_cindex_score: 0.7884\n","Epoch 43/100\n","20036/20036 [==============================] - 13s 654us/step - loss: 0.4736 - cindex_score: 0.8015 - val_loss: 0.5354 - val_cindex_score: 0.7790\n","Epoch 44/100\n","20036/20036 [==============================] - 13s 651us/step - loss: 0.4955 - cindex_score: 0.7963 - val_loss: 0.4931 - val_cindex_score: 0.8002\n","Epoch 45/100\n","20036/20036 [==============================] - 13s 652us/step - loss: 0.4813 - cindex_score: 0.7966 - val_loss: 0.4925 - val_cindex_score: 0.8003\n","Epoch 46/100\n","20036/20036 [==============================] - 13s 651us/step - loss: 0.4748 - cindex_score: 0.7983 - val_loss: 0.5064 - val_cindex_score: 0.7962\n","Epoch 47/100\n","20036/20036 [==============================] - 13s 654us/step - loss: 0.4926 - cindex_score: 0.7957 - val_loss: 0.5124 - val_cindex_score: 0.7974\n","Epoch 48/100\n","20036/20036 [==============================] - 13s 652us/step - loss: 0.4644 - cindex_score: 0.8012 - val_loss: 0.5088 - val_cindex_score: 0.7914\n","Epoch 49/100\n","20036/20036 [==============================] - 13s 653us/step - loss: 0.4686 - cindex_score: 0.7986 - val_loss: 0.4970 - val_cindex_score: 0.7882\n","Epoch 50/100\n","20036/20036 [==============================] - 13s 657us/step - loss: 0.4600 - cindex_score: 0.7998 - val_loss: 0.5217 - val_cindex_score: 0.7851\n","Epoch 51/100\n","20036/20036 [==============================] - 13s 654us/step - loss: 0.4600 - cindex_score: 0.7987 - val_loss: 0.4975 - val_cindex_score: 0.7946\n","Epoch 52/100\n","20036/20036 [==============================] - 13s 652us/step - loss: 0.4628 - cindex_score: 0.8009 - val_loss: 0.5532 - val_cindex_score: 0.7780\n","Epoch 53/100\n","20036/20036 [==============================] - 13s 653us/step - loss: 0.4724 - cindex_score: 0.7982 - val_loss: 0.5081 - val_cindex_score: 0.7876\n","Epoch 54/100\n","20036/20036 [==============================] - 13s 651us/step - loss: 0.4727 - cindex_score: 0.7980 - val_loss: 0.5125 - val_cindex_score: 0.7929\n","Epoch 55/100\n","20036/20036 [==============================] - 13s 655us/step - loss: 0.4641 - cindex_score: 0.8040 - val_loss: 0.4846 - val_cindex_score: 0.8019\n","Epoch 56/100\n","20036/20036 [==============================] - 13s 652us/step - loss: 0.4497 - cindex_score: 0.8056 - val_loss: 0.4891 - val_cindex_score: 0.7986\n","Epoch 57/100\n","20036/20036 [==============================] - 13s 653us/step - loss: 0.4472 - cindex_score: 0.8016 - val_loss: 0.5156 - val_cindex_score: 0.7879\n","Epoch 58/100\n","20036/20036 [==============================] - 13s 653us/step - loss: 0.4553 - cindex_score: 0.8036 - val_loss: 0.5107 - val_cindex_score: 0.7858\n","Epoch 59/100\n","20036/20036 [==============================] - 13s 654us/step - loss: 0.4533 - cindex_score: 0.8027 - val_loss: 0.5000 - val_cindex_score: 0.7887\n","Epoch 60/100\n","20036/20036 [==============================] - 13s 653us/step - loss: 0.4452 - cindex_score: 0.8055 - val_loss: 0.5408 - val_cindex_score: 0.7919\n","Epoch 61/100\n","20036/20036 [==============================] - 13s 653us/step - loss: 0.4506 - cindex_score: 0.8033 - val_loss: 0.5065 - val_cindex_score: 0.7929\n","Epoch 62/100\n","20036/20036 [==============================] - 13s 653us/step - loss: 0.4527 - cindex_score: 0.8005 - val_loss: 0.5027 - val_cindex_score: 0.8033\n","Epoch 63/100\n","20036/20036 [==============================] - 13s 654us/step - loss: 0.4719 - cindex_score: 0.8005 - val_loss: 0.5136 - val_cindex_score: 0.8010\n","Epoch 64/100\n","20036/20036 [==============================] - 13s 652us/step - loss: 0.4592 - cindex_score: 0.7985 - val_loss: 0.5023 - val_cindex_score: 0.8004\n","Epoch 65/100\n","20036/20036 [==============================] - 13s 652us/step - loss: 0.4663 - cindex_score: 0.7984 - val_loss: 0.5112 - val_cindex_score: 0.7981\n","Epoch 66/100\n","20036/20036 [==============================] - 13s 651us/step - loss: 0.4510 - cindex_score: 0.8055 - val_loss: 0.4982 - val_cindex_score: 0.7997\n","Epoch 67/100\n","20036/20036 [==============================] - 13s 654us/step - loss: 0.4348 - cindex_score: 0.8087 - val_loss: 0.5049 - val_cindex_score: 0.7978\n","Epoch 68/100\n","20036/20036 [==============================] - 13s 652us/step - loss: 0.4260 - cindex_score: 0.8112 - val_loss: 0.5035 - val_cindex_score: 0.7997\n","Epoch 69/100\n","20036/20036 [==============================] - 13s 651us/step - loss: 0.4093 - cindex_score: 0.8164 - val_loss: 0.4939 - val_cindex_score: 0.8076\n","Epoch 70/100\n","20036/20036 [==============================] - 13s 652us/step - loss: 0.4192 - cindex_score: 0.8141 - val_loss: 0.4898 - val_cindex_score: 0.8109\n","Epoch 00070: early stopping\n","run_experiments.py:456: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:469: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:483: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n"]}]},{"cell_type":"markdown","source":["### KIBA"],"metadata":{"id":"UNbS494SJDJI"}},{"cell_type":"code","source":["!./go.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zcu8Rd4b-Kx5","executionInfo":{"status":"ok","timestamp":1651585678632,"user_tz":300,"elapsed":2209524,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"}},"outputId":"e8e3e322-d610-495b-9414-3a929ce6f902"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From run_experiments.py:16: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","Using TensorFlow backend.\n","WARNING:tensorflow:From run_experiments.py:19: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","2022-05-03 13:11:10.436979: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n","2022-05-03 13:11:10.437126: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x19ed2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2022-05-03 13:11:10.437154: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2022-05-03 13:11:10.438789: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2022-05-03 13:11:10.668578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 13:11:10.669317: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x19ed640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2022-05-03 13:11:10.669352: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2022-05-03 13:11:10.669529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 13:11:10.670080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2022-05-03 13:11:10.670359: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-05-03 13:11:10.671771: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-05-03 13:11:10.672643: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2022-05-03 13:11:10.672976: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2022-05-03 13:11:10.674470: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2022-05-03 13:11:10.675142: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2022-05-03 13:11:10.678003: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-05-03 13:11:10.678103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 13:11:10.678662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 13:11:10.679181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2022-05-03 13:11:10.679236: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-05-03 13:11:10.680272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-05-03 13:11:10.680300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2022-05-03 13:11:10.680312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2022-05-03 13:11:10.680431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 13:11:10.681077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 13:11:10.681640: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-05-03 13:11:10.681680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","Read data/kiba/ start\n","2111\n","229\n","logs/1651583471.3697548/\n","Reading data/kiba/ start\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","[[0, 0, 0, 0, 0]]\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From run_experiments.py:436: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n","\n","WARNING:tensorflow:From run_experiments.py:441: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 1000, 128)    3328        input_2[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_1 (Conv1D)               (None, 993, 32)      32800       embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_2 (Conv1D)               (None, 986, 64)      16448       conv1d_1[0][0]                   \n","__________________________________________________________________________________________________\n","input_1 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","conv1d_3 (Conv1D)               (None, 979, 96)      49248       conv1d_2[0][0]                   \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1)            101         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","global_max_pooling1d_1 (GlobalM (None, 96)           0           conv1d_3[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 97)           0           dense_1[0][0]                    \n","                                                                 global_max_pooling1d_1[0][0]     \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1024)         100352      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 1024)         1049600     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 1024)         0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 512)          524800      dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 1)            513         dense_4[0][0]                    \n","==================================================================================================\n","Total params: 1,777,190\n","Trainable params: 1,777,190\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 78836 samples, validate on 19709 samples\n","Epoch 1/100\n","2022-05-03 13:11:14.340521: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-05-03 13:11:14.596193: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","78836/78836 [==============================] - 23s 294us/step - loss: 2.7204 - cindex_score: 0.5453 - val_loss: 0.6716 - val_cindex_score: 0.6459\n","Epoch 2/100\n","78836/78836 [==============================] - 20s 256us/step - loss: 0.8175 - cindex_score: 0.5916 - val_loss: 1.1082 - val_cindex_score: 0.6690\n","Epoch 3/100\n","78836/78836 [==============================] - 20s 256us/step - loss: 0.7844 - cindex_score: 0.6116 - val_loss: 0.6993 - val_cindex_score: 0.6750\n","Epoch 4/100\n","78836/78836 [==============================] - 20s 256us/step - loss: 0.8100 - cindex_score: 0.6181 - val_loss: 0.6930 - val_cindex_score: 0.6785\n","Epoch 5/100\n","78836/78836 [==============================] - 20s 256us/step - loss: 0.7657 - cindex_score: 0.6217 - val_loss: 0.7651 - val_cindex_score: 0.6776\n","Epoch 6/100\n","78836/78836 [==============================] - 21s 260us/step - loss: 0.7593 - cindex_score: 0.6257 - val_loss: 0.8263 - val_cindex_score: 0.6772\n","Epoch 7/100\n","78836/78836 [==============================] - 21s 263us/step - loss: 0.7689 - cindex_score: 0.6257 - val_loss: 1.2117 - val_cindex_score: 0.6763\n","Epoch 8/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.7575 - cindex_score: 0.6264 - val_loss: 0.8753 - val_cindex_score: 0.6788\n","Epoch 9/100\n","78836/78836 [==============================] - 21s 267us/step - loss: 0.7495 - cindex_score: 0.6265 - val_loss: 0.8813 - val_cindex_score: 0.6775\n","Epoch 10/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.7547 - cindex_score: 0.6279 - val_loss: 0.6788 - val_cindex_score: 0.6780\n","Epoch 11/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.7414 - cindex_score: 0.6262 - val_loss: 0.6518 - val_cindex_score: 0.6786\n","Epoch 12/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.7396 - cindex_score: 0.6277 - val_loss: 0.6760 - val_cindex_score: 0.6785\n","Epoch 13/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.7259 - cindex_score: 0.6284 - val_loss: 0.7219 - val_cindex_score: 0.6790\n","Epoch 14/100\n","78836/78836 [==============================] - 21s 271us/step - loss: 0.7328 - cindex_score: 0.6295 - val_loss: 0.6396 - val_cindex_score: 0.6793\n","Epoch 15/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.7359 - cindex_score: 0.6290 - val_loss: 0.8631 - val_cindex_score: 0.6785\n","Epoch 16/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.7282 - cindex_score: 0.6317 - val_loss: 0.8708 - val_cindex_score: 0.6787\n","Epoch 17/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.7160 - cindex_score: 0.6335 - val_loss: 1.0200 - val_cindex_score: 0.6767\n","Epoch 18/100\n","78836/78836 [==============================] - 21s 271us/step - loss: 0.7168 - cindex_score: 0.6336 - val_loss: 0.9855 - val_cindex_score: 0.6802\n","Epoch 19/100\n","78836/78836 [==============================] - 21s 271us/step - loss: 0.7030 - cindex_score: 0.6375 - val_loss: 0.7910 - val_cindex_score: 0.6797\n","Epoch 20/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.6937 - cindex_score: 0.6402 - val_loss: 0.8530 - val_cindex_score: 0.6801\n","Epoch 21/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6916 - cindex_score: 0.6425 - val_loss: 1.2003 - val_cindex_score: 0.6824\n","Epoch 22/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.6802 - cindex_score: 0.6463 - val_loss: 1.5106 - val_cindex_score: 0.6816\n","Epoch 23/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.6790 - cindex_score: 0.6479 - val_loss: 1.6099 - val_cindex_score: 0.6808\n","Epoch 24/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.6761 - cindex_score: 0.6504 - val_loss: 1.4016 - val_cindex_score: 0.6811\n","Epoch 25/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.6718 - cindex_score: 0.6507 - val_loss: 1.6953 - val_cindex_score: 0.6843\n","Epoch 26/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.6653 - cindex_score: 0.6538 - val_loss: 1.4199 - val_cindex_score: 0.6857\n","Epoch 27/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.6541 - cindex_score: 0.6554 - val_loss: 1.6073 - val_cindex_score: 0.6842\n","Epoch 28/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.6589 - cindex_score: 0.6542 - val_loss: 1.4752 - val_cindex_score: 0.6830\n","Epoch 29/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.6620 - cindex_score: 0.6534 - val_loss: 1.7078 - val_cindex_score: 0.6829\n","Epoch 00029: early stopping\n","run_experiments.py:457: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:470: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:484: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","[[0, 0, 0, 0, 0]]\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","embedding_2 (Embedding)         (None, 1000, 128)    3328        input_4[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_4 (Conv1D)               (None, 993, 32)      32800       embedding_2[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_5 (Conv1D)               (None, 986, 64)      16448       conv1d_4[0][0]                   \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","conv1d_6 (Conv1D)               (None, 979, 96)      49248       conv1d_5[0][0]                   \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 1)            101         input_3[0][0]                    \n","__________________________________________________________________________________________________\n","global_max_pooling1d_2 (GlobalM (None, 96)           0           conv1d_6[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 97)           0           dense_6[0][0]                    \n","                                                                 global_max_pooling1d_2[0][0]     \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 1024)         100352      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 1024)         0           dense_7[0][0]                    \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 1024)         1049600     dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 512)          524800      dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","dense_10 (Dense)                (None, 1)            513         dense_9[0][0]                    \n","==================================================================================================\n","Total params: 1,777,190\n","Trainable params: 1,777,190\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Train on 78836 samples, validate on 19709 samples\n","Epoch 1/100\n","78836/78836 [==============================] - 21s 262us/step - loss: 3.3530 - cindex_score: 0.5445 - val_loss: 0.9161 - val_cindex_score: 0.6431\n","Epoch 2/100\n","78836/78836 [==============================] - 20s 256us/step - loss: 0.8033 - cindex_score: 0.6005 - val_loss: 0.9289 - val_cindex_score: 0.6594\n","Epoch 3/100\n","78836/78836 [==============================] - 20s 257us/step - loss: 0.7914 - cindex_score: 0.6161 - val_loss: 0.8888 - val_cindex_score: 0.6652\n","Epoch 4/100\n","78836/78836 [==============================] - 21s 261us/step - loss: 0.7887 - cindex_score: 0.6208 - val_loss: 0.8249 - val_cindex_score: 0.6734\n","Epoch 5/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.7906 - cindex_score: 0.6244 - val_loss: 1.0225 - val_cindex_score: 0.6670\n","Epoch 6/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.7519 - cindex_score: 0.6267 - val_loss: 0.8705 - val_cindex_score: 0.6728\n","Epoch 7/100\n","78836/78836 [==============================] - 21s 268us/step - loss: 0.7576 - cindex_score: 0.6267 - val_loss: 1.0498 - val_cindex_score: 0.6758\n","Epoch 8/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.7584 - cindex_score: 0.6287 - val_loss: 1.1083 - val_cindex_score: 0.6712\n","Epoch 9/100\n","78836/78836 [==============================] - 21s 271us/step - loss: 0.7482 - cindex_score: 0.6300 - val_loss: 1.1607 - val_cindex_score: 0.6718\n","Epoch 10/100\n","78836/78836 [==============================] - 21s 271us/step - loss: 0.7428 - cindex_score: 0.6325 - val_loss: 1.1022 - val_cindex_score: 0.6761\n","Epoch 11/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.7314 - cindex_score: 0.6362 - val_loss: 0.9361 - val_cindex_score: 0.6721\n","Epoch 12/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.7146 - cindex_score: 0.6386 - val_loss: 1.1699 - val_cindex_score: 0.6752\n","Epoch 13/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.7119 - cindex_score: 0.6418 - val_loss: 1.7013 - val_cindex_score: 0.6749\n","Epoch 14/100\n","78836/78836 [==============================] - 21s 271us/step - loss: 0.6974 - cindex_score: 0.6454 - val_loss: 1.4562 - val_cindex_score: 0.6778\n","Epoch 15/100\n","78836/78836 [==============================] - 21s 271us/step - loss: 0.6928 - cindex_score: 0.6460 - val_loss: 1.5539 - val_cindex_score: 0.6748\n","Epoch 16/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.6849 - cindex_score: 0.6494 - val_loss: 2.0447 - val_cindex_score: 0.6778\n","Epoch 17/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.6805 - cindex_score: 0.6509 - val_loss: 2.5756 - val_cindex_score: 0.6819\n","Epoch 18/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.6772 - cindex_score: 0.6528 - val_loss: 1.9879 - val_cindex_score: 0.6850\n","Epoch 19/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.6756 - cindex_score: 0.6537 - val_loss: 1.4612 - val_cindex_score: 0.6847\n","Epoch 00019: early stopping\n","run_experiments.py:457: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:470: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:484: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n"]}]},{"cell_type":"markdown","source":["## Single Drug"],"metadata":{"id":"QjcE4_6aR_vi"}},{"cell_type":"markdown","source":["### Davis"],"metadata":{"id":"2hPvPbMWSEVs"}},{"cell_type":"code","source":["!./go.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dakb1WlsTcyg","executionInfo":{"status":"ok","timestamp":1650465334390,"user_tz":300,"elapsed":487669,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"}},"outputId":"a96e6e19-2cf2-4c81-cfdf-3638efc4607f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From run_experiments.py:16: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","Using TensorFlow backend.\n","WARNING:tensorflow:From run_experiments.py:19: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","2022-04-20 14:27:28.832443: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n","2022-04-20 14:27:28.832662: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5611c5dcd2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2022-04-20 14:27:28.832704: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2022-04-20 14:27:28.834906: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2022-04-20 14:27:28.978505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-20 14:27:28.979449: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5611c5dcd800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2022-04-20 14:27:28.979486: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n","2022-04-20 14:27:28.979707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-20 14:27:28.980432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2022-04-20 14:27:28.980862: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-04-20 14:27:28.982982: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-04-20 14:27:28.984176: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2022-04-20 14:27:28.984573: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2022-04-20 14:27:28.986974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2022-04-20 14:27:28.988254: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2022-04-20 14:27:28.993014: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-20 14:27:28.993151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-20 14:27:28.994014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-20 14:27:28.994684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2022-04-20 14:27:28.994773: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-04-20 14:27:28.995980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-20 14:27:28.996017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2022-04-20 14:27:28.996036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2022-04-20 14:27:28.996187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-20 14:27:28.996953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-20 14:27:28.997694: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-04-20 14:27:28.997767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","Read data/davis/ start\n","68\n","442\n","logs/1650464849.9639883/\n","Reading data/davis/ start\n","val set 5010\n","train set 20036\n","val set 5009\n","train set 20037\n","val set 5009\n","train set 20037\n","val set 5009\n","train set 20037\n","val set 5009\n","train set 20037\n","[[0, 0, 0, 0, 0]]\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From run_experiments.py:437: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n","\n","WARNING:tensorflow:From run_experiments.py:442: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 85)           0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 85, 128)      8320        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_1 (Conv1D)               (None, 80, 32)       24608       embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_2 (Conv1D)               (None, 75, 64)       12352       conv1d_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_3 (Conv1D)               (None, 70, 96)       36960       conv1d_2[0][0]                   \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 1200)         0                                            \n","__________________________________________________________________________________________________\n","global_max_pooling1d_1 (GlobalM (None, 96)           0           conv1d_3[0][0]                   \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1)            1201        input_2[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 97)           0           global_max_pooling1d_1[0][0]     \n","                                                                 dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1024)         100352      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 1024)         1049600     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 1024)         0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 512)          524800      dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 1)            513         dense_4[0][0]                    \n","==================================================================================================\n","Total params: 1,758,706\n","Trainable params: 1,758,706\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 20036 samples, validate on 5010 samples\n","Epoch 1/100\n","2022-04-20 14:27:32.669538: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-04-20 14:27:32.825004: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","20036/20036 [==============================] - 5s 245us/step - loss: 2.0737 - cindex_score: 0.5991 - val_loss: 0.6818 - val_cindex_score: 0.7102\n","Epoch 2/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.7171 - cindex_score: 0.6978 - val_loss: 0.6437 - val_cindex_score: 0.7461\n","Epoch 3/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.6885 - cindex_score: 0.7326 - val_loss: 0.6225 - val_cindex_score: 0.7555\n","Epoch 4/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.6795 - cindex_score: 0.7371 - val_loss: 0.6245 - val_cindex_score: 0.7608\n","Epoch 5/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.6632 - cindex_score: 0.7460 - val_loss: 0.6171 - val_cindex_score: 0.7628\n","Epoch 6/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.6546 - cindex_score: 0.7471 - val_loss: 0.5973 - val_cindex_score: 0.7662\n","Epoch 7/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.6397 - cindex_score: 0.7510 - val_loss: 0.6096 - val_cindex_score: 0.7648\n","Epoch 8/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.6355 - cindex_score: 0.7505 - val_loss: 0.5841 - val_cindex_score: 0.7650\n","Epoch 9/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.6403 - cindex_score: 0.7538 - val_loss: 0.5827 - val_cindex_score: 0.7669\n","Epoch 10/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.6288 - cindex_score: 0.7535 - val_loss: 0.5749 - val_cindex_score: 0.7701\n","Epoch 11/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.6179 - cindex_score: 0.7566 - val_loss: 0.5668 - val_cindex_score: 0.7779\n","Epoch 12/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.6259 - cindex_score: 0.7573 - val_loss: 0.5532 - val_cindex_score: 0.7813\n","Epoch 13/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.5920 - cindex_score: 0.7659 - val_loss: 0.5411 - val_cindex_score: 0.7850\n","Epoch 14/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.5977 - cindex_score: 0.7622 - val_loss: 0.5332 - val_cindex_score: 0.7857\n","Epoch 15/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.5892 - cindex_score: 0.7655 - val_loss: 0.5296 - val_cindex_score: 0.7891\n","Epoch 16/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.5855 - cindex_score: 0.7708 - val_loss: 0.5515 - val_cindex_score: 0.7910\n","Epoch 17/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.6027 - cindex_score: 0.7692 - val_loss: 0.6050 - val_cindex_score: 0.7903\n","Epoch 18/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.5894 - cindex_score: 0.7712 - val_loss: 0.5190 - val_cindex_score: 0.7918\n","Epoch 19/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.5721 - cindex_score: 0.7714 - val_loss: 0.5492 - val_cindex_score: 0.7934\n","Epoch 20/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.5690 - cindex_score: 0.7767 - val_loss: 0.5450 - val_cindex_score: 0.7947\n","Epoch 21/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.5714 - cindex_score: 0.7722 - val_loss: 0.5053 - val_cindex_score: 0.7956\n","Epoch 22/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.5509 - cindex_score: 0.7766 - val_loss: 0.4983 - val_cindex_score: 0.8007\n","Epoch 23/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.5475 - cindex_score: 0.7765 - val_loss: 0.4910 - val_cindex_score: 0.7989\n","Epoch 24/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.5408 - cindex_score: 0.7803 - val_loss: 0.4970 - val_cindex_score: 0.8007\n","Epoch 25/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.5385 - cindex_score: 0.7795 - val_loss: 0.4942 - val_cindex_score: 0.8009\n","Epoch 26/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.5304 - cindex_score: 0.7814 - val_loss: 0.4890 - val_cindex_score: 0.8033\n","Epoch 27/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.5248 - cindex_score: 0.7823 - val_loss: 0.4836 - val_cindex_score: 0.7943\n","Epoch 28/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.5232 - cindex_score: 0.7816 - val_loss: 0.4765 - val_cindex_score: 0.7991\n","Epoch 29/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.5140 - cindex_score: 0.7884 - val_loss: 0.4840 - val_cindex_score: 0.7988\n","Epoch 30/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.5208 - cindex_score: 0.7869 - val_loss: 0.4724 - val_cindex_score: 0.8021\n","Epoch 31/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.5166 - cindex_score: 0.7866 - val_loss: 0.4735 - val_cindex_score: 0.8039\n","Epoch 32/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.5044 - cindex_score: 0.7872 - val_loss: 0.4812 - val_cindex_score: 0.8063\n","Epoch 33/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.5032 - cindex_score: 0.7892 - val_loss: 0.4630 - val_cindex_score: 0.8069\n","Epoch 34/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.5108 - cindex_score: 0.7913 - val_loss: 0.4648 - val_cindex_score: 0.8062\n","Epoch 35/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.5081 - cindex_score: 0.7883 - val_loss: 0.4761 - val_cindex_score: 0.8053\n","Epoch 36/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.4954 - cindex_score: 0.7906 - val_loss: 0.4614 - val_cindex_score: 0.8068\n","Epoch 37/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.4923 - cindex_score: 0.7921 - val_loss: 0.4552 - val_cindex_score: 0.8088\n","Epoch 38/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.4852 - cindex_score: 0.7933 - val_loss: 0.4491 - val_cindex_score: 0.8107\n","Epoch 39/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.4887 - cindex_score: 0.7946 - val_loss: 0.4584 - val_cindex_score: 0.8095\n","Epoch 40/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4993 - cindex_score: 0.7965 - val_loss: 0.4665 - val_cindex_score: 0.8171\n","Epoch 41/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.4825 - cindex_score: 0.7976 - val_loss: 0.4712 - val_cindex_score: 0.8191\n","Epoch 42/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.4706 - cindex_score: 0.8022 - val_loss: 0.4694 - val_cindex_score: 0.8084\n","Epoch 43/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.4832 - cindex_score: 0.8002 - val_loss: 0.4699 - val_cindex_score: 0.8108\n","Epoch 44/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.4661 - cindex_score: 0.8065 - val_loss: 0.4747 - val_cindex_score: 0.8081\n","Epoch 45/100\n","20036/20036 [==============================] - 2s 91us/step - loss: 0.4659 - cindex_score: 0.8047 - val_loss: 0.4479 - val_cindex_score: 0.8157\n","Epoch 46/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.4603 - cindex_score: 0.8065 - val_loss: 0.4987 - val_cindex_score: 0.8131\n","Epoch 47/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.4461 - cindex_score: 0.8095 - val_loss: 0.4888 - val_cindex_score: 0.8133\n","Epoch 48/100\n","20036/20036 [==============================] - 2s 91us/step - loss: 0.4573 - cindex_score: 0.8077 - val_loss: 0.5209 - val_cindex_score: 0.7935\n","Epoch 49/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.4512 - cindex_score: 0.8104 - val_loss: 0.5286 - val_cindex_score: 0.8114\n","Epoch 50/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.4418 - cindex_score: 0.8134 - val_loss: 0.4993 - val_cindex_score: 0.8091\n","Epoch 51/100\n","20036/20036 [==============================] - 2s 91us/step - loss: 0.4393 - cindex_score: 0.8147 - val_loss: 0.4683 - val_cindex_score: 0.8228\n","Epoch 52/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.4457 - cindex_score: 0.8111 - val_loss: 0.4446 - val_cindex_score: 0.8097\n","Epoch 53/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.4361 - cindex_score: 0.8132 - val_loss: 0.5174 - val_cindex_score: 0.7995\n","Epoch 54/100\n","20036/20036 [==============================] - 2s 91us/step - loss: 0.4297 - cindex_score: 0.8160 - val_loss: 0.4611 - val_cindex_score: 0.8184\n","Epoch 55/100\n","20036/20036 [==============================] - 2s 91us/step - loss: 0.4415 - cindex_score: 0.8123 - val_loss: 0.4666 - val_cindex_score: 0.8161\n","Epoch 56/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.4306 - cindex_score: 0.8146 - val_loss: 0.4548 - val_cindex_score: 0.8193\n","Epoch 57/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.4243 - cindex_score: 0.8188 - val_loss: 0.4842 - val_cindex_score: 0.8168\n","Epoch 58/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.4259 - cindex_score: 0.8173 - val_loss: 0.4534 - val_cindex_score: 0.8211\n","Epoch 59/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.4186 - cindex_score: 0.8179 - val_loss: 0.4952 - val_cindex_score: 0.8127\n","Epoch 60/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.4217 - cindex_score: 0.8179 - val_loss: 0.5040 - val_cindex_score: 0.8186\n","Epoch 61/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.4179 - cindex_score: 0.8191 - val_loss: 0.5328 - val_cindex_score: 0.8081\n","Epoch 62/100\n","20036/20036 [==============================] - 2s 97us/step - loss: 0.4250 - cindex_score: 0.8166 - val_loss: 0.4605 - val_cindex_score: 0.8299\n","Epoch 63/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.4081 - cindex_score: 0.8205 - val_loss: 0.4647 - val_cindex_score: 0.8284\n","Epoch 64/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.4113 - cindex_score: 0.8213 - val_loss: 0.4291 - val_cindex_score: 0.8301\n","Epoch 65/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.4036 - cindex_score: 0.8231 - val_loss: 0.4705 - val_cindex_score: 0.8251\n","Epoch 66/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.3963 - cindex_score: 0.8272 - val_loss: 0.5148 - val_cindex_score: 0.8239\n","Epoch 67/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.4117 - cindex_score: 0.8218 - val_loss: 0.4308 - val_cindex_score: 0.8275\n","Epoch 68/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.3935 - cindex_score: 0.8246 - val_loss: 0.4273 - val_cindex_score: 0.8339\n","Epoch 69/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.4005 - cindex_score: 0.8248 - val_loss: 0.4494 - val_cindex_score: 0.8370\n","Epoch 70/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.3905 - cindex_score: 0.8268 - val_loss: 0.4242 - val_cindex_score: 0.8374\n","Epoch 71/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.3866 - cindex_score: 0.8289 - val_loss: 0.5242 - val_cindex_score: 0.8311\n","Epoch 72/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.3968 - cindex_score: 0.8264 - val_loss: 0.4070 - val_cindex_score: 0.8389\n","Epoch 73/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.3984 - cindex_score: 0.8268 - val_loss: 0.4517 - val_cindex_score: 0.8352\n","Epoch 74/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.3845 - cindex_score: 0.8310 - val_loss: 0.4883 - val_cindex_score: 0.8316\n","Epoch 75/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.3807 - cindex_score: 0.8308 - val_loss: 0.4562 - val_cindex_score: 0.8341\n","Epoch 76/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.3901 - cindex_score: 0.8283 - val_loss: 0.4837 - val_cindex_score: 0.8176\n","Epoch 77/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.3850 - cindex_score: 0.8318 - val_loss: 0.3895 - val_cindex_score: 0.8373\n","Epoch 78/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.3733 - cindex_score: 0.8338 - val_loss: 0.4044 - val_cindex_score: 0.8381\n","Epoch 79/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.3843 - cindex_score: 0.8305 - val_loss: 0.4496 - val_cindex_score: 0.8201\n","Epoch 80/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.3920 - cindex_score: 0.8293 - val_loss: 0.4007 - val_cindex_score: 0.8330\n","Epoch 81/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.3775 - cindex_score: 0.8331 - val_loss: 0.3990 - val_cindex_score: 0.8390\n","Epoch 82/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.4001 - cindex_score: 0.8298 - val_loss: 0.4348 - val_cindex_score: 0.8244\n","Epoch 83/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.3888 - cindex_score: 0.8308 - val_loss: 0.4130 - val_cindex_score: 0.8363\n","Epoch 84/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.3732 - cindex_score: 0.8351 - val_loss: 0.3808 - val_cindex_score: 0.8415\n","Epoch 85/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.3681 - cindex_score: 0.8353 - val_loss: 0.4057 - val_cindex_score: 0.8382\n","Epoch 86/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.3801 - cindex_score: 0.8370 - val_loss: 0.4152 - val_cindex_score: 0.8291\n","Epoch 87/100\n","20036/20036 [==============================] - 2s 91us/step - loss: 0.3775 - cindex_score: 0.8347 - val_loss: 0.4981 - val_cindex_score: 0.8341\n","Epoch 88/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.3907 - cindex_score: 0.8328 - val_loss: 0.4122 - val_cindex_score: 0.8371\n","Epoch 89/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.3989 - cindex_score: 0.8304 - val_loss: 0.4953 - val_cindex_score: 0.8187\n","Epoch 90/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.3856 - cindex_score: 0.8316 - val_loss: 0.5661 - val_cindex_score: 0.7950\n","Epoch 91/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.3843 - cindex_score: 0.8331 - val_loss: 0.4825 - val_cindex_score: 0.8292\n","Epoch 92/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.3836 - cindex_score: 0.8345 - val_loss: 0.5335 - val_cindex_score: 0.8118\n","Epoch 93/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.3789 - cindex_score: 0.8344 - val_loss: 0.4979 - val_cindex_score: 0.8184\n","Epoch 94/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.3810 - cindex_score: 0.8325 - val_loss: 0.4885 - val_cindex_score: 0.8147\n","Epoch 95/100\n","20036/20036 [==============================] - 2s 91us/step - loss: 0.4028 - cindex_score: 0.8302 - val_loss: 0.4508 - val_cindex_score: 0.8185\n","Epoch 96/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.3831 - cindex_score: 0.8359 - val_loss: 0.4465 - val_cindex_score: 0.8170\n","Epoch 97/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.3672 - cindex_score: 0.8390 - val_loss: 0.5273 - val_cindex_score: 0.7998\n","Epoch 98/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.3719 - cindex_score: 0.8358 - val_loss: 0.4652 - val_cindex_score: 0.8135\n","Epoch 99/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.3604 - cindex_score: 0.8400 - val_loss: 0.4892 - val_cindex_score: 0.8096\n","Epoch 00099: early stopping\n","run_experiments.py:458: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:471: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:485: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","[[0, 0, 0, 0, 0]]\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            (None, 85)           0                                            \n","__________________________________________________________________________________________________\n","embedding_2 (Embedding)         (None, 85, 128)      8320        input_3[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_4 (Conv1D)               (None, 80, 32)       24608       embedding_2[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_5 (Conv1D)               (None, 75, 64)       12352       conv1d_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_6 (Conv1D)               (None, 70, 96)       36960       conv1d_5[0][0]                   \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            (None, 1200)         0                                            \n","__________________________________________________________________________________________________\n","global_max_pooling1d_2 (GlobalM (None, 96)           0           conv1d_6[0][0]                   \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 1)            1201        input_4[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 97)           0           global_max_pooling1d_2[0][0]     \n","                                                                 dense_6[0][0]                    \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 1024)         100352      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 1024)         0           dense_7[0][0]                    \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 1024)         1049600     dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 512)          524800      dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","dense_10 (Dense)                (None, 1)            513         dense_9[0][0]                    \n","==================================================================================================\n","Total params: 1,758,706\n","Trainable params: 1,758,706\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Train on 20036 samples, validate on 5010 samples\n","Epoch 1/100\n","20036/20036 [==============================] - 3s 127us/step - loss: 2.4487 - cindex_score: 0.5773 - val_loss: 0.7759 - val_cindex_score: 0.6701\n","Epoch 2/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.7323 - cindex_score: 0.6608 - val_loss: 0.6886 - val_cindex_score: 0.7195\n","Epoch 3/100\n","20036/20036 [==============================] - 2s 97us/step - loss: 0.7342 - cindex_score: 0.7037 - val_loss: 0.7357 - val_cindex_score: 0.7348\n","Epoch 4/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.7024 - cindex_score: 0.7274 - val_loss: 0.6865 - val_cindex_score: 0.7423\n","Epoch 5/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.6797 - cindex_score: 0.7300 - val_loss: 0.6712 - val_cindex_score: 0.7449\n","Epoch 6/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.6791 - cindex_score: 0.7352 - val_loss: 0.6492 - val_cindex_score: 0.7470\n","Epoch 7/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.6612 - cindex_score: 0.7417 - val_loss: 0.6495 - val_cindex_score: 0.7450\n","Epoch 8/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.6757 - cindex_score: 0.7422 - val_loss: 0.6874 - val_cindex_score: 0.7450\n","Epoch 9/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.6810 - cindex_score: 0.7459 - val_loss: 0.7403 - val_cindex_score: 0.7489\n","Epoch 10/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.6808 - cindex_score: 0.7463 - val_loss: 0.7139 - val_cindex_score: 0.7464\n","Epoch 11/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.6535 - cindex_score: 0.7479 - val_loss: 0.7000 - val_cindex_score: 0.7516\n","Epoch 12/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.6461 - cindex_score: 0.7524 - val_loss: 0.6563 - val_cindex_score: 0.7528\n","Epoch 13/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.6270 - cindex_score: 0.7557 - val_loss: 0.7000 - val_cindex_score: 0.7547\n","Epoch 14/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.6277 - cindex_score: 0.7552 - val_loss: 0.6800 - val_cindex_score: 0.7415\n","Epoch 15/100\n","20036/20036 [==============================] - 2s 97us/step - loss: 0.6234 - cindex_score: 0.7560 - val_loss: 0.6419 - val_cindex_score: 0.7497\n","Epoch 16/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.6089 - cindex_score: 0.7606 - val_loss: 0.6843 - val_cindex_score: 0.7471\n","Epoch 17/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.6059 - cindex_score: 0.7651 - val_loss: 0.6410 - val_cindex_score: 0.7617\n","Epoch 18/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.5957 - cindex_score: 0.7657 - val_loss: 0.6139 - val_cindex_score: 0.7689\n","Epoch 19/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.5844 - cindex_score: 0.7724 - val_loss: 0.6241 - val_cindex_score: 0.7574\n","Epoch 20/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.5883 - cindex_score: 0.7691 - val_loss: 0.6219 - val_cindex_score: 0.7732\n","Epoch 21/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.5907 - cindex_score: 0.7728 - val_loss: 0.5963 - val_cindex_score: 0.7785\n","Epoch 22/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.5680 - cindex_score: 0.7748 - val_loss: 0.5998 - val_cindex_score: 0.7631\n","Epoch 23/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.5648 - cindex_score: 0.7759 - val_loss: 0.5975 - val_cindex_score: 0.7657\n","Epoch 24/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.5616 - cindex_score: 0.7800 - val_loss: 0.5780 - val_cindex_score: 0.7681\n","Epoch 25/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.5615 - cindex_score: 0.7746 - val_loss: 0.5711 - val_cindex_score: 0.7822\n","Epoch 26/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.5488 - cindex_score: 0.7802 - val_loss: 0.5490 - val_cindex_score: 0.7867\n","Epoch 27/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.5461 - cindex_score: 0.7827 - val_loss: 0.5582 - val_cindex_score: 0.7804\n","Epoch 28/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.5467 - cindex_score: 0.7839 - val_loss: 0.5514 - val_cindex_score: 0.7840\n","Epoch 29/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.5452 - cindex_score: 0.7805 - val_loss: 0.5575 - val_cindex_score: 0.7815\n","Epoch 30/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.5377 - cindex_score: 0.7848 - val_loss: 0.5718 - val_cindex_score: 0.7814\n","Epoch 31/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.5304 - cindex_score: 0.7876 - val_loss: 0.5422 - val_cindex_score: 0.7844\n","Epoch 32/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.5311 - cindex_score: 0.7865 - val_loss: 0.5733 - val_cindex_score: 0.7757\n","Epoch 33/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.5317 - cindex_score: 0.7868 - val_loss: 0.5806 - val_cindex_score: 0.7781\n","Epoch 34/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.5202 - cindex_score: 0.7882 - val_loss: 0.5365 - val_cindex_score: 0.7895\n","Epoch 35/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.5204 - cindex_score: 0.7893 - val_loss: 0.6322 - val_cindex_score: 0.7564\n","Epoch 36/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.5338 - cindex_score: 0.7859 - val_loss: 0.5350 - val_cindex_score: 0.7865\n","Epoch 37/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.4990 - cindex_score: 0.7956 - val_loss: 0.5099 - val_cindex_score: 0.8023\n","Epoch 38/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4989 - cindex_score: 0.7946 - val_loss: 0.5191 - val_cindex_score: 0.8080\n","Epoch 39/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.5016 - cindex_score: 0.7948 - val_loss: 0.5584 - val_cindex_score: 0.7754\n","Epoch 40/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.4991 - cindex_score: 0.7953 - val_loss: 0.5595 - val_cindex_score: 0.7855\n","Epoch 41/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.5226 - cindex_score: 0.7886 - val_loss: 0.5400 - val_cindex_score: 0.7950\n","Epoch 42/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.5020 - cindex_score: 0.7937 - val_loss: 0.4868 - val_cindex_score: 0.8125\n","Epoch 43/100\n","20036/20036 [==============================] - 2s 92us/step - loss: 0.4846 - cindex_score: 0.7974 - val_loss: 0.5378 - val_cindex_score: 0.7972\n","Epoch 44/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.4867 - cindex_score: 0.7969 - val_loss: 0.5175 - val_cindex_score: 0.7962\n","Epoch 45/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4757 - cindex_score: 0.8018 - val_loss: 0.5189 - val_cindex_score: 0.8019\n","Epoch 46/100\n","20036/20036 [==============================] - 2s 98us/step - loss: 0.4858 - cindex_score: 0.7987 - val_loss: 0.4921 - val_cindex_score: 0.8103\n","Epoch 47/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.5044 - cindex_score: 0.7891 - val_loss: 0.4843 - val_cindex_score: 0.8115\n","Epoch 48/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4621 - cindex_score: 0.8057 - val_loss: 0.5252 - val_cindex_score: 0.8014\n","Epoch 49/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4761 - cindex_score: 0.8001 - val_loss: 0.5171 - val_cindex_score: 0.7966\n","Epoch 50/100\n","20036/20036 [==============================] - 2s 97us/step - loss: 0.4808 - cindex_score: 0.7999 - val_loss: 0.4878 - val_cindex_score: 0.8086\n","Epoch 51/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.4627 - cindex_score: 0.8038 - val_loss: 0.5263 - val_cindex_score: 0.7977\n","Epoch 52/100\n","20036/20036 [==============================] - 2s 97us/step - loss: 0.4598 - cindex_score: 0.8064 - val_loss: 0.5086 - val_cindex_score: 0.8042\n","Epoch 53/100\n","20036/20036 [==============================] - 2s 98us/step - loss: 0.4677 - cindex_score: 0.8033 - val_loss: 0.4953 - val_cindex_score: 0.8067\n","Epoch 54/100\n","20036/20036 [==============================] - 2s 97us/step - loss: 0.4766 - cindex_score: 0.7993 - val_loss: 0.4793 - val_cindex_score: 0.8110\n","Epoch 55/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.4858 - cindex_score: 0.7986 - val_loss: 0.4770 - val_cindex_score: 0.8174\n","Epoch 56/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.4599 - cindex_score: 0.8058 - val_loss: 0.4848 - val_cindex_score: 0.8089\n","Epoch 57/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.4600 - cindex_score: 0.8044 - val_loss: 0.4760 - val_cindex_score: 0.8092\n","Epoch 58/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4683 - cindex_score: 0.8001 - val_loss: 0.4731 - val_cindex_score: 0.8153\n","Epoch 59/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.4695 - cindex_score: 0.8009 - val_loss: 0.4781 - val_cindex_score: 0.8140\n","Epoch 60/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4669 - cindex_score: 0.8037 - val_loss: 0.4838 - val_cindex_score: 0.8102\n","Epoch 61/100\n","20036/20036 [==============================] - 2s 97us/step - loss: 0.4755 - cindex_score: 0.7980 - val_loss: 0.4926 - val_cindex_score: 0.8093\n","Epoch 62/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.4741 - cindex_score: 0.8009 - val_loss: 0.4894 - val_cindex_score: 0.8090\n","Epoch 63/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4757 - cindex_score: 0.8011 - val_loss: 0.4725 - val_cindex_score: 0.8104\n","Epoch 64/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.4614 - cindex_score: 0.8033 - val_loss: 0.4741 - val_cindex_score: 0.8129\n","Epoch 65/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.4585 - cindex_score: 0.8059 - val_loss: 0.4671 - val_cindex_score: 0.8111\n","Epoch 66/100\n","20036/20036 [==============================] - 2s 97us/step - loss: 0.4515 - cindex_score: 0.8095 - val_loss: 0.4668 - val_cindex_score: 0.8162\n","Epoch 67/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.4428 - cindex_score: 0.8068 - val_loss: 0.4673 - val_cindex_score: 0.8124\n","Epoch 68/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.4490 - cindex_score: 0.8068 - val_loss: 0.4608 - val_cindex_score: 0.8173\n","Epoch 69/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.4535 - cindex_score: 0.8045 - val_loss: 0.4722 - val_cindex_score: 0.8157\n","Epoch 70/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4645 - cindex_score: 0.8030 - val_loss: 0.4735 - val_cindex_score: 0.8098\n","Epoch 71/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4663 - cindex_score: 0.8043 - val_loss: 0.4714 - val_cindex_score: 0.8122\n","Epoch 72/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.4423 - cindex_score: 0.8105 - val_loss: 0.4584 - val_cindex_score: 0.8137\n","Epoch 73/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4461 - cindex_score: 0.8097 - val_loss: 0.4768 - val_cindex_score: 0.8164\n","Epoch 74/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.4404 - cindex_score: 0.8087 - val_loss: 0.4745 - val_cindex_score: 0.8153\n","Epoch 75/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.4416 - cindex_score: 0.8097 - val_loss: 0.4616 - val_cindex_score: 0.8132\n","Epoch 76/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4538 - cindex_score: 0.8043 - val_loss: 0.4948 - val_cindex_score: 0.8101\n","Epoch 77/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.4621 - cindex_score: 0.8033 - val_loss: 0.4981 - val_cindex_score: 0.8031\n","Epoch 78/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4641 - cindex_score: 0.8064 - val_loss: 0.4906 - val_cindex_score: 0.8005\n","Epoch 79/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4477 - cindex_score: 0.8068 - val_loss: 0.4554 - val_cindex_score: 0.8111\n","Epoch 80/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.4233 - cindex_score: 0.8175 - val_loss: 0.4972 - val_cindex_score: 0.8129\n","Epoch 81/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.4169 - cindex_score: 0.8156 - val_loss: 0.5017 - val_cindex_score: 0.8144\n","Epoch 82/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4264 - cindex_score: 0.8110 - val_loss: 0.4794 - val_cindex_score: 0.8142\n","Epoch 83/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4162 - cindex_score: 0.8188 - val_loss: 0.5382 - val_cindex_score: 0.8183\n","Epoch 84/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4124 - cindex_score: 0.8157 - val_loss: 0.4661 - val_cindex_score: 0.8157\n","Epoch 85/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4174 - cindex_score: 0.8152 - val_loss: 0.5137 - val_cindex_score: 0.8127\n","Epoch 86/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4234 - cindex_score: 0.8139 - val_loss: 0.4733 - val_cindex_score: 0.8130\n","Epoch 87/100\n","20036/20036 [==============================] - 2s 94us/step - loss: 0.4178 - cindex_score: 0.8149 - val_loss: 0.5085 - val_cindex_score: 0.8120\n","Epoch 88/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.4395 - cindex_score: 0.8069 - val_loss: 0.5009 - val_cindex_score: 0.8187\n","Epoch 89/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4330 - cindex_score: 0.8104 - val_loss: 0.4989 - val_cindex_score: 0.8183\n","Epoch 90/100\n","20036/20036 [==============================] - 2s 93us/step - loss: 0.4342 - cindex_score: 0.8102 - val_loss: 0.4677 - val_cindex_score: 0.8151\n","Epoch 91/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4317 - cindex_score: 0.8118 - val_loss: 0.4627 - val_cindex_score: 0.8112\n","Epoch 92/100\n","20036/20036 [==============================] - 2s 97us/step - loss: 0.4357 - cindex_score: 0.8125 - val_loss: 0.4524 - val_cindex_score: 0.8164\n","Epoch 93/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.4493 - cindex_score: 0.8057 - val_loss: 0.5491 - val_cindex_score: 0.7900\n","Epoch 94/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4259 - cindex_score: 0.8162 - val_loss: 0.4809 - val_cindex_score: 0.8157\n","Epoch 95/100\n","20036/20036 [==============================] - 2s 95us/step - loss: 0.4107 - cindex_score: 0.8141 - val_loss: 0.4798 - val_cindex_score: 0.8132\n","Epoch 96/100\n","20036/20036 [==============================] - 2s 96us/step - loss: 0.4020 - cindex_score: 0.8163 - val_loss: 0.4906 - val_cindex_score: 0.8102\n","Epoch 97/100\n","20036/20036 [==============================] - 2s 97us/step - loss: 0.4064 - cindex_score: 0.8146 - val_loss: 0.5089 - val_cindex_score: 0.8111\n","Epoch 98/100\n","20036/20036 [==============================] - 2s 97us/step - loss: 0.4205 - cindex_score: 0.8112 - val_loss: 0.5364 - val_cindex_score: 0.8120\n","Epoch 99/100\n","20036/20036 [==============================] - 2s 97us/step - loss: 0.4229 - cindex_score: 0.8120 - val_loss: 0.5263 - val_cindex_score: 0.8143\n","Epoch 100/100\n","20036/20036 [==============================] - 2s 97us/step - loss: 0.4329 - cindex_score: 0.8102 - val_loss: 0.4618 - val_cindex_score: 0.8205\n","run_experiments.py:458: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:471: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:485: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n"]}]},{"cell_type":"markdown","source":["### KIBA"],"metadata":{"id":"Yfe0QDyDSGfT"}},{"cell_type":"code","source":["!./go.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NSszBNB9QZZD","executionInfo":{"status":"ok","timestamp":1651588380027,"user_tz":300,"elapsed":1380058,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"}},"outputId":"099ea354-5874-48e0-ad10-74232edabafb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From run_experiments.py:16: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","Using TensorFlow backend.\n","WARNING:tensorflow:From run_experiments.py:19: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","2022-05-03 14:10:01.470695: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n","2022-05-03 14:10:01.470839: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x32af2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2022-05-03 14:10:01.470871: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2022-05-03 14:10:01.472563: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2022-05-03 14:10:01.701925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 14:10:01.702681: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x32af640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2022-05-03 14:10:01.702714: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2022-05-03 14:10:01.702925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 14:10:01.703464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2022-05-03 14:10:01.703763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-05-03 14:10:01.705348: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-05-03 14:10:01.706244: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2022-05-03 14:10:01.706558: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2022-05-03 14:10:01.708174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2022-05-03 14:10:01.708843: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2022-05-03 14:10:01.712004: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-05-03 14:10:01.712120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 14:10:01.712689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 14:10:01.713198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2022-05-03 14:10:01.713252: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-05-03 14:10:01.714221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-05-03 14:10:01.714246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2022-05-03 14:10:01.714257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2022-05-03 14:10:01.714362: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 14:10:01.714921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 14:10:01.715435: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-05-03 14:10:01.715474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","Read data/kiba/ start\n","2111\n","229\n","logs/1651587002.3914814/\n","Reading data/kiba/ start\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","[[0, 0, 0, 0, 0]]\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From run_experiments.py:435: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n","\n","WARNING:tensorflow:From run_experiments.py:440: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 100, 128)     8320        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_1 (Conv1D)               (None, 95, 32)       24608       embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_2 (Conv1D)               (None, 90, 64)       12352       conv1d_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_3 (Conv1D)               (None, 85, 96)       36960       conv1d_2[0][0]                   \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","global_max_pooling1d_1 (GlobalM (None, 96)           0           conv1d_3[0][0]                   \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1)            1001        input_2[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 97)           0           global_max_pooling1d_1[0][0]     \n","                                                                 dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1024)         100352      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 1024)         1049600     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 1024)         0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 512)          524800      dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 1)            513         dense_4[0][0]                    \n","==================================================================================================\n","Total params: 1,758,506\n","Trainable params: 1,758,506\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 78836 samples, validate on 19709 samples\n","Epoch 1/100\n","2022-05-03 14:10:05.702106: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-05-03 14:10:05.959247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","78836/78836 [==============================] - 8s 95us/step - loss: 2.8222 - cindex_score: 0.5652 - val_loss: 0.7227 - val_cindex_score: 0.6364\n","Epoch 2/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.7307 - cindex_score: 0.6089 - val_loss: 0.6519 - val_cindex_score: 0.6597\n","Epoch 3/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.6667 - cindex_score: 0.6313 - val_loss: 0.9208 - val_cindex_score: 0.6735\n","Epoch 4/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.6578 - cindex_score: 0.6441 - val_loss: 0.6219 - val_cindex_score: 0.6854\n","Epoch 5/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.6165 - cindex_score: 0.6571 - val_loss: 0.8469 - val_cindex_score: 0.6925\n","Epoch 6/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.6100 - cindex_score: 0.6643 - val_loss: 0.8081 - val_cindex_score: 0.6948\n","Epoch 7/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.5951 - cindex_score: 0.6711 - val_loss: 0.5125 - val_cindex_score: 0.7026\n","Epoch 8/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.5752 - cindex_score: 0.6770 - val_loss: 0.4739 - val_cindex_score: 0.7058\n","Epoch 9/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.5727 - cindex_score: 0.6812 - val_loss: 0.6852 - val_cindex_score: 0.7068\n","Epoch 10/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.5461 - cindex_score: 0.6860 - val_loss: 0.5541 - val_cindex_score: 0.7048\n","Epoch 11/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.5316 - cindex_score: 0.6889 - val_loss: 0.4991 - val_cindex_score: 0.7135\n","Epoch 12/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.5129 - cindex_score: 0.6952 - val_loss: 0.5703 - val_cindex_score: 0.7158\n","Epoch 13/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.5223 - cindex_score: 0.6975 - val_loss: 0.6539 - val_cindex_score: 0.7265\n","Epoch 14/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4996 - cindex_score: 0.7039 - val_loss: 0.5849 - val_cindex_score: 0.7424\n","Epoch 15/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4739 - cindex_score: 0.7156 - val_loss: 0.8303 - val_cindex_score: 0.7478\n","Epoch 16/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.4750 - cindex_score: 0.7192 - val_loss: 0.6747 - val_cindex_score: 0.7521\n","Epoch 17/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.4629 - cindex_score: 0.7232 - val_loss: 0.7406 - val_cindex_score: 0.7517\n","Epoch 18/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.4611 - cindex_score: 0.7232 - val_loss: 0.8680 - val_cindex_score: 0.7381\n","Epoch 19/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.4482 - cindex_score: 0.7271 - val_loss: 0.8200 - val_cindex_score: 0.7432\n","Epoch 20/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.4357 - cindex_score: 0.7332 - val_loss: 1.0617 - val_cindex_score: 0.7516\n","Epoch 21/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.4281 - cindex_score: 0.7334 - val_loss: 0.8851 - val_cindex_score: 0.7553\n","Epoch 22/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.4244 - cindex_score: 0.7346 - val_loss: 1.4410 - val_cindex_score: 0.7439\n","Epoch 23/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4259 - cindex_score: 0.7374 - val_loss: 1.2547 - val_cindex_score: 0.7551\n","Epoch 00023: early stopping\n","run_experiments.py:456: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:469: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:483: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","[[0, 0, 0, 0, 0]]\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","embedding_2 (Embedding)         (None, 100, 128)     8320        input_3[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_4 (Conv1D)               (None, 95, 32)       24608       embedding_2[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_5 (Conv1D)               (None, 90, 64)       12352       conv1d_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_6 (Conv1D)               (None, 85, 96)       36960       conv1d_5[0][0]                   \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","global_max_pooling1d_2 (GlobalM (None, 96)           0           conv1d_6[0][0]                   \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 1)            1001        input_4[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 97)           0           global_max_pooling1d_2[0][0]     \n","                                                                 dense_6[0][0]                    \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 1024)         100352      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 1024)         0           dense_7[0][0]                    \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 1024)         1049600     dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 512)          524800      dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","dense_10 (Dense)                (None, 1)            513         dense_9[0][0]                    \n","==================================================================================================\n","Total params: 1,758,506\n","Trainable params: 1,758,506\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Train on 78836 samples, validate on 19709 samples\n","Epoch 1/100\n","78836/78836 [==============================] - 4s 50us/step - loss: 3.3982 - cindex_score: 0.5536 - val_loss: 0.7195 - val_cindex_score: 0.6184\n","Epoch 2/100\n","78836/78836 [==============================] - 4s 44us/step - loss: 0.7370 - cindex_score: 0.5938 - val_loss: 0.7987 - val_cindex_score: 0.6401\n","Epoch 3/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.6896 - cindex_score: 0.6155 - val_loss: 0.6493 - val_cindex_score: 0.6545\n","Epoch 4/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.6985 - cindex_score: 0.6306 - val_loss: 0.5242 - val_cindex_score: 0.6665\n","Epoch 5/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.6483 - cindex_score: 0.6434 - val_loss: 0.5735 - val_cindex_score: 0.6772\n","Epoch 6/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.6094 - cindex_score: 0.6562 - val_loss: 0.5172 - val_cindex_score: 0.6904\n","Epoch 7/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.6256 - cindex_score: 0.6660 - val_loss: 0.4686 - val_cindex_score: 0.6971\n","Epoch 8/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.5656 - cindex_score: 0.6798 - val_loss: 0.4400 - val_cindex_score: 0.7145\n","Epoch 9/100\n","78836/78836 [==============================] - 4s 46us/step - loss: 0.5433 - cindex_score: 0.6931 - val_loss: 0.5397 - val_cindex_score: 0.7280\n","Epoch 10/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.5438 - cindex_score: 0.7021 - val_loss: 0.4228 - val_cindex_score: 0.7265\n","Epoch 11/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.5294 - cindex_score: 0.7096 - val_loss: 0.4110 - val_cindex_score: 0.7388\n","Epoch 12/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.5147 - cindex_score: 0.7151 - val_loss: 0.4086 - val_cindex_score: 0.7368\n","Epoch 13/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.5005 - cindex_score: 0.7187 - val_loss: 0.4224 - val_cindex_score: 0.7419\n","Epoch 14/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.5233 - cindex_score: 0.7195 - val_loss: 0.6534 - val_cindex_score: 0.7460\n","Epoch 15/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.5042 - cindex_score: 0.7201 - val_loss: 0.5208 - val_cindex_score: 0.7460\n","Epoch 16/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.5108 - cindex_score: 0.7188 - val_loss: 0.5217 - val_cindex_score: 0.7365\n","Epoch 17/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.4975 - cindex_score: 0.7203 - val_loss: 0.4530 - val_cindex_score: 0.7436\n","Epoch 18/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.4841 - cindex_score: 0.7234 - val_loss: 0.4592 - val_cindex_score: 0.7472\n","Epoch 19/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.4874 - cindex_score: 0.7219 - val_loss: 0.5005 - val_cindex_score: 0.7323\n","Epoch 20/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.4856 - cindex_score: 0.7217 - val_loss: 0.4314 - val_cindex_score: 0.7452\n","Epoch 21/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.4826 - cindex_score: 0.7191 - val_loss: 0.5413 - val_cindex_score: 0.7374\n","Epoch 22/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.4865 - cindex_score: 0.7198 - val_loss: 0.3901 - val_cindex_score: 0.7473\n","Epoch 23/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.4627 - cindex_score: 0.7250 - val_loss: 0.4796 - val_cindex_score: 0.7492\n","Epoch 24/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.4703 - cindex_score: 0.7206 - val_loss: 0.4023 - val_cindex_score: 0.7415\n","Epoch 25/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.4581 - cindex_score: 0.7244 - val_loss: 0.3993 - val_cindex_score: 0.7557\n","Epoch 26/100\n","78836/78836 [==============================] - 4s 46us/step - loss: 0.4534 - cindex_score: 0.7290 - val_loss: 0.4022 - val_cindex_score: 0.7398\n","Epoch 27/100\n","78836/78836 [==============================] - 4s 46us/step - loss: 0.4396 - cindex_score: 0.7307 - val_loss: 0.4717 - val_cindex_score: 0.7548\n","Epoch 28/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.4317 - cindex_score: 0.7341 - val_loss: 0.5586 - val_cindex_score: 0.7528\n","Epoch 29/100\n","78836/78836 [==============================] - 4s 46us/step - loss: 0.4126 - cindex_score: 0.7395 - val_loss: 0.7174 - val_cindex_score: 0.7572\n","Epoch 30/100\n","78836/78836 [==============================] - 4s 46us/step - loss: 0.4238 - cindex_score: 0.7367 - val_loss: 0.6874 - val_cindex_score: 0.7552\n","Epoch 31/100\n","78836/78836 [==============================] - 4s 46us/step - loss: 0.4156 - cindex_score: 0.7371 - val_loss: 0.7789 - val_cindex_score: 0.7465\n","Epoch 32/100\n","78836/78836 [==============================] - 4s 46us/step - loss: 0.4113 - cindex_score: 0.7374 - val_loss: 1.0126 - val_cindex_score: 0.7518\n","Epoch 33/100\n","78836/78836 [==============================] - 4s 46us/step - loss: 0.4099 - cindex_score: 0.7410 - val_loss: 0.9769 - val_cindex_score: 0.7347\n","Epoch 34/100\n","78836/78836 [==============================] - 4s 46us/step - loss: 0.4060 - cindex_score: 0.7419 - val_loss: 0.8424 - val_cindex_score: 0.7509\n","Epoch 35/100\n","78836/78836 [==============================] - 4s 46us/step - loss: 0.4065 - cindex_score: 0.7411 - val_loss: 0.8652 - val_cindex_score: 0.7562\n","Epoch 36/100\n","78836/78836 [==============================] - 4s 46us/step - loss: 0.4111 - cindex_score: 0.7381 - val_loss: 1.0220 - val_cindex_score: 0.7494\n","Epoch 37/100\n","78836/78836 [==============================] - 4s 46us/step - loss: 0.4020 - cindex_score: 0.7413 - val_loss: 0.9817 - val_cindex_score: 0.7568\n","Epoch 00037: early stopping\n","run_experiments.py:456: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:469: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:483: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n"]}]},{"cell_type":"markdown","metadata":{"id":"nkNZwVYdM-hC"},"source":["## Combined"]},{"cell_type":"markdown","source":["### Davis"],"metadata":{"id":"cAMQHFKsFkVR"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1226331,"status":"ok","timestamp":1650125935278,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"},"user_tz":300},"id":"sew1uA20xB5Q","outputId":"264209b3-4f41-472a-d1b1-da425c148057"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From run_experiments.py:16: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","Using TensorFlow backend.\n","WARNING:tensorflow:From run_experiments.py:19: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","2022-04-16 15:45:53.653761: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2022-04-16 15:45:53.654001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563ecd5412c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2022-04-16 15:45:53.654037: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2022-04-16 15:45:53.655709: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2022-04-16 15:45:53.783313: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 15:45:53.784161: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563ecd541800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2022-04-16 15:45:53.784228: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n","2022-04-16 15:45:53.784432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 15:45:53.785238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2022-04-16 15:45:53.785579: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-04-16 15:45:53.787529: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-04-16 15:45:53.788670: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2022-04-16 15:45:53.789042: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2022-04-16 15:45:53.790936: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2022-04-16 15:45:53.792128: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2022-04-16 15:45:53.795843: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-16 15:45:53.795993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 15:45:53.796757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 15:45:53.797525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2022-04-16 15:45:53.797600: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-04-16 15:45:53.798812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-16 15:45:53.798844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2022-04-16 15:45:53.798862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2022-04-16 15:45:53.799002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 15:45:53.799796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 15:45:53.800502: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-04-16 15:45:53.800558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","Read data/davis/ start\n","68\n","442\n","logs/1650123954.7126462/\n","Reading data/davis/ start\n","val set 5010\n","train set 20036\n","val set 5009\n","train set 20037\n","val set 5009\n","train set 20037\n","val set 5009\n","train set 20037\n","val set 5009\n","train set 20037\n","[[0, 0, 0, 0, 0]]\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From run_experiments.py:432: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n","\n","WARNING:tensorflow:From run_experiments.py:437: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 100, 128)     8320        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_2 (Embedding)         (None, 1000, 128)    3328        input_2[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_1 (Conv1D)               (None, 95, 32)       24608       embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_4 (Conv1D)               (None, 993, 32)      32800       embedding_2[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_2 (Conv1D)               (None, 90, 64)       12352       conv1d_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_5 (Conv1D)               (None, 986, 64)      16448       conv1d_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_3 (Conv1D)               (None, 85, 96)       36960       conv1d_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_6 (Conv1D)               (None, 979, 96)      49248       conv1d_5[0][0]                   \n","__________________________________________________________________________________________________\n","global_max_pooling1d_1 (GlobalM (None, 96)           0           conv1d_3[0][0]                   \n","__________________________________________________________________________________________________\n","global_max_pooling1d_2 (GlobalM (None, 96)           0           conv1d_6[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 192)          0           global_max_pooling1d_1[0][0]     \n","                                                                 global_max_pooling1d_2[0][0]     \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1024)         197632      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1024)         1049600     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 512)          524800      dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 1)            513         dense_3[0][0]                    \n","==================================================================================================\n","Total params: 1,956,609\n","Trainable params: 1,956,609\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 20036 samples, validate on 5010 samples\n","Epoch 1/100\n","2022-04-16 15:45:57.864262: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-04-16 15:45:58.022152: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","20036/20036 [==============================] - 17s 828us/step - loss: 2.4771 - cindex_score: 0.6596 - val_loss: 0.6304 - val_cindex_score: 0.7573\n","Epoch 2/100\n","20036/20036 [==============================] - 13s 630us/step - loss: 0.6163 - cindex_score: 0.7567 - val_loss: 0.5842 - val_cindex_score: 0.7844\n","Epoch 3/100\n","20036/20036 [==============================] - 13s 628us/step - loss: 0.5796 - cindex_score: 0.7757 - val_loss: 0.6169 - val_cindex_score: 0.7938\n","Epoch 4/100\n","20036/20036 [==============================] - 13s 627us/step - loss: 0.5682 - cindex_score: 0.7830 - val_loss: 0.6020 - val_cindex_score: 0.7965\n","Epoch 5/100\n","20036/20036 [==============================] - 13s 626us/step - loss: 0.5617 - cindex_score: 0.7880 - val_loss: 0.5494 - val_cindex_score: 0.7980\n","Epoch 6/100\n","20036/20036 [==============================] - 13s 625us/step - loss: 0.5668 - cindex_score: 0.7878 - val_loss: 0.5737 - val_cindex_score: 0.7982\n","Epoch 7/100\n","20036/20036 [==============================] - 13s 625us/step - loss: 0.5620 - cindex_score: 0.7902 - val_loss: 0.5369 - val_cindex_score: 0.7992\n","Epoch 8/100\n","20036/20036 [==============================] - 13s 626us/step - loss: 0.5658 - cindex_score: 0.7892 - val_loss: 0.5415 - val_cindex_score: 0.8009\n","Epoch 9/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.5643 - cindex_score: 0.7919 - val_loss: 0.5391 - val_cindex_score: 0.8011\n","Epoch 10/100\n","20036/20036 [==============================] - 13s 624us/step - loss: 0.5597 - cindex_score: 0.7937 - val_loss: 0.5338 - val_cindex_score: 0.8028\n","Epoch 11/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.5527 - cindex_score: 0.7958 - val_loss: 0.5218 - val_cindex_score: 0.8033\n","Epoch 12/100\n","20036/20036 [==============================] - 13s 625us/step - loss: 0.5367 - cindex_score: 0.8013 - val_loss: 0.4901 - val_cindex_score: 0.8167\n","Epoch 13/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.5212 - cindex_score: 0.8063 - val_loss: 0.4742 - val_cindex_score: 0.8219\n","Epoch 14/100\n","20036/20036 [==============================] - 13s 625us/step - loss: 0.5090 - cindex_score: 0.8079 - val_loss: 0.4667 - val_cindex_score: 0.8255\n","Epoch 15/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.5059 - cindex_score: 0.8124 - val_loss: 0.4633 - val_cindex_score: 0.8266\n","Epoch 16/100\n","20036/20036 [==============================] - 12s 624us/step - loss: 0.4942 - cindex_score: 0.8164 - val_loss: 0.4816 - val_cindex_score: 0.8319\n","Epoch 17/100\n","20036/20036 [==============================] - 12s 623us/step - loss: 0.4771 - cindex_score: 0.8216 - val_loss: 0.4617 - val_cindex_score: 0.8281\n","Epoch 18/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.4718 - cindex_score: 0.8204 - val_loss: 0.4603 - val_cindex_score: 0.8314\n","Epoch 19/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.4667 - cindex_score: 0.8251 - val_loss: 0.4450 - val_cindex_score: 0.8349\n","Epoch 20/100\n","20036/20036 [==============================] - 13s 624us/step - loss: 0.4449 - cindex_score: 0.8280 - val_loss: 0.4108 - val_cindex_score: 0.8403\n","Epoch 21/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.4161 - cindex_score: 0.8315 - val_loss: 0.3967 - val_cindex_score: 0.8447\n","Epoch 22/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.3921 - cindex_score: 0.8365 - val_loss: 0.3798 - val_cindex_score: 0.8472\n","Epoch 23/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.3788 - cindex_score: 0.8428 - val_loss: 0.3836 - val_cindex_score: 0.8465\n","Epoch 24/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.3685 - cindex_score: 0.8427 - val_loss: 0.3824 - val_cindex_score: 0.8546\n","Epoch 25/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.3568 - cindex_score: 0.8474 - val_loss: 0.3624 - val_cindex_score: 0.8535\n","Epoch 26/100\n","20036/20036 [==============================] - 12s 623us/step - loss: 0.3532 - cindex_score: 0.8527 - val_loss: 0.3489 - val_cindex_score: 0.8587\n","Epoch 27/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.3428 - cindex_score: 0.8527 - val_loss: 0.3905 - val_cindex_score: 0.8575\n","Epoch 28/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.3302 - cindex_score: 0.8569 - val_loss: 0.3454 - val_cindex_score: 0.8634\n","Epoch 29/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.3220 - cindex_score: 0.8598 - val_loss: 0.3335 - val_cindex_score: 0.8613\n","Epoch 30/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.3154 - cindex_score: 0.8621 - val_loss: 0.3253 - val_cindex_score: 0.8591\n","Epoch 31/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.3027 - cindex_score: 0.8647 - val_loss: 0.3308 - val_cindex_score: 0.8593\n","Epoch 32/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.2982 - cindex_score: 0.8648 - val_loss: 0.3144 - val_cindex_score: 0.8633\n","Epoch 33/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.2920 - cindex_score: 0.8674 - val_loss: 0.3241 - val_cindex_score: 0.8606\n","Epoch 34/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.2911 - cindex_score: 0.8692 - val_loss: 0.3136 - val_cindex_score: 0.8677\n","Epoch 35/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.2778 - cindex_score: 0.8713 - val_loss: 0.3763 - val_cindex_score: 0.8658\n","Epoch 36/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.2749 - cindex_score: 0.8718 - val_loss: 0.3756 - val_cindex_score: 0.8624\n","Epoch 37/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.2641 - cindex_score: 0.8753 - val_loss: 0.3364 - val_cindex_score: 0.8639\n","Epoch 38/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.2531 - cindex_score: 0.8766 - val_loss: 0.3263 - val_cindex_score: 0.8675\n","Epoch 39/100\n","20036/20036 [==============================] - 12s 617us/step - loss: 0.2406 - cindex_score: 0.8774 - val_loss: 0.3396 - val_cindex_score: 0.8693\n","Epoch 40/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.2385 - cindex_score: 0.8824 - val_loss: 0.3659 - val_cindex_score: 0.8693\n","Epoch 41/100\n","20036/20036 [==============================] - 12s 617us/step - loss: 0.2304 - cindex_score: 0.8830 - val_loss: 0.3232 - val_cindex_score: 0.8685\n","Epoch 42/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.2275 - cindex_score: 0.8819 - val_loss: 0.3206 - val_cindex_score: 0.8675\n","Epoch 43/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.2242 - cindex_score: 0.8822 - val_loss: 0.3669 - val_cindex_score: 0.8704\n","Epoch 44/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.2135 - cindex_score: 0.8873 - val_loss: 0.3014 - val_cindex_score: 0.8716\n","Epoch 45/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.2018 - cindex_score: 0.8879 - val_loss: 0.3174 - val_cindex_score: 0.8688\n","Epoch 46/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.1988 - cindex_score: 0.8906 - val_loss: 0.2927 - val_cindex_score: 0.8670\n","Epoch 47/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1942 - cindex_score: 0.8911 - val_loss: 0.2822 - val_cindex_score: 0.8684\n","Epoch 48/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1855 - cindex_score: 0.8917 - val_loss: 0.2983 - val_cindex_score: 0.8715\n","Epoch 49/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.1908 - cindex_score: 0.8910 - val_loss: 0.2831 - val_cindex_score: 0.8712\n","Epoch 50/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1948 - cindex_score: 0.8899 - val_loss: 0.2912 - val_cindex_score: 0.8599\n","Epoch 51/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1901 - cindex_score: 0.8938 - val_loss: 0.2748 - val_cindex_score: 0.8733\n","Epoch 52/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1709 - cindex_score: 0.8959 - val_loss: 0.2734 - val_cindex_score: 0.8741\n","Epoch 53/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.1642 - cindex_score: 0.9012 - val_loss: 0.2762 - val_cindex_score: 0.8740\n","Epoch 54/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1566 - cindex_score: 0.9020 - val_loss: 0.2712 - val_cindex_score: 0.8742\n","Epoch 55/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.1533 - cindex_score: 0.9042 - val_loss: 0.2701 - val_cindex_score: 0.8708\n","Epoch 56/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.1473 - cindex_score: 0.9068 - val_loss: 0.2536 - val_cindex_score: 0.8752\n","Epoch 57/100\n","20036/20036 [==============================] - 12s 617us/step - loss: 0.1464 - cindex_score: 0.9054 - val_loss: 0.2776 - val_cindex_score: 0.8748\n","Epoch 58/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1426 - cindex_score: 0.9085 - val_loss: 0.2680 - val_cindex_score: 0.8734\n","Epoch 59/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.1407 - cindex_score: 0.9108 - val_loss: 0.2583 - val_cindex_score: 0.8718\n","Epoch 60/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1418 - cindex_score: 0.9088 - val_loss: 0.2542 - val_cindex_score: 0.8706\n","Epoch 61/100\n","20036/20036 [==============================] - 12s 617us/step - loss: 0.1353 - cindex_score: 0.9114 - val_loss: 0.2604 - val_cindex_score: 0.8793\n","Epoch 62/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.1290 - cindex_score: 0.9133 - val_loss: 0.2541 - val_cindex_score: 0.8722\n","Epoch 63/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.1279 - cindex_score: 0.9155 - val_loss: 0.2671 - val_cindex_score: 0.8753\n","Epoch 64/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1286 - cindex_score: 0.9159 - val_loss: 0.2542 - val_cindex_score: 0.8743\n","Epoch 65/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1218 - cindex_score: 0.9187 - val_loss: 0.2634 - val_cindex_score: 0.8724\n","Epoch 66/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1196 - cindex_score: 0.9194 - val_loss: 0.2677 - val_cindex_score: 0.8680\n","Epoch 67/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.1190 - cindex_score: 0.9215 - val_loss: 0.2669 - val_cindex_score: 0.8729\n","Epoch 68/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1172 - cindex_score: 0.9236 - val_loss: 0.2750 - val_cindex_score: 0.8769\n","Epoch 69/100\n","20036/20036 [==============================] - 12s 617us/step - loss: 0.1152 - cindex_score: 0.9227 - val_loss: 0.2796 - val_cindex_score: 0.8753\n","Epoch 70/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.1161 - cindex_score: 0.9230 - val_loss: 0.2922 - val_cindex_score: 0.8759\n","Epoch 71/100\n","20036/20036 [==============================] - 12s 617us/step - loss: 0.1178 - cindex_score: 0.9269 - val_loss: 0.2950 - val_cindex_score: 0.8728\n","Epoch 00071: early stopping\n","run_experiments.py:453: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:466: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:480: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","[[0, 0, 0, 0, 0]]\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","embedding_3 (Embedding)         (None, 100, 128)     8320        input_3[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_4 (Embedding)         (None, 1000, 128)    3328        input_4[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_7 (Conv1D)               (None, 95, 32)       24608       embedding_3[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_10 (Conv1D)              (None, 993, 32)      32800       embedding_4[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_8 (Conv1D)               (None, 90, 64)       12352       conv1d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_11 (Conv1D)              (None, 986, 64)      16448       conv1d_10[0][0]                  \n","__________________________________________________________________________________________________\n","conv1d_9 (Conv1D)               (None, 85, 96)       36960       conv1d_8[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_12 (Conv1D)              (None, 979, 96)      49248       conv1d_11[0][0]                  \n","__________________________________________________________________________________________________\n","global_max_pooling1d_3 (GlobalM (None, 96)           0           conv1d_9[0][0]                   \n","__________________________________________________________________________________________________\n","global_max_pooling1d_4 (GlobalM (None, 96)           0           conv1d_12[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 192)          0           global_max_pooling1d_3[0][0]     \n","                                                                 global_max_pooling1d_4[0][0]     \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 1024)         197632      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 1024)         0           dense_5[0][0]                    \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 1024)         1049600     dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 1024)         0           dense_6[0][0]                    \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 512)          524800      dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 1)            513         dense_7[0][0]                    \n","==================================================================================================\n","Total params: 1,956,609\n","Trainable params: 1,956,609\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Train on 20036 samples, validate on 5010 samples\n","Epoch 1/100\n","20036/20036 [==============================] - 13s 658us/step - loss: 2.7358 - cindex_score: 0.6436 - val_loss: 0.6552 - val_cindex_score: 0.7505\n","Epoch 2/100\n","20036/20036 [==============================] - 13s 628us/step - loss: 0.6263 - cindex_score: 0.7490 - val_loss: 0.6406 - val_cindex_score: 0.7776\n","Epoch 3/100\n","20036/20036 [==============================] - 13s 626us/step - loss: 0.5839 - cindex_score: 0.7732 - val_loss: 0.5982 - val_cindex_score: 0.7868\n","Epoch 4/100\n","20036/20036 [==============================] - 13s 625us/step - loss: 0.5691 - cindex_score: 0.7813 - val_loss: 0.6482 - val_cindex_score: 0.7908\n","Epoch 5/100\n","20036/20036 [==============================] - 13s 627us/step - loss: 0.5617 - cindex_score: 0.7857 - val_loss: 0.6125 - val_cindex_score: 0.7924\n","Epoch 6/100\n","20036/20036 [==============================] - 13s 626us/step - loss: 0.5570 - cindex_score: 0.7896 - val_loss: 0.6088 - val_cindex_score: 0.7951\n","Epoch 7/100\n","20036/20036 [==============================] - 13s 626us/step - loss: 0.5523 - cindex_score: 0.7917 - val_loss: 0.5691 - val_cindex_score: 0.7963\n","Epoch 8/100\n","20036/20036 [==============================] - 13s 627us/step - loss: 0.5423 - cindex_score: 0.7922 - val_loss: 0.5382 - val_cindex_score: 0.8006\n","Epoch 9/100\n","20036/20036 [==============================] - 13s 625us/step - loss: 0.5332 - cindex_score: 0.7966 - val_loss: 0.5281 - val_cindex_score: 0.8020\n","Epoch 10/100\n","20036/20036 [==============================] - 13s 625us/step - loss: 0.5237 - cindex_score: 0.7997 - val_loss: 0.5256 - val_cindex_score: 0.8046\n","Epoch 11/100\n","20036/20036 [==============================] - 13s 625us/step - loss: 0.5218 - cindex_score: 0.7990 - val_loss: 0.5133 - val_cindex_score: 0.8076\n","Epoch 12/100\n","20036/20036 [==============================] - 13s 626us/step - loss: 0.5106 - cindex_score: 0.8039 - val_loss: 0.5048 - val_cindex_score: 0.8094\n","Epoch 13/100\n","20036/20036 [==============================] - 13s 626us/step - loss: 0.5050 - cindex_score: 0.8087 - val_loss: 0.4938 - val_cindex_score: 0.8153\n","Epoch 14/100\n","20036/20036 [==============================] - 13s 625us/step - loss: 0.4926 - cindex_score: 0.8142 - val_loss: 0.4824 - val_cindex_score: 0.8157\n","Epoch 15/100\n","20036/20036 [==============================] - 13s 625us/step - loss: 0.4847 - cindex_score: 0.8175 - val_loss: 0.4905 - val_cindex_score: 0.8185\n","Epoch 16/100\n","20036/20036 [==============================] - 12s 623us/step - loss: 0.4730 - cindex_score: 0.8184 - val_loss: 0.4712 - val_cindex_score: 0.8203\n","Epoch 17/100\n","20036/20036 [==============================] - 13s 626us/step - loss: 0.4668 - cindex_score: 0.8206 - val_loss: 0.4677 - val_cindex_score: 0.8202\n","Epoch 18/100\n","20036/20036 [==============================] - 13s 625us/step - loss: 0.4671 - cindex_score: 0.8198 - val_loss: 0.4718 - val_cindex_score: 0.8198\n","Epoch 19/100\n","20036/20036 [==============================] - 13s 624us/step - loss: 0.4560 - cindex_score: 0.8232 - val_loss: 0.4645 - val_cindex_score: 0.8219\n","Epoch 20/100\n","20036/20036 [==============================] - 12s 623us/step - loss: 0.4423 - cindex_score: 0.8242 - val_loss: 0.4484 - val_cindex_score: 0.8255\n","Epoch 21/100\n","20036/20036 [==============================] - 12s 624us/step - loss: 0.4269 - cindex_score: 0.8291 - val_loss: 0.4299 - val_cindex_score: 0.8282\n","Epoch 22/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.4095 - cindex_score: 0.8345 - val_loss: 0.4211 - val_cindex_score: 0.8329\n","Epoch 23/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.3991 - cindex_score: 0.8359 - val_loss: 0.4204 - val_cindex_score: 0.8377\n","Epoch 24/100\n","20036/20036 [==============================] - 12s 623us/step - loss: 0.3770 - cindex_score: 0.8402 - val_loss: 0.3966 - val_cindex_score: 0.8412\n","Epoch 25/100\n","20036/20036 [==============================] - 12s 623us/step - loss: 0.3707 - cindex_score: 0.8483 - val_loss: 0.4412 - val_cindex_score: 0.8527\n","Epoch 26/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.3404 - cindex_score: 0.8522 - val_loss: 0.3861 - val_cindex_score: 0.8511\n","Epoch 27/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.3270 - cindex_score: 0.8540 - val_loss: 0.3762 - val_cindex_score: 0.8509\n","Epoch 28/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.3279 - cindex_score: 0.8554 - val_loss: 0.3646 - val_cindex_score: 0.8595\n","Epoch 29/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.3242 - cindex_score: 0.8574 - val_loss: 0.3848 - val_cindex_score: 0.8594\n","Epoch 30/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.3166 - cindex_score: 0.8624 - val_loss: 0.3621 - val_cindex_score: 0.8621\n","Epoch 31/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.3018 - cindex_score: 0.8651 - val_loss: 0.3425 - val_cindex_score: 0.8632\n","Epoch 32/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.2973 - cindex_score: 0.8678 - val_loss: 0.3487 - val_cindex_score: 0.8653\n","Epoch 33/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.2838 - cindex_score: 0.8698 - val_loss: 0.3405 - val_cindex_score: 0.8656\n","Epoch 34/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.2771 - cindex_score: 0.8694 - val_loss: 0.3447 - val_cindex_score: 0.8665\n","Epoch 35/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.2681 - cindex_score: 0.8718 - val_loss: 0.3825 - val_cindex_score: 0.8641\n","Epoch 36/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.2581 - cindex_score: 0.8770 - val_loss: 0.4038 - val_cindex_score: 0.8632\n","Epoch 37/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.2554 - cindex_score: 0.8783 - val_loss: 0.3693 - val_cindex_score: 0.8650\n","Epoch 38/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.2335 - cindex_score: 0.8803 - val_loss: 0.3306 - val_cindex_score: 0.8611\n","Epoch 39/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.2330 - cindex_score: 0.8813 - val_loss: 0.3436 - val_cindex_score: 0.8596\n","Epoch 40/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.2260 - cindex_score: 0.8825 - val_loss: 0.3264 - val_cindex_score: 0.8610\n","Epoch 41/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.2181 - cindex_score: 0.8838 - val_loss: 0.3127 - val_cindex_score: 0.8658\n","Epoch 42/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.2106 - cindex_score: 0.8847 - val_loss: 0.3192 - val_cindex_score: 0.8741\n","Epoch 43/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.2033 - cindex_score: 0.8838 - val_loss: 0.2891 - val_cindex_score: 0.8743\n","Epoch 44/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.1972 - cindex_score: 0.8884 - val_loss: 0.2958 - val_cindex_score: 0.8699\n","Epoch 45/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1923 - cindex_score: 0.8907 - val_loss: 0.2957 - val_cindex_score: 0.8734\n","Epoch 46/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1868 - cindex_score: 0.8916 - val_loss: 0.2845 - val_cindex_score: 0.8694\n","Epoch 47/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.1796 - cindex_score: 0.8938 - val_loss: 0.2863 - val_cindex_score: 0.8681\n","Epoch 48/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.1778 - cindex_score: 0.8946 - val_loss: 0.2922 - val_cindex_score: 0.8650\n","Epoch 49/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.1791 - cindex_score: 0.8935 - val_loss: 0.2888 - val_cindex_score: 0.8676\n","Epoch 50/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.1718 - cindex_score: 0.8957 - val_loss: 0.3016 - val_cindex_score: 0.8713\n","Epoch 51/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.1676 - cindex_score: 0.8939 - val_loss: 0.2848 - val_cindex_score: 0.8728\n","Epoch 52/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.1638 - cindex_score: 0.8990 - val_loss: 0.2912 - val_cindex_score: 0.8755\n","Epoch 53/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1598 - cindex_score: 0.9025 - val_loss: 0.2856 - val_cindex_score: 0.8717\n","Epoch 54/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1543 - cindex_score: 0.9040 - val_loss: 0.2851 - val_cindex_score: 0.8698\n","Epoch 55/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.1514 - cindex_score: 0.9048 - val_loss: 0.2800 - val_cindex_score: 0.8716\n","Epoch 56/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1549 - cindex_score: 0.9049 - val_loss: 0.3029 - val_cindex_score: 0.8695\n","Epoch 57/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1517 - cindex_score: 0.9088 - val_loss: 0.2858 - val_cindex_score: 0.8731\n","Epoch 58/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1428 - cindex_score: 0.9083 - val_loss: 0.2844 - val_cindex_score: 0.8690\n","Epoch 59/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1455 - cindex_score: 0.9089 - val_loss: 0.2729 - val_cindex_score: 0.8710\n","Epoch 60/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1390 - cindex_score: 0.9118 - val_loss: 0.2725 - val_cindex_score: 0.8654\n","Epoch 61/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1343 - cindex_score: 0.9129 - val_loss: 0.2652 - val_cindex_score: 0.8685\n","Epoch 62/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.1342 - cindex_score: 0.9141 - val_loss: 0.2957 - val_cindex_score: 0.8737\n","Epoch 63/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1288 - cindex_score: 0.9159 - val_loss: 0.3277 - val_cindex_score: 0.8727\n","Epoch 64/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1317 - cindex_score: 0.9161 - val_loss: 0.3041 - val_cindex_score: 0.8737\n","Epoch 65/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.1295 - cindex_score: 0.9186 - val_loss: 0.3026 - val_cindex_score: 0.8763\n","Epoch 66/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1324 - cindex_score: 0.9184 - val_loss: 0.2975 - val_cindex_score: 0.8784\n","Epoch 67/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1267 - cindex_score: 0.9187 - val_loss: 0.2686 - val_cindex_score: 0.8756\n","Epoch 68/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.1277 - cindex_score: 0.9213 - val_loss: 0.2723 - val_cindex_score: 0.8756\n","Epoch 69/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1248 - cindex_score: 0.9205 - val_loss: 0.2762 - val_cindex_score: 0.8743\n","Epoch 70/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1298 - cindex_score: 0.9222 - val_loss: 0.2737 - val_cindex_score: 0.8645\n","Epoch 71/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.1421 - cindex_score: 0.9201 - val_loss: 0.3069 - val_cindex_score: 0.8727\n","Epoch 72/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1424 - cindex_score: 0.9214 - val_loss: 0.2758 - val_cindex_score: 0.8674\n","Epoch 73/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1301 - cindex_score: 0.9251 - val_loss: 0.2721 - val_cindex_score: 0.8670\n","Epoch 74/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1292 - cindex_score: 0.9256 - val_loss: 0.3148 - val_cindex_score: 0.8615\n","Epoch 75/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1462 - cindex_score: 0.9255 - val_loss: 0.3460 - val_cindex_score: 0.8609\n","Epoch 76/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1394 - cindex_score: 0.9242 - val_loss: 0.2766 - val_cindex_score: 0.8678\n","Epoch 00076: early stopping\n","run_experiments.py:453: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:466: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:480: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n"]}],"source":["!./go.sh"]},{"cell_type":"markdown","metadata":{"id":"Xf8UvjPtNCAI"},"source":["### KIBA"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"JwmWBSkhNDUE","outputId":"4760c728-1b73-45e2-891e-7d3fb25b379a"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From run_experiments.py:16: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","Using TensorFlow backend.\n","WARNING:tensorflow:From run_experiments.py:19: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","2022-04-16 17:06:31.808102: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2022-04-16 17:06:31.808309: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563e6618b2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2022-04-16 17:06:31.808346: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2022-04-16 17:06:31.810031: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2022-04-16 17:06:31.941740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 17:06:31.942855: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563e6618b800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2022-04-16 17:06:31.942909: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n","2022-04-16 17:06:31.943166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 17:06:31.944052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2022-04-16 17:06:31.944511: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-04-16 17:06:31.946264: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-04-16 17:06:31.947335: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2022-04-16 17:06:31.947698: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2022-04-16 17:06:31.949799: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2022-04-16 17:06:31.950893: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2022-04-16 17:06:31.954924: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-16 17:06:31.955032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 17:06:31.955777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 17:06:31.956407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2022-04-16 17:06:31.956475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-04-16 17:06:31.957685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-16 17:06:31.957719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2022-04-16 17:06:31.957739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2022-04-16 17:06:31.957904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 17:06:31.958747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 17:06:31.959581: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-04-16 17:06:31.959640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","Read data/kiba/ start\n","2111\n","229\n","logs/1650128792.872829/\n","Reading data/kiba/ start\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","[[0, 0, 0, 0, 0]]\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From run_experiments.py:432: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n","\n","WARNING:tensorflow:From run_experiments.py:437: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 100, 128)     8320        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_2 (Embedding)         (None, 1000, 128)    3328        input_2[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_1 (Conv1D)               (None, 95, 32)       24608       embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_4 (Conv1D)               (None, 993, 32)      32800       embedding_2[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_2 (Conv1D)               (None, 90, 64)       12352       conv1d_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_5 (Conv1D)               (None, 986, 64)      16448       conv1d_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_3 (Conv1D)               (None, 85, 96)       36960       conv1d_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_6 (Conv1D)               (None, 979, 96)      49248       conv1d_5[0][0]                   \n","__________________________________________________________________________________________________\n","global_max_pooling1d_1 (GlobalM (None, 96)           0           conv1d_3[0][0]                   \n","__________________________________________________________________________________________________\n","global_max_pooling1d_2 (GlobalM (None, 96)           0           conv1d_6[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 192)          0           global_max_pooling1d_1[0][0]     \n","                                                                 global_max_pooling1d_2[0][0]     \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1024)         197632      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1024)         1049600     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 512)          524800      dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 1)            513         dense_3[0][0]                    \n","==================================================================================================\n","Total params: 1,956,609\n","Trainable params: 1,956,609\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 78836 samples, validate on 19709 samples\n","Epoch 1/100\n","2022-04-16 17:06:36.983235: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-04-16 17:06:37.133268: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","78836/78836 [==============================] - 54s 689us/step - loss: 3.0435 - cindex_score: 0.6089 - val_loss: 0.5205 - val_cindex_score: 0.7141\n","Epoch 2/100\n","78836/78836 [==============================] - 49s 627us/step - loss: 0.6050 - cindex_score: 0.6782 - val_loss: 0.4630 - val_cindex_score: 0.7340\n","Epoch 3/100\n","78836/78836 [==============================] - 49s 623us/step - loss: 0.5470 - cindex_score: 0.7042 - val_loss: 0.4565 - val_cindex_score: 0.7452\n","Epoch 4/100\n","78836/78836 [==============================] - 49s 625us/step - loss: 0.5232 - cindex_score: 0.7166 - val_loss: 0.4698 - val_cindex_score: 0.7510\n","Epoch 5/100\n","78836/78836 [==============================] - 49s 621us/step - loss: 0.5195 - cindex_score: 0.7238 - val_loss: 0.6212 - val_cindex_score: 0.7505\n","Epoch 6/100\n","78836/78836 [==============================] - 49s 625us/step - loss: 0.5015 - cindex_score: 0.7281 - val_loss: 0.6286 - val_cindex_score: 0.7527\n","Epoch 7/100\n","78836/78836 [==============================] - 49s 622us/step - loss: 0.4966 - cindex_score: 0.7304 - val_loss: 0.4692 - val_cindex_score: 0.7542\n","Epoch 8/100\n","78836/78836 [==============================] - 49s 625us/step - loss: 0.4879 - cindex_score: 0.7331 - val_loss: 0.4023 - val_cindex_score: 0.7543\n","Epoch 9/100\n","78836/78836 [==============================] - 49s 620us/step - loss: 0.4672 - cindex_score: 0.7342 - val_loss: 0.4072 - val_cindex_score: 0.7557\n","Epoch 10/100\n","78836/78836 [==============================] - 49s 623us/step - loss: 0.4589 - cindex_score: 0.7372 - val_loss: 0.3942 - val_cindex_score: 0.7564\n","Epoch 11/100\n","78836/78836 [==============================] - 49s 619us/step - loss: 0.4531 - cindex_score: 0.7403 - val_loss: 0.3762 - val_cindex_score: 0.7668\n","Epoch 12/100\n","78836/78836 [==============================] - 49s 623us/step - loss: 0.4293 - cindex_score: 0.7447 - val_loss: 0.3792 - val_cindex_score: 0.7723\n","Epoch 13/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.4103 - cindex_score: 0.7492 - val_loss: 0.3521 - val_cindex_score: 0.7743\n","Epoch 14/100\n","78836/78836 [==============================] - 49s 622us/step - loss: 0.3987 - cindex_score: 0.7534 - val_loss: 0.3781 - val_cindex_score: 0.7701\n","Epoch 15/100\n","78836/78836 [==============================] - 49s 619us/step - loss: 0.3885 - cindex_score: 0.7567 - val_loss: 0.3648 - val_cindex_score: 0.7785\n","Epoch 16/100\n","78836/78836 [==============================] - 49s 621us/step - loss: 0.3774 - cindex_score: 0.7612 - val_loss: 0.3251 - val_cindex_score: 0.7824\n","Epoch 17/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.3704 - cindex_score: 0.7643 - val_loss: 0.3240 - val_cindex_score: 0.7845\n","Epoch 18/100\n","78836/78836 [==============================] - 49s 620us/step - loss: 0.3563 - cindex_score: 0.7671 - val_loss: 0.3249 - val_cindex_score: 0.7890\n","Epoch 19/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.3466 - cindex_score: 0.7714 - val_loss: 0.3123 - val_cindex_score: 0.7929\n","Epoch 20/100\n","78836/78836 [==============================] - 49s 621us/step - loss: 0.3415 - cindex_score: 0.7747 - val_loss: 0.3391 - val_cindex_score: 0.7893\n","Epoch 21/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.3339 - cindex_score: 0.7764 - val_loss: 0.3315 - val_cindex_score: 0.7906\n","Epoch 22/100\n","78836/78836 [==============================] - 49s 619us/step - loss: 0.3217 - cindex_score: 0.7798 - val_loss: 0.3149 - val_cindex_score: 0.7973\n","Epoch 23/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.3139 - cindex_score: 0.7826 - val_loss: 0.3067 - val_cindex_score: 0.7998\n","Epoch 24/100\n","78836/78836 [==============================] - 49s 619us/step - loss: 0.3120 - cindex_score: 0.7844 - val_loss: 0.3000 - val_cindex_score: 0.8013\n","Epoch 25/100\n","78836/78836 [==============================] - 49s 615us/step - loss: 0.2972 - cindex_score: 0.7888 - val_loss: 0.3058 - val_cindex_score: 0.8049\n","Epoch 26/100\n","78836/78836 [==============================] - 49s 618us/step - loss: 0.2929 - cindex_score: 0.7906 - val_loss: 0.2901 - val_cindex_score: 0.8074\n","Epoch 27/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.2790 - cindex_score: 0.7955 - val_loss: 0.2814 - val_cindex_score: 0.8074\n","Epoch 28/100\n","78836/78836 [==============================] - 49s 618us/step - loss: 0.2739 - cindex_score: 0.7975 - val_loss: 0.2784 - val_cindex_score: 0.8103\n","Epoch 29/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.2682 - cindex_score: 0.8004 - val_loss: 0.2728 - val_cindex_score: 0.8103\n","Epoch 30/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2638 - cindex_score: 0.8035 - val_loss: 0.2677 - val_cindex_score: 0.8137\n","Epoch 31/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.2453 - cindex_score: 0.8095 - val_loss: 0.2563 - val_cindex_score: 0.8158\n","Epoch 32/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2385 - cindex_score: 0.8129 - val_loss: 0.2563 - val_cindex_score: 0.8181\n","Epoch 33/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.2297 - cindex_score: 0.8158 - val_loss: 0.2599 - val_cindex_score: 0.8192\n","Epoch 34/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2221 - cindex_score: 0.8201 - val_loss: 0.2630 - val_cindex_score: 0.8195\n","Epoch 35/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.2193 - cindex_score: 0.8221 - val_loss: 0.2547 - val_cindex_score: 0.8166\n","Epoch 36/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2107 - cindex_score: 0.8251 - val_loss: 0.2622 - val_cindex_score: 0.8193\n","Epoch 37/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.2042 - cindex_score: 0.8277 - val_loss: 0.2483 - val_cindex_score: 0.8262\n","Epoch 38/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.2063 - cindex_score: 0.8310 - val_loss: 0.2395 - val_cindex_score: 0.8270\n","Epoch 39/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.2028 - cindex_score: 0.8327 - val_loss: 0.2481 - val_cindex_score: 0.8206\n","Epoch 40/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.1913 - cindex_score: 0.8364 - val_loss: 0.2636 - val_cindex_score: 0.8264\n","Epoch 41/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.1830 - cindex_score: 0.8401 - val_loss: 0.2383 - val_cindex_score: 0.8284\n","Epoch 42/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.1719 - cindex_score: 0.8426 - val_loss: 0.2321 - val_cindex_score: 0.8282\n","Epoch 43/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.1725 - cindex_score: 0.8430 - val_loss: 0.2344 - val_cindex_score: 0.8285\n","Epoch 44/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.1616 - cindex_score: 0.8464 - val_loss: 0.2381 - val_cindex_score: 0.8304\n","Epoch 45/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.1546 - cindex_score: 0.8502 - val_loss: 0.2298 - val_cindex_score: 0.8320\n","Epoch 46/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.1503 - cindex_score: 0.8524 - val_loss: 0.2280 - val_cindex_score: 0.8299\n","Epoch 47/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.1419 - cindex_score: 0.8567 - val_loss: 0.2351 - val_cindex_score: 0.8335\n","Epoch 48/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.1459 - cindex_score: 0.8566 - val_loss: 0.2288 - val_cindex_score: 0.8296\n","Epoch 49/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.1376 - cindex_score: 0.8609 - val_loss: 0.2272 - val_cindex_score: 0.8321\n","Epoch 50/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.1336 - cindex_score: 0.8635 - val_loss: 0.2194 - val_cindex_score: 0.8358\n","Epoch 51/100\n","78836/78836 [==============================] - 48s 611us/step - loss: 0.1318 - cindex_score: 0.8666 - val_loss: 0.2267 - val_cindex_score: 0.8381\n","Epoch 52/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.1285 - cindex_score: 0.8684 - val_loss: 0.2247 - val_cindex_score: 0.8326\n","Epoch 53/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.1286 - cindex_score: 0.8701 - val_loss: 0.2196 - val_cindex_score: 0.8378\n","Epoch 54/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.1219 - cindex_score: 0.8742 - val_loss: 0.2505 - val_cindex_score: 0.8390\n","Epoch 55/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.1267 - cindex_score: 0.8740 - val_loss: 0.2230 - val_cindex_score: 0.8382\n","Epoch 56/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.1245 - cindex_score: 0.8757 - val_loss: 0.2408 - val_cindex_score: 0.8374\n","Epoch 57/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.1131 - cindex_score: 0.8793 - val_loss: 0.2442 - val_cindex_score: 0.8402\n","Epoch 58/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.1046 - cindex_score: 0.8828 - val_loss: 0.2136 - val_cindex_score: 0.8436\n","Epoch 59/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.1021 - cindex_score: 0.8851 - val_loss: 0.2118 - val_cindex_score: 0.8449\n","Epoch 60/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.1019 - cindex_score: 0.8861 - val_loss: 0.2157 - val_cindex_score: 0.8436\n","Epoch 61/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.1080 - cindex_score: 0.8866 - val_loss: 0.2212 - val_cindex_score: 0.8421\n","Epoch 62/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1046 - cindex_score: 0.8878 - val_loss: 0.2107 - val_cindex_score: 0.8446\n","Epoch 63/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.0973 - cindex_score: 0.8908 - val_loss: 0.2193 - val_cindex_score: 0.8446\n","Epoch 64/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0944 - cindex_score: 0.8925 - val_loss: 0.2074 - val_cindex_score: 0.8482\n","Epoch 65/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0919 - cindex_score: 0.8939 - val_loss: 0.2105 - val_cindex_score: 0.8493\n","Epoch 66/100\n","78836/78836 [==============================] - 49s 615us/step - loss: 0.0860 - cindex_score: 0.8971 - val_loss: 0.2094 - val_cindex_score: 0.8519\n","Epoch 67/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.0848 - cindex_score: 0.8986 - val_loss: 0.2071 - val_cindex_score: 0.8532\n","Epoch 68/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0814 - cindex_score: 0.9009 - val_loss: 0.2093 - val_cindex_score: 0.8502\n","Epoch 69/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.0790 - cindex_score: 0.9027 - val_loss: 0.2104 - val_cindex_score: 0.8517\n","Epoch 70/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0809 - cindex_score: 0.9026 - val_loss: 0.2098 - val_cindex_score: 0.8505\n","Epoch 71/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.0834 - cindex_score: 0.9026 - val_loss: 0.2120 - val_cindex_score: 0.8503\n","Epoch 72/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0877 - cindex_score: 0.9027 - val_loss: 0.2158 - val_cindex_score: 0.8502\n","Epoch 73/100\n","78836/78836 [==============================] - 48s 611us/step - loss: 0.0861 - cindex_score: 0.9028 - val_loss: 0.2101 - val_cindex_score: 0.8522\n","Epoch 74/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0815 - cindex_score: 0.9052 - val_loss: 0.2398 - val_cindex_score: 0.8522\n","Epoch 75/100\n","78836/78836 [==============================] - 48s 611us/step - loss: 0.0801 - cindex_score: 0.9062 - val_loss: 0.2376 - val_cindex_score: 0.8548\n","Epoch 76/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0786 - cindex_score: 0.9065 - val_loss: 0.2302 - val_cindex_score: 0.8545\n","Epoch 77/100\n","78836/78836 [==============================] - 48s 611us/step - loss: 0.0739 - cindex_score: 0.9098 - val_loss: 0.2203 - val_cindex_score: 0.8533\n","Epoch 78/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0662 - cindex_score: 0.9124 - val_loss: 0.2226 - val_cindex_score: 0.8548\n","Epoch 79/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.0670 - cindex_score: 0.9126 - val_loss: 0.2117 - val_cindex_score: 0.8572\n","Epoch 80/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0627 - cindex_score: 0.9152 - val_loss: 0.2099 - val_cindex_score: 0.8565\n","Epoch 81/100\n","78836/78836 [==============================] - 48s 611us/step - loss: 0.0619 - cindex_score: 0.9157 - val_loss: 0.2057 - val_cindex_score: 0.8549\n","Epoch 82/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0619 - cindex_score: 0.9162 - val_loss: 0.2083 - val_cindex_score: 0.8583\n","Epoch 83/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.0628 - cindex_score: 0.9151 - val_loss: 0.2082 - val_cindex_score: 0.8550\n","Epoch 84/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.0619 - cindex_score: 0.9161 - val_loss: 0.2056 - val_cindex_score: 0.8548\n","Epoch 85/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.0614 - cindex_score: 0.9166 - val_loss: 0.2039 - val_cindex_score: 0.8583\n","Epoch 86/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.0602 - cindex_score: 0.9182 - val_loss: 0.2028 - val_cindex_score: 0.8584\n","Epoch 87/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0623 - cindex_score: 0.9165 - val_loss: 0.1988 - val_cindex_score: 0.8589\n","Epoch 88/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.0595 - cindex_score: 0.9181 - val_loss: 0.1975 - val_cindex_score: 0.8581\n","Epoch 89/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.0579 - cindex_score: 0.9194 - val_loss: 0.2089 - val_cindex_score: 0.8580\n","Epoch 90/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.0593 - cindex_score: 0.9191 - val_loss: 0.2091 - val_cindex_score: 0.8579\n","Epoch 91/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0596 - cindex_score: 0.9194 - val_loss: 0.2043 - val_cindex_score: 0.8570\n","Epoch 92/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.0678 - cindex_score: 0.9163 - val_loss: 0.2090 - val_cindex_score: 0.8552\n","Epoch 93/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0591 - cindex_score: 0.9195 - val_loss: 0.2027 - val_cindex_score: 0.8587\n","Epoch 94/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0531 - cindex_score: 0.9239 - val_loss: 0.1991 - val_cindex_score: 0.8589\n","Epoch 95/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.0539 - cindex_score: 0.9247 - val_loss: 0.1943 - val_cindex_score: 0.8615\n","Epoch 96/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.0522 - cindex_score: 0.9255 - val_loss: 0.1945 - val_cindex_score: 0.8607\n","Epoch 97/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.0507 - cindex_score: 0.9264 - val_loss: 0.1987 - val_cindex_score: 0.8622\n","Epoch 98/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0552 - cindex_score: 0.9233 - val_loss: 0.2064 - val_cindex_score: 0.8551\n","Epoch 99/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0566 - cindex_score: 0.9214 - val_loss: 0.1979 - val_cindex_score: 0.8604\n","Epoch 100/100\n","78836/78836 [==============================] - 49s 615us/step - loss: 0.0533 - cindex_score: 0.9249 - val_loss: 0.1986 - val_cindex_score: 0.8605\n","run_experiments.py:453: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:466: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:480: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","[[0, 0, 0, 0, 0]]\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","embedding_3 (Embedding)         (None, 100, 128)     8320        input_3[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_4 (Embedding)         (None, 1000, 128)    3328        input_4[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_7 (Conv1D)               (None, 95, 32)       24608       embedding_3[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_10 (Conv1D)              (None, 993, 32)      32800       embedding_4[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_8 (Conv1D)               (None, 90, 64)       12352       conv1d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_11 (Conv1D)              (None, 986, 64)      16448       conv1d_10[0][0]                  \n","__________________________________________________________________________________________________\n","conv1d_9 (Conv1D)               (None, 85, 96)       36960       conv1d_8[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_12 (Conv1D)              (None, 979, 96)      49248       conv1d_11[0][0]                  \n","__________________________________________________________________________________________________\n","global_max_pooling1d_3 (GlobalM (None, 96)           0           conv1d_9[0][0]                   \n","__________________________________________________________________________________________________\n","global_max_pooling1d_4 (GlobalM (None, 96)           0           conv1d_12[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 192)          0           global_max_pooling1d_3[0][0]     \n","                                                                 global_max_pooling1d_4[0][0]     \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 1024)         197632      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 1024)         0           dense_5[0][0]                    \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 1024)         1049600     dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 1024)         0           dense_6[0][0]                    \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 512)          524800      dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 1)            513         dense_7[0][0]                    \n","==================================================================================================\n","Total params: 1,956,609\n","Trainable params: 1,956,609\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Train on 78836 samples, validate on 19709 samples\n","Epoch 1/100\n","78836/78836 [==============================] - 50s 639us/step - loss: 3.2802 - cindex_score: 0.6018 - val_loss: 0.5002 - val_cindex_score: 0.7097\n","Epoch 2/100\n","78836/78836 [==============================] - 49s 627us/step - loss: 0.5835 - cindex_score: 0.6790 - val_loss: 0.4769 - val_cindex_score: 0.7362\n","Epoch 3/100\n","78836/78836 [==============================] - 49s 626us/step - loss: 0.5322 - cindex_score: 0.7066 - val_loss: 0.4253 - val_cindex_score: 0.7449\n","Epoch 4/100\n","78836/78836 [==============================] - 49s 626us/step - loss: 0.5216 - cindex_score: 0.7177 - val_loss: 0.4939 - val_cindex_score: 0.7502\n","Epoch 5/100\n","78836/78836 [==============================] - 49s 625us/step - loss: 0.5034 - cindex_score: 0.7257 - val_loss: 0.5142 - val_cindex_score: 0.7541\n","Epoch 6/100\n","78836/78836 [==============================] - 49s 626us/step - loss: 0.4999 - cindex_score: 0.7284 - val_loss: 0.4837 - val_cindex_score: 0.7510\n","Epoch 7/100\n","78836/78836 [==============================] - 49s 626us/step - loss: 0.4880 - cindex_score: 0.7311 - val_loss: 0.5418 - val_cindex_score: 0.7504\n","Epoch 8/100\n","78836/78836 [==============================] - 49s 624us/step - loss: 0.4817 - cindex_score: 0.7337 - val_loss: 0.5110 - val_cindex_score: 0.7520\n","Epoch 9/100\n","78836/78836 [==============================] - 49s 624us/step - loss: 0.4757 - cindex_score: 0.7363 - val_loss: 0.3910 - val_cindex_score: 0.7532\n","Epoch 10/100\n","78836/78836 [==============================] - 49s 625us/step - loss: 0.4657 - cindex_score: 0.7377 - val_loss: 0.3880 - val_cindex_score: 0.7546\n","Epoch 11/100\n","78836/78836 [==============================] - 49s 623us/step - loss: 0.4501 - cindex_score: 0.7425 - val_loss: 0.4266 - val_cindex_score: 0.7604\n","Epoch 12/100\n","78836/78836 [==============================] - 49s 623us/step - loss: 0.4269 - cindex_score: 0.7477 - val_loss: 0.3837 - val_cindex_score: 0.7676\n","Epoch 13/100\n","78836/78836 [==============================] - 49s 622us/step - loss: 0.4040 - cindex_score: 0.7509 - val_loss: 0.3463 - val_cindex_score: 0.7658\n","Epoch 14/100\n","78836/78836 [==============================] - 49s 623us/step - loss: 0.3951 - cindex_score: 0.7539 - val_loss: 0.3631 - val_cindex_score: 0.7729\n","Epoch 15/100\n","78836/78836 [==============================] - 49s 622us/step - loss: 0.3804 - cindex_score: 0.7596 - val_loss: 0.3502 - val_cindex_score: 0.7782\n","Epoch 16/100\n","78836/78836 [==============================] - 49s 621us/step - loss: 0.3675 - cindex_score: 0.7641 - val_loss: 0.3126 - val_cindex_score: 0.7858\n","Epoch 17/100\n","78836/78836 [==============================] - 49s 621us/step - loss: 0.3605 - cindex_score: 0.7685 - val_loss: 0.3341 - val_cindex_score: 0.7813\n","Epoch 18/100\n","78836/78836 [==============================] - 49s 622us/step - loss: 0.3504 - cindex_score: 0.7726 - val_loss: 0.3026 - val_cindex_score: 0.7894\n","Epoch 19/100\n","78836/78836 [==============================] - 49s 620us/step - loss: 0.3410 - cindex_score: 0.7747 - val_loss: 0.3236 - val_cindex_score: 0.7905\n","Epoch 20/100\n","78836/78836 [==============================] - 49s 620us/step - loss: 0.3387 - cindex_score: 0.7773 - val_loss: 0.3086 - val_cindex_score: 0.7940\n","Epoch 21/100\n","78836/78836 [==============================] - 49s 619us/step - loss: 0.3256 - cindex_score: 0.7818 - val_loss: 0.2937 - val_cindex_score: 0.7982\n","Epoch 22/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.3134 - cindex_score: 0.7844 - val_loss: 0.2935 - val_cindex_score: 0.7965\n","Epoch 23/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.3028 - cindex_score: 0.7867 - val_loss: 0.3129 - val_cindex_score: 0.8003\n","Epoch 24/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2913 - cindex_score: 0.7907 - val_loss: 0.3006 - val_cindex_score: 0.8036\n","Epoch 25/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.2869 - cindex_score: 0.7933 - val_loss: 0.2801 - val_cindex_score: 0.8017\n","Epoch 26/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2798 - cindex_score: 0.7968 - val_loss: 0.2696 - val_cindex_score: 0.8081\n","Epoch 27/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2695 - cindex_score: 0.8007 - val_loss: 0.2997 - val_cindex_score: 0.8105\n","Epoch 28/100\n","78836/78836 [==============================] - 49s 615us/step - loss: 0.2647 - cindex_score: 0.8030 - val_loss: 0.2590 - val_cindex_score: 0.8105\n","Epoch 29/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.2557 - cindex_score: 0.8059 - val_loss: 0.2674 - val_cindex_score: 0.8069\n","Epoch 30/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2434 - cindex_score: 0.8097 - val_loss: 0.2758 - val_cindex_score: 0.8093\n","Epoch 31/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2363 - cindex_score: 0.8141 - val_loss: 0.2610 - val_cindex_score: 0.8162\n","Epoch 32/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2361 - cindex_score: 0.8135 - val_loss: 0.2551 - val_cindex_score: 0.8118\n","Epoch 33/100\n","78836/78836 [==============================] - 49s 615us/step - loss: 0.2215 - cindex_score: 0.8184 - val_loss: 0.2494 - val_cindex_score: 0.8139\n","Epoch 34/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2155 - cindex_score: 0.8216 - val_loss: 0.2492 - val_cindex_score: 0.8194\n","Epoch 35/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2055 - cindex_score: 0.8253 - val_loss: 0.2485 - val_cindex_score: 0.8186\n","Epoch 36/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.2029 - cindex_score: 0.8278 - val_loss: 0.2461 - val_cindex_score: 0.8177\n","Epoch 37/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.2027 - cindex_score: 0.8281 - val_loss: 0.2462 - val_cindex_score: 0.8163\n","Epoch 38/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1924 - cindex_score: 0.8324 - val_loss: 0.2340 - val_cindex_score: 0.8226\n","Epoch 39/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1888 - cindex_score: 0.8354 - val_loss: 0.2311 - val_cindex_score: 0.8249\n","Epoch 40/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.1936 - cindex_score: 0.8367 - val_loss: 0.2379 - val_cindex_score: 0.8276\n","Epoch 41/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.1887 - cindex_score: 0.8391 - val_loss: 0.2468 - val_cindex_score: 0.8263\n","Epoch 42/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1740 - cindex_score: 0.8430 - val_loss: 0.2270 - val_cindex_score: 0.8286\n","Epoch 43/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.1646 - cindex_score: 0.8473 - val_loss: 0.2379 - val_cindex_score: 0.8264\n","Epoch 44/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1591 - cindex_score: 0.8484 - val_loss: 0.2298 - val_cindex_score: 0.8292\n","Epoch 45/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.1521 - cindex_score: 0.8516 - val_loss: 0.2251 - val_cindex_score: 0.8303\n","Epoch 46/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.1464 - cindex_score: 0.8536 - val_loss: 0.2337 - val_cindex_score: 0.8279\n","Epoch 47/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.1401 - cindex_score: 0.8575 - val_loss: 0.2190 - val_cindex_score: 0.8338\n","Epoch 48/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1386 - cindex_score: 0.8591 - val_loss: 0.2310 - val_cindex_score: 0.8314\n","Epoch 49/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1357 - cindex_score: 0.8610 - val_loss: 0.2212 - val_cindex_score: 0.8310\n","Epoch 50/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1535 - cindex_score: 0.8546 - val_loss: 0.2415 - val_cindex_score: 0.8338\n","Epoch 51/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.1340 - cindex_score: 0.8643 - val_loss: 0.2241 - val_cindex_score: 0.8360\n","Epoch 52/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.1246 - cindex_score: 0.8687 - val_loss: 0.2132 - val_cindex_score: 0.8360\n","Epoch 53/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1232 - cindex_score: 0.8711 - val_loss: 0.2352 - val_cindex_score: 0.8352\n","Epoch 54/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.1236 - cindex_score: 0.8727 - val_loss: 0.2385 - val_cindex_score: 0.8359\n","Epoch 55/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.1254 - cindex_score: 0.8743 - val_loss: 0.2143 - val_cindex_score: 0.8375\n","Epoch 56/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1213 - cindex_score: 0.8762 - val_loss: 0.2140 - val_cindex_score: 0.8379\n","Epoch 57/100\n","78836/78836 [==============================] - 49s 615us/step - loss: 0.1202 - cindex_score: 0.8783 - val_loss: 0.2339 - val_cindex_score: 0.8384\n","Epoch 58/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.1066 - cindex_score: 0.8825 - val_loss: 0.2168 - val_cindex_score: 0.8413\n","Epoch 59/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0974 - cindex_score: 0.8865 - val_loss: 0.2073 - val_cindex_score: 0.8414\n","Epoch 60/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1021 - cindex_score: 0.8846 - val_loss: 0.2053 - val_cindex_score: 0.8446\n","Epoch 61/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.1050 - cindex_score: 0.8870 - val_loss: 0.2107 - val_cindex_score: 0.8428\n","Epoch 62/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1012 - cindex_score: 0.8885 - val_loss: 0.2101 - val_cindex_score: 0.8463\n","Epoch 63/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0924 - cindex_score: 0.8913 - val_loss: 0.2117 - val_cindex_score: 0.8456\n","Epoch 64/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0898 - cindex_score: 0.8933 - val_loss: 0.2032 - val_cindex_score: 0.8484\n","Epoch 65/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0864 - cindex_score: 0.8952 - val_loss: 0.2121 - val_cindex_score: 0.8475\n","Epoch 66/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0897 - cindex_score: 0.8957 - val_loss: 0.2110 - val_cindex_score: 0.8474\n","Epoch 67/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0979 - cindex_score: 0.8948 - val_loss: 0.2229 - val_cindex_score: 0.8471\n","Epoch 68/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0960 - cindex_score: 0.8948 - val_loss: 0.2300 - val_cindex_score: 0.8478\n","Epoch 69/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0880 - cindex_score: 0.8987 - val_loss: 0.2114 - val_cindex_score: 0.8489\n","Epoch 70/100\n","78836/78836 [==============================] - 49s 615us/step - loss: 0.0823 - cindex_score: 0.9012 - val_loss: 0.2098 - val_cindex_score: 0.8481\n","Epoch 71/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0770 - cindex_score: 0.9042 - val_loss: 0.2070 - val_cindex_score: 0.8502\n","Epoch 72/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0748 - cindex_score: 0.9045 - val_loss: 0.2003 - val_cindex_score: 0.8532\n","Epoch 73/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0741 - cindex_score: 0.9068 - val_loss: 0.2038 - val_cindex_score: 0.8538\n","Epoch 74/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0725 - cindex_score: 0.9072 - val_loss: 0.1999 - val_cindex_score: 0.8540\n","Epoch 75/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0785 - cindex_score: 0.9044 - val_loss: 0.2013 - val_cindex_score: 0.8526\n","Epoch 76/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0729 - cindex_score: 0.9076 - val_loss: 0.2040 - val_cindex_score: 0.8528\n","Epoch 77/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0719 - cindex_score: 0.9086 - val_loss: 0.2075 - val_cindex_score: 0.8527\n","Epoch 78/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0717 - cindex_score: 0.9094 - val_loss: 0.2134 - val_cindex_score: 0.8521\n","Epoch 79/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0720 - cindex_score: 0.9089 - val_loss: 0.2039 - val_cindex_score: 0.8541\n","Epoch 80/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.0707 - cindex_score: 0.9093 - val_loss: 0.2009 - val_cindex_score: 0.8558\n","Epoch 81/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0697 - cindex_score: 0.9110 - val_loss: 0.2032 - val_cindex_score: 0.8529\n","Epoch 82/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0715 - cindex_score: 0.9116 - val_loss: 0.2060 - val_cindex_score: 0.8558\n","Epoch 83/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0739 - cindex_score: 0.9097 - val_loss: 0.2124 - val_cindex_score: 0.8539\n","Epoch 84/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0693 - cindex_score: 0.9124 - val_loss: 0.2046 - val_cindex_score: 0.8554\n","Epoch 85/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0798 - cindex_score: 0.9070 - val_loss: 0.2073 - val_cindex_score: 0.8515\n","Epoch 86/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0727 - cindex_score: 0.9112 - val_loss: 0.2008 - val_cindex_score: 0.8559\n","Epoch 87/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0715 - cindex_score: 0.9146 - val_loss: 0.2042 - val_cindex_score: 0.8551\n","Epoch 88/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0712 - cindex_score: 0.9147 - val_loss: 0.2181 - val_cindex_score: 0.8561\n","Epoch 89/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0663 - cindex_score: 0.9162 - val_loss: 0.2106 - val_cindex_score: 0.8559\n","Epoch 00089: early stopping\n","run_experiments.py:453: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:466: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:480: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n"]}],"source":["!./go.sh"]},{"cell_type":"markdown","source":["## Loading Pre-trained Models"],"metadata":{"id":"xz_WlZz3iPNq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xg09XNlZpO8v"},"outputs":[],"source":["def cindex_score(y_true, y_pred):\n","\n","    g = tf.subtract(tf.expand_dims(y_pred, -1), y_pred)\n","    g = tf.cast(g == 0.0, tf.float32) * 0.5 + tf.cast(g > 0.0, tf.float32)\n","\n","    f = tf.subtract(tf.expand_dims(y_true, -1), y_true) > 0.0\n","    f = tf.matrix_band_part(tf.cast(f, tf.float32), -1, 0)\n","\n","    g = tf.reduce_sum(tf.multiply(g, f))\n","    f = tf.reduce_sum(f)\n","\n","    return tf.where(tf.equal(g, 0), 0.0, g/f) #select"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6tWE13p2lBAP"},"outputs":[],"source":["from keras.models import load_model\n","model = load_model('combined_davis.01-0.66.h5', custom_objects={\"cindex_score\": cindex_score})"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":452,"status":"ok","timestamp":1649983021156,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"},"user_tz":300},"id":"it7MuSWlpXIl","outputId":"41d71cd5-0822-4aa6-967d-08c851e421b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_7\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_13 (InputLayer)          [(None, 100)]        0           []                               \n","                                                                                                  \n"," input_14 (InputLayer)          [(None, 1000)]       0           []                               \n","                                                                                                  \n"," embedding_13 (Embedding)       (None, 100, 128)     8320        ['input_13[0][0]']               \n","                                                                                                  \n"," embedding_14 (Embedding)       (None, 1000, 128)    3328        ['input_14[0][0]']               \n","                                                                                                  \n"," conv1d_37 (Conv1D)             (None, 93, 32)       32800       ['embedding_13[0][0]']           \n","                                                                                                  \n"," conv1d_40 (Conv1D)             (None, 989, 32)      49184       ['embedding_14[0][0]']           \n","                                                                                                  \n"," conv1d_38 (Conv1D)             (None, 86, 64)       16448       ['conv1d_37[0][0]']              \n","                                                                                                  \n"," conv1d_41 (Conv1D)             (None, 978, 64)      24640       ['conv1d_40[0][0]']              \n","                                                                                                  \n"," conv1d_39 (Conv1D)             (None, 79, 96)       49248       ['conv1d_38[0][0]']              \n","                                                                                                  \n"," conv1d_42 (Conv1D)             (None, 967, 96)      73824       ['conv1d_41[0][0]']              \n","                                                                                                  \n"," global_max_pooling1d_13 (Globa  (None, 96)          0           ['conv1d_39[0][0]']              \n"," lMaxPooling1D)                                                                                   \n","                                                                                                  \n"," global_max_pooling1d_14 (Globa  (None, 96)          0           ['conv1d_42[0][0]']              \n"," lMaxPooling1D)                                                                                   \n","                                                                                                  \n"," concatenate_7 (Concatenate)    (None, 192)          0           ['global_max_pooling1d_13[0][0]',\n","                                                                  'global_max_pooling1d_14[0][0]']\n","                                                                                                  \n"," dense_25 (Dense)               (None, 1024)         197632      ['concatenate_7[0][0]']          \n","                                                                                                  \n"," dropout_13 (Dropout)           (None, 1024)         0           ['dense_25[0][0]']               \n","                                                                                                  \n"," dense_26 (Dense)               (None, 1024)         1049600     ['dropout_13[0][0]']             \n","                                                                                                  \n"," dropout_14 (Dropout)           (None, 1024)         0           ['dense_26[0][0]']               \n","                                                                                                  \n"," dense_27 (Dense)               (None, 512)          524800      ['dropout_14[0][0]']             \n","                                                                                                  \n"," dense_28 (Dense)               (None, 1)            513         ['dense_27[0][0]']               \n","                                                                                                  \n","==================================================================================================\n","Total params: 2,030,337\n","Trainable params: 2,030,337\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"22ZQKxHMqIvQ"},"outputs":[],"source":["model.predict()"]},{"cell_type":"markdown","source":["## Without Early Stopping"],"metadata":{"id":"Cx3KNW1geNF1"}},{"cell_type":"markdown","source":["### Baselines"],"metadata":{"id":"G5FULvB6FlYW"}},{"cell_type":"markdown","source":["#### KIBA"],"metadata":{"id":"h_rCn3J6FnBv"}},{"cell_type":"code","source":["!./go.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t70WX0CiFozg","executionInfo":{"status":"ok","timestamp":1651602905166,"user_tz":300,"elapsed":1493369,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"}},"outputId":"983d2d6b-90df-4914-ecce-c47cdf344c1b"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From run_experiments.py:16: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","Using TensorFlow backend.\n","WARNING:tensorflow:From run_experiments.py:19: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","2022-05-03 18:10:13.356926: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n","2022-05-03 18:10:13.357089: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1fdd2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2022-05-03 18:10:13.357116: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2022-05-03 18:10:13.358744: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2022-05-03 18:10:13.581754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 18:10:13.582522: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1fdd640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2022-05-03 18:10:13.582553: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2022-05-03 18:10:13.582748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 18:10:13.583290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2022-05-03 18:10:13.583567: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-05-03 18:10:13.585096: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-05-03 18:10:13.585942: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2022-05-03 18:10:13.586220: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2022-05-03 18:10:13.587676: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2022-05-03 18:10:13.588398: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2022-05-03 18:10:13.591380: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-05-03 18:10:13.591488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 18:10:13.592077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 18:10:13.592579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2022-05-03 18:10:13.592668: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-05-03 18:10:13.593622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-05-03 18:10:13.593646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2022-05-03 18:10:13.593657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2022-05-03 18:10:13.593761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 18:10:13.594314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 18:10:13.594825: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-05-03 18:10:13.594866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","Read data/kiba/ start\n","2111\n","229\n","logs/1651601414.3064923/\n","Reading data/kiba/ start\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","[[0, 0, 0, 0, 0]]\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From run_experiments.py:435: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n","\n","WARNING:tensorflow:From run_experiments.py:440: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1)            101         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1)            1001        input_2[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 2)            0           dense_1[0][0]                    \n","                                                                 dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 1024)         3072        concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 1024)         0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 1024)         1049600     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 1024)         0           dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 512)          524800      dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 1)            513         dense_5[0][0]                    \n","==================================================================================================\n","Total params: 1,579,087\n","Trainable params: 1,579,087\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 78836 samples, validate on 19709 samples\n","Epoch 1/100\n","2022-05-03 18:10:16.925114: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","78836/78836 [==============================] - 2s 27us/step - loss: 2.5397 - cindex_score: 0.5231 - val_loss: 2.5321 - val_cindex_score: 0.5490\n","Epoch 2/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.9358 - cindex_score: 0.5658 - val_loss: 1.4739 - val_cindex_score: 0.6053\n","Epoch 3/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.8083 - cindex_score: 0.5967 - val_loss: 1.5134 - val_cindex_score: 0.6382\n","Epoch 4/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.7433 - cindex_score: 0.6166 - val_loss: 2.4539 - val_cindex_score: 0.6572\n","Epoch 5/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.7292 - cindex_score: 0.6281 - val_loss: 1.6016 - val_cindex_score: 0.6638\n","Epoch 6/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.7120 - cindex_score: 0.6341 - val_loss: 2.1165 - val_cindex_score: 0.6708\n","Epoch 7/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.7068 - cindex_score: 0.6368 - val_loss: 1.9903 - val_cindex_score: 0.6723\n","Epoch 8/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6932 - cindex_score: 0.6395 - val_loss: 2.1639 - val_cindex_score: 0.6744\n","Epoch 9/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6917 - cindex_score: 0.6410 - val_loss: 1.7687 - val_cindex_score: 0.6738\n","Epoch 10/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6946 - cindex_score: 0.6419 - val_loss: 1.8362 - val_cindex_score: 0.6767\n","Epoch 11/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.7034 - cindex_score: 0.6425 - val_loss: 1.5897 - val_cindex_score: 0.6755\n","Epoch 12/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6825 - cindex_score: 0.6462 - val_loss: 1.3402 - val_cindex_score: 0.6758\n","Epoch 13/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6762 - cindex_score: 0.6476 - val_loss: 1.4217 - val_cindex_score: 0.6785\n","Epoch 14/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6721 - cindex_score: 0.6492 - val_loss: 1.3358 - val_cindex_score: 0.6782\n","Epoch 15/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6658 - cindex_score: 0.6499 - val_loss: 1.2779 - val_cindex_score: 0.6794\n","Epoch 16/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6694 - cindex_score: 0.6510 - val_loss: 1.4121 - val_cindex_score: 0.6811\n","Epoch 17/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6647 - cindex_score: 0.6517 - val_loss: 1.4594 - val_cindex_score: 0.6821\n","Epoch 18/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6568 - cindex_score: 0.6537 - val_loss: 1.3837 - val_cindex_score: 0.6841\n","Epoch 19/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6603 - cindex_score: 0.6551 - val_loss: 1.3575 - val_cindex_score: 0.6827\n","Epoch 20/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6526 - cindex_score: 0.6573 - val_loss: 1.4218 - val_cindex_score: 0.6856\n","Epoch 21/100\n","78836/78836 [==============================] - 2s 20us/step - loss: 0.6494 - cindex_score: 0.6595 - val_loss: 1.4385 - val_cindex_score: 0.6870\n","Epoch 22/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6476 - cindex_score: 0.6604 - val_loss: 1.4971 - val_cindex_score: 0.6884\n","Epoch 23/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6400 - cindex_score: 0.6641 - val_loss: 1.4744 - val_cindex_score: 0.6896\n","Epoch 24/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6355 - cindex_score: 0.6653 - val_loss: 1.4167 - val_cindex_score: 0.6912\n","Epoch 25/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6356 - cindex_score: 0.6652 - val_loss: 1.6564 - val_cindex_score: 0.6917\n","Epoch 26/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6340 - cindex_score: 0.6653 - val_loss: 1.4255 - val_cindex_score: 0.6936\n","Epoch 27/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6311 - cindex_score: 0.6668 - val_loss: 1.6136 - val_cindex_score: 0.6931\n","Epoch 28/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6297 - cindex_score: 0.6676 - val_loss: 1.4447 - val_cindex_score: 0.6939\n","Epoch 29/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6289 - cindex_score: 0.6683 - val_loss: 1.5694 - val_cindex_score: 0.6932\n","Epoch 30/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6275 - cindex_score: 0.6691 - val_loss: 1.6717 - val_cindex_score: 0.6941\n","Epoch 31/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6319 - cindex_score: 0.6693 - val_loss: 1.6969 - val_cindex_score: 0.6938\n","Epoch 32/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6230 - cindex_score: 0.6688 - val_loss: 1.4821 - val_cindex_score: 0.6945\n","Epoch 33/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6241 - cindex_score: 0.6701 - val_loss: 1.6062 - val_cindex_score: 0.6949\n","Epoch 34/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6255 - cindex_score: 0.6697 - val_loss: 1.5046 - val_cindex_score: 0.6953\n","Epoch 35/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6255 - cindex_score: 0.6704 - val_loss: 1.6799 - val_cindex_score: 0.6942\n","Epoch 36/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6248 - cindex_score: 0.6695 - val_loss: 1.7234 - val_cindex_score: 0.6941\n","Epoch 37/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6217 - cindex_score: 0.6703 - val_loss: 1.6629 - val_cindex_score: 0.6950\n","Epoch 38/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6234 - cindex_score: 0.6700 - val_loss: 1.5228 - val_cindex_score: 0.6943\n","Epoch 39/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6194 - cindex_score: 0.6711 - val_loss: 1.5639 - val_cindex_score: 0.6952\n","Epoch 40/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6198 - cindex_score: 0.6715 - val_loss: 1.4086 - val_cindex_score: 0.6951\n","Epoch 41/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6201 - cindex_score: 0.6712 - val_loss: 1.7149 - val_cindex_score: 0.6940\n","Epoch 42/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6200 - cindex_score: 0.6717 - val_loss: 1.5622 - val_cindex_score: 0.6944\n","Epoch 43/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6177 - cindex_score: 0.6720 - val_loss: 1.6132 - val_cindex_score: 0.6956\n","Epoch 44/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6177 - cindex_score: 0.6728 - val_loss: 1.5270 - val_cindex_score: 0.6947\n","Epoch 45/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6179 - cindex_score: 0.6724 - val_loss: 1.5894 - val_cindex_score: 0.6952\n","Epoch 46/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6184 - cindex_score: 0.6724 - val_loss: 1.5922 - val_cindex_score: 0.6951\n","Epoch 47/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6161 - cindex_score: 0.6723 - val_loss: 1.5684 - val_cindex_score: 0.6956\n","Epoch 48/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6139 - cindex_score: 0.6737 - val_loss: 1.6454 - val_cindex_score: 0.6965\n","Epoch 49/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6115 - cindex_score: 0.6744 - val_loss: 1.5614 - val_cindex_score: 0.6968\n","Epoch 50/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6155 - cindex_score: 0.6734 - val_loss: 1.6495 - val_cindex_score: 0.6964\n","Epoch 51/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6119 - cindex_score: 0.6729 - val_loss: 1.5070 - val_cindex_score: 0.6960\n","Epoch 52/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6125 - cindex_score: 0.6747 - val_loss: 1.6435 - val_cindex_score: 0.6962\n","Epoch 53/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6116 - cindex_score: 0.6746 - val_loss: 1.4262 - val_cindex_score: 0.6959\n","Epoch 54/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6122 - cindex_score: 0.6749 - val_loss: 1.6192 - val_cindex_score: 0.6964\n","Epoch 55/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6126 - cindex_score: 0.6742 - val_loss: 1.6679 - val_cindex_score: 0.6971\n","Epoch 56/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6129 - cindex_score: 0.6746 - val_loss: 1.5325 - val_cindex_score: 0.6967\n","Epoch 57/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6083 - cindex_score: 0.6760 - val_loss: 1.5635 - val_cindex_score: 0.6968\n","Epoch 58/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6096 - cindex_score: 0.6749 - val_loss: 1.5967 - val_cindex_score: 0.6967\n","Epoch 59/100\n","78836/78836 [==============================] - 2s 20us/step - loss: 0.6120 - cindex_score: 0.6745 - val_loss: 1.5657 - val_cindex_score: 0.6965\n","Epoch 60/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6093 - cindex_score: 0.6748 - val_loss: 1.4573 - val_cindex_score: 0.6963\n","Epoch 61/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6116 - cindex_score: 0.6747 - val_loss: 1.4578 - val_cindex_score: 0.6957\n","Epoch 62/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6096 - cindex_score: 0.6754 - val_loss: 1.4481 - val_cindex_score: 0.6958\n","Epoch 63/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6092 - cindex_score: 0.6765 - val_loss: 1.6416 - val_cindex_score: 0.6965\n","Epoch 64/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6127 - cindex_score: 0.6751 - val_loss: 1.6041 - val_cindex_score: 0.6967\n","Epoch 65/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6101 - cindex_score: 0.6759 - val_loss: 1.6744 - val_cindex_score: 0.6960\n","Epoch 66/100\n","78836/78836 [==============================] - 2s 20us/step - loss: 0.6090 - cindex_score: 0.6758 - val_loss: 1.6049 - val_cindex_score: 0.6969\n","Epoch 67/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6114 - cindex_score: 0.6742 - val_loss: 1.5657 - val_cindex_score: 0.6966\n","Epoch 68/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6099 - cindex_score: 0.6756 - val_loss: 1.5615 - val_cindex_score: 0.6969\n","Epoch 69/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6080 - cindex_score: 0.6767 - val_loss: 1.6181 - val_cindex_score: 0.6974\n","Epoch 70/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6063 - cindex_score: 0.6768 - val_loss: 1.5383 - val_cindex_score: 0.6963\n","Epoch 71/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6051 - cindex_score: 0.6778 - val_loss: 1.5598 - val_cindex_score: 0.6963\n","Epoch 72/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6058 - cindex_score: 0.6766 - val_loss: 1.4514 - val_cindex_score: 0.6968\n","Epoch 73/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6068 - cindex_score: 0.6776 - val_loss: 1.6287 - val_cindex_score: 0.6968\n","Epoch 74/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6043 - cindex_score: 0.6775 - val_loss: 1.5552 - val_cindex_score: 0.6966\n","Epoch 75/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6100 - cindex_score: 0.6760 - val_loss: 1.5931 - val_cindex_score: 0.6968\n","Epoch 76/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6075 - cindex_score: 0.6773 - val_loss: 1.5911 - val_cindex_score: 0.6968\n","Epoch 77/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6064 - cindex_score: 0.6776 - val_loss: 1.6201 - val_cindex_score: 0.6967\n","Epoch 78/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6077 - cindex_score: 0.6777 - val_loss: 1.6136 - val_cindex_score: 0.6977\n","Epoch 79/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6016 - cindex_score: 0.6790 - val_loss: 1.5878 - val_cindex_score: 0.6965\n","Epoch 80/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6031 - cindex_score: 0.6790 - val_loss: 1.5122 - val_cindex_score: 0.6972\n","Epoch 81/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6078 - cindex_score: 0.6782 - val_loss: 1.5744 - val_cindex_score: 0.6974\n","Epoch 82/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6036 - cindex_score: 0.6795 - val_loss: 1.5306 - val_cindex_score: 0.6976\n","Epoch 83/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6068 - cindex_score: 0.6782 - val_loss: 1.4842 - val_cindex_score: 0.6972\n","Epoch 84/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6044 - cindex_score: 0.6788 - val_loss: 1.5435 - val_cindex_score: 0.6978\n","Epoch 85/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6038 - cindex_score: 0.6789 - val_loss: 1.5206 - val_cindex_score: 0.6973\n","Epoch 86/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6029 - cindex_score: 0.6795 - val_loss: 1.4546 - val_cindex_score: 0.6976\n","Epoch 87/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6010 - cindex_score: 0.6800 - val_loss: 1.4945 - val_cindex_score: 0.6977\n","Epoch 88/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6025 - cindex_score: 0.6805 - val_loss: 1.5723 - val_cindex_score: 0.6970\n","Epoch 89/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6036 - cindex_score: 0.6803 - val_loss: 1.5582 - val_cindex_score: 0.6969\n","Epoch 90/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5996 - cindex_score: 0.6810 - val_loss: 1.5177 - val_cindex_score: 0.6979\n","Epoch 91/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6002 - cindex_score: 0.6812 - val_loss: 1.4947 - val_cindex_score: 0.6972\n","Epoch 92/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5999 - cindex_score: 0.6808 - val_loss: 1.3803 - val_cindex_score: 0.6980\n","Epoch 93/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5954 - cindex_score: 0.6822 - val_loss: 1.3188 - val_cindex_score: 0.6981\n","Epoch 94/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5984 - cindex_score: 0.6811 - val_loss: 1.3869 - val_cindex_score: 0.6978\n","Epoch 95/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6005 - cindex_score: 0.6818 - val_loss: 1.3463 - val_cindex_score: 0.6978\n","Epoch 96/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5956 - cindex_score: 0.6824 - val_loss: 1.3184 - val_cindex_score: 0.6974\n","Epoch 97/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6001 - cindex_score: 0.6818 - val_loss: 1.2804 - val_cindex_score: 0.6976\n","Epoch 98/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5969 - cindex_score: 0.6825 - val_loss: 1.4448 - val_cindex_score: 0.6969\n","Epoch 99/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6022 - cindex_score: 0.6823 - val_loss: 1.3252 - val_cindex_score: 0.6973\n","Epoch 100/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5954 - cindex_score: 0.6833 - val_loss: 1.2410 - val_cindex_score: 0.6971\n","run_experiments.py:456: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:469: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:483: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","[[0, 0, 0, 0, 0]]\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 1)            101         input_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 1)            1001        input_4[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 2)            0           dense_7[0][0]                    \n","                                                                 dense_8[0][0]                    \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 1024)         3072        concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 1024)         0           dense_9[0][0]                    \n","__________________________________________________________________________________________________\n","dense_10 (Dense)                (None, 1024)         1049600     dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 1024)         0           dense_10[0][0]                   \n","__________________________________________________________________________________________________\n","dense_11 (Dense)                (None, 512)          524800      dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","dense_12 (Dense)                (None, 1)            513         dense_11[0][0]                   \n","==================================================================================================\n","Total params: 1,579,087\n","Trainable params: 1,579,087\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Train on 78836 samples, validate on 19709 samples\n","Epoch 1/100\n","78836/78836 [==============================] - 2s 26us/step - loss: 3.0280 - cindex_score: 0.5400 - val_loss: 1.4462 - val_cindex_score: 0.5648\n","Epoch 2/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.9227 - cindex_score: 0.5738 - val_loss: 1.5603 - val_cindex_score: 0.6110\n","Epoch 3/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.7989 - cindex_score: 0.5972 - val_loss: 1.9024 - val_cindex_score: 0.6414\n","Epoch 4/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.7679 - cindex_score: 0.6107 - val_loss: 2.1285 - val_cindex_score: 0.6548\n","Epoch 5/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.7377 - cindex_score: 0.6203 - val_loss: 1.9701 - val_cindex_score: 0.6645\n","Epoch 6/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.7326 - cindex_score: 0.6265 - val_loss: 2.4529 - val_cindex_score: 0.6698\n","Epoch 7/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.7117 - cindex_score: 0.6315 - val_loss: 2.3150 - val_cindex_score: 0.6723\n","Epoch 8/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.7049 - cindex_score: 0.6364 - val_loss: 1.9052 - val_cindex_score: 0.6753\n","Epoch 9/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6939 - cindex_score: 0.6387 - val_loss: 1.9384 - val_cindex_score: 0.6767\n","Epoch 10/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6885 - cindex_score: 0.6410 - val_loss: 1.9175 - val_cindex_score: 0.6789\n","Epoch 11/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6843 - cindex_score: 0.6421 - val_loss: 1.7822 - val_cindex_score: 0.6799\n","Epoch 12/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6847 - cindex_score: 0.6449 - val_loss: 1.9636 - val_cindex_score: 0.6811\n","Epoch 13/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6895 - cindex_score: 0.6462 - val_loss: 1.4892 - val_cindex_score: 0.6808\n","Epoch 14/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6778 - cindex_score: 0.6474 - val_loss: 1.4370 - val_cindex_score: 0.6825\n","Epoch 15/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6710 - cindex_score: 0.6487 - val_loss: 1.5171 - val_cindex_score: 0.6840\n","Epoch 16/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6716 - cindex_score: 0.6495 - val_loss: 1.4066 - val_cindex_score: 0.6850\n","Epoch 17/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6634 - cindex_score: 0.6519 - val_loss: 1.3790 - val_cindex_score: 0.6853\n","Epoch 18/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6633 - cindex_score: 0.6520 - val_loss: 1.4447 - val_cindex_score: 0.6866\n","Epoch 19/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6600 - cindex_score: 0.6540 - val_loss: 1.3072 - val_cindex_score: 0.6860\n","Epoch 20/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6548 - cindex_score: 0.6557 - val_loss: 1.5549 - val_cindex_score: 0.6895\n","Epoch 21/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6558 - cindex_score: 0.6571 - val_loss: 1.5081 - val_cindex_score: 0.6894\n","Epoch 22/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6543 - cindex_score: 0.6573 - val_loss: 1.3308 - val_cindex_score: 0.6900\n","Epoch 23/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6507 - cindex_score: 0.6600 - val_loss: 1.5077 - val_cindex_score: 0.6908\n","Epoch 24/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6483 - cindex_score: 0.6611 - val_loss: 1.5570 - val_cindex_score: 0.6919\n","Epoch 25/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6439 - cindex_score: 0.6626 - val_loss: 1.4765 - val_cindex_score: 0.6928\n","Epoch 26/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6387 - cindex_score: 0.6636 - val_loss: 1.6287 - val_cindex_score: 0.6932\n","Epoch 27/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6367 - cindex_score: 0.6657 - val_loss: 1.6002 - val_cindex_score: 0.6961\n","Epoch 28/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6342 - cindex_score: 0.6668 - val_loss: 1.7128 - val_cindex_score: 0.6962\n","Epoch 29/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6274 - cindex_score: 0.6691 - val_loss: 1.6889 - val_cindex_score: 0.6970\n","Epoch 30/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6253 - cindex_score: 0.6684 - val_loss: 1.6480 - val_cindex_score: 0.6980\n","Epoch 31/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6249 - cindex_score: 0.6691 - val_loss: 1.4711 - val_cindex_score: 0.6995\n","Epoch 32/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6219 - cindex_score: 0.6717 - val_loss: 1.5477 - val_cindex_score: 0.6996\n","Epoch 33/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6224 - cindex_score: 0.6709 - val_loss: 1.4201 - val_cindex_score: 0.6995\n","Epoch 34/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6221 - cindex_score: 0.6716 - val_loss: 1.5463 - val_cindex_score: 0.7009\n","Epoch 35/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6207 - cindex_score: 0.6721 - val_loss: 1.7602 - val_cindex_score: 0.7004\n","Epoch 36/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6181 - cindex_score: 0.6725 - val_loss: 1.7331 - val_cindex_score: 0.7018\n","Epoch 37/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6208 - cindex_score: 0.6731 - val_loss: 1.5815 - val_cindex_score: 0.7014\n","Epoch 38/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6141 - cindex_score: 0.6743 - val_loss: 1.5126 - val_cindex_score: 0.7013\n","Epoch 39/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6116 - cindex_score: 0.6755 - val_loss: 1.5109 - val_cindex_score: 0.7019\n","Epoch 40/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6108 - cindex_score: 0.6757 - val_loss: 1.6479 - val_cindex_score: 0.7016\n","Epoch 41/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6122 - cindex_score: 0.6751 - val_loss: 1.4559 - val_cindex_score: 0.7031\n","Epoch 42/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6106 - cindex_score: 0.6746 - val_loss: 1.5711 - val_cindex_score: 0.7016\n","Epoch 43/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.6119 - cindex_score: 0.6759 - val_loss: 1.6305 - val_cindex_score: 0.7022\n","Epoch 44/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6072 - cindex_score: 0.6774 - val_loss: 1.6376 - val_cindex_score: 0.7026\n","Epoch 45/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6127 - cindex_score: 0.6776 - val_loss: 1.6424 - val_cindex_score: 0.7019\n","Epoch 46/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6071 - cindex_score: 0.6767 - val_loss: 1.7213 - val_cindex_score: 0.7033\n","Epoch 47/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6048 - cindex_score: 0.6776 - val_loss: 1.6988 - val_cindex_score: 0.7025\n","Epoch 48/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6067 - cindex_score: 0.6769 - val_loss: 1.7206 - val_cindex_score: 0.7025\n","Epoch 49/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6032 - cindex_score: 0.6780 - val_loss: 1.7907 - val_cindex_score: 0.7020\n","Epoch 50/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6061 - cindex_score: 0.6772 - val_loss: 1.6172 - val_cindex_score: 0.7028\n","Epoch 51/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6099 - cindex_score: 0.6776 - val_loss: 1.7013 - val_cindex_score: 0.7028\n","Epoch 52/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6061 - cindex_score: 0.6780 - val_loss: 1.6291 - val_cindex_score: 0.7033\n","Epoch 53/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6007 - cindex_score: 0.6791 - val_loss: 1.5390 - val_cindex_score: 0.7029\n","Epoch 54/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6020 - cindex_score: 0.6781 - val_loss: 1.7895 - val_cindex_score: 0.7026\n","Epoch 55/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6090 - cindex_score: 0.6781 - val_loss: 1.6665 - val_cindex_score: 0.7031\n","Epoch 56/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6070 - cindex_score: 0.6782 - val_loss: 1.2569 - val_cindex_score: 0.7019\n","Epoch 57/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6017 - cindex_score: 0.6789 - val_loss: 1.7472 - val_cindex_score: 0.7015\n","Epoch 58/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6021 - cindex_score: 0.6784 - val_loss: 1.6245 - val_cindex_score: 0.7030\n","Epoch 59/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6010 - cindex_score: 0.6800 - val_loss: 1.6565 - val_cindex_score: 0.7028\n","Epoch 60/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.6024 - cindex_score: 0.6797 - val_loss: 1.6705 - val_cindex_score: 0.7033\n","Epoch 61/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5996 - cindex_score: 0.6797 - val_loss: 1.5738 - val_cindex_score: 0.7015\n","Epoch 62/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5990 - cindex_score: 0.6791 - val_loss: 1.6474 - val_cindex_score: 0.7021\n","Epoch 63/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5983 - cindex_score: 0.6787 - val_loss: 1.6009 - val_cindex_score: 0.7029\n","Epoch 64/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5998 - cindex_score: 0.6795 - val_loss: 1.6581 - val_cindex_score: 0.7021\n","Epoch 65/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5996 - cindex_score: 0.6801 - val_loss: 1.5535 - val_cindex_score: 0.7027\n","Epoch 66/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5984 - cindex_score: 0.6805 - val_loss: 1.4898 - val_cindex_score: 0.7019\n","Epoch 67/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5994 - cindex_score: 0.6796 - val_loss: 1.5848 - val_cindex_score: 0.7021\n","Epoch 68/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.5968 - cindex_score: 0.6803 - val_loss: 1.5478 - val_cindex_score: 0.7027\n","Epoch 69/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5984 - cindex_score: 0.6807 - val_loss: 1.6271 - val_cindex_score: 0.7029\n","Epoch 70/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.5982 - cindex_score: 0.6809 - val_loss: 1.5309 - val_cindex_score: 0.7024\n","Epoch 71/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5964 - cindex_score: 0.6811 - val_loss: 1.5957 - val_cindex_score: 0.7025\n","Epoch 72/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5953 - cindex_score: 0.6819 - val_loss: 1.6764 - val_cindex_score: 0.7023\n","Epoch 73/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5966 - cindex_score: 0.6813 - val_loss: 1.6221 - val_cindex_score: 0.7026\n","Epoch 74/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5976 - cindex_score: 0.6817 - val_loss: 1.6266 - val_cindex_score: 0.7025\n","Epoch 75/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5947 - cindex_score: 0.6814 - val_loss: 1.7833 - val_cindex_score: 0.7019\n","Epoch 76/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5987 - cindex_score: 0.6808 - val_loss: 1.5959 - val_cindex_score: 0.7028\n","Epoch 77/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5991 - cindex_score: 0.6810 - val_loss: 1.8578 - val_cindex_score: 0.7032\n","Epoch 78/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.5961 - cindex_score: 0.6812 - val_loss: 1.5667 - val_cindex_score: 0.7026\n","Epoch 79/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5964 - cindex_score: 0.6810 - val_loss: 1.5932 - val_cindex_score: 0.7023\n","Epoch 80/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5961 - cindex_score: 0.6813 - val_loss: 1.6460 - val_cindex_score: 0.7021\n","Epoch 81/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5937 - cindex_score: 0.6817 - val_loss: 1.6268 - val_cindex_score: 0.7029\n","Epoch 82/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5944 - cindex_score: 0.6817 - val_loss: 1.5692 - val_cindex_score: 0.7031\n","Epoch 83/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5969 - cindex_score: 0.6814 - val_loss: 1.6468 - val_cindex_score: 0.7028\n","Epoch 84/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5932 - cindex_score: 0.6821 - val_loss: 1.4902 - val_cindex_score: 0.7035\n","Epoch 85/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5933 - cindex_score: 0.6826 - val_loss: 1.5490 - val_cindex_score: 0.7023\n","Epoch 86/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5926 - cindex_score: 0.6827 - val_loss: 1.5405 - val_cindex_score: 0.7025\n","Epoch 87/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5926 - cindex_score: 0.6820 - val_loss: 1.4752 - val_cindex_score: 0.7028\n","Epoch 88/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5928 - cindex_score: 0.6822 - val_loss: 1.5378 - val_cindex_score: 0.7018\n","Epoch 89/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5924 - cindex_score: 0.6825 - val_loss: 1.4543 - val_cindex_score: 0.7033\n","Epoch 90/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5957 - cindex_score: 0.6825 - val_loss: 1.5959 - val_cindex_score: 0.7024\n","Epoch 91/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5923 - cindex_score: 0.6836 - val_loss: 1.6069 - val_cindex_score: 0.7020\n","Epoch 92/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5902 - cindex_score: 0.6840 - val_loss: 1.5685 - val_cindex_score: 0.7024\n","Epoch 93/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5924 - cindex_score: 0.6837 - val_loss: 1.6450 - val_cindex_score: 0.7019\n","Epoch 94/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5890 - cindex_score: 0.6843 - val_loss: 1.4936 - val_cindex_score: 0.7011\n","Epoch 95/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5923 - cindex_score: 0.6838 - val_loss: 1.5565 - val_cindex_score: 0.7031\n","Epoch 96/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5883 - cindex_score: 0.6832 - val_loss: 1.6054 - val_cindex_score: 0.7031\n","Epoch 97/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5929 - cindex_score: 0.6838 - val_loss: 1.6057 - val_cindex_score: 0.7030\n","Epoch 98/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5896 - cindex_score: 0.6843 - val_loss: 1.6371 - val_cindex_score: 0.7023\n","Epoch 99/100\n","78836/78836 [==============================] - 2s 22us/step - loss: 0.5879 - cindex_score: 0.6844 - val_loss: 1.5071 - val_cindex_score: 0.7031\n","Epoch 100/100\n","78836/78836 [==============================] - 2s 21us/step - loss: 0.5902 - cindex_score: 0.6847 - val_loss: 1.5902 - val_cindex_score: 0.7035\n","run_experiments.py:456: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:469: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:483: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n"]}]},{"cell_type":"markdown","source":["### Single Protein"],"metadata":{"id":"v8G9OATzvwoB"}},{"cell_type":"markdown","source":["#### KIBA"],"metadata":{"id":"wOhZgmx_vyUr"}},{"cell_type":"code","source":["!./go.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kf8lHCacv0_t","outputId":"1b4d356e-0db4-498d-a346-e6ab6f6e47c3","executionInfo":{"status":"ok","timestamp":1651600784251,"user_tz":300,"elapsed":658977,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"}}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From run_experiments.py:16: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","Using TensorFlow backend.\n","WARNING:tensorflow:From run_experiments.py:19: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","2022-05-03 16:29:20.648371: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n","2022-05-03 16:29:20.648521: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x20f52c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2022-05-03 16:29:20.648550: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2022-05-03 16:29:20.650226: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2022-05-03 16:29:20.879358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 16:29:20.880352: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x20f5640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2022-05-03 16:29:20.880395: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2022-05-03 16:29:20.880665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 16:29:20.881238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2022-05-03 16:29:20.881543: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-05-03 16:29:20.883170: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-05-03 16:29:20.884108: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2022-05-03 16:29:20.884418: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2022-05-03 16:29:20.886026: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2022-05-03 16:29:20.886722: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2022-05-03 16:29:20.890017: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-05-03 16:29:20.890120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 16:29:20.890678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 16:29:20.891194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2022-05-03 16:29:20.891255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-05-03 16:29:20.892216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-05-03 16:29:20.892241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2022-05-03 16:29:20.892252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2022-05-03 16:29:20.892355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 16:29:20.892907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 16:29:20.893419: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-05-03 16:29:20.893459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","Read data/kiba/ start\n","2111\n","229\n","logs/1651595361.5802426/\n","Reading data/kiba/ start\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","[[0, 0, 0, 0, 0]]\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From run_experiments.py:435: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n","\n","WARNING:tensorflow:From run_experiments.py:440: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 1000, 128)    3328        input_2[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_1 (Conv1D)               (None, 993, 32)      32800       embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_2 (Conv1D)               (None, 986, 64)      16448       conv1d_1[0][0]                   \n","__________________________________________________________________________________________________\n","input_1 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","conv1d_3 (Conv1D)               (None, 979, 96)      49248       conv1d_2[0][0]                   \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1)            101         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","global_max_pooling1d_1 (GlobalM (None, 96)           0           conv1d_3[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 97)           0           dense_1[0][0]                    \n","                                                                 global_max_pooling1d_1[0][0]     \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1024)         100352      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 1024)         1049600     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 1024)         0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 512)          524800      dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 1)            513         dense_4[0][0]                    \n","==================================================================================================\n","Total params: 1,777,190\n","Trainable params: 1,777,190\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 78836 samples, validate on 19709 samples\n","Epoch 1/100\n","2022-05-03 16:29:24.588696: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-05-03 16:29:24.844299: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","78836/78836 [==============================] - 23s 287us/step - loss: 2.7195 - cindex_score: 0.5454 - val_loss: 0.6445 - val_cindex_score: 0.6469\n","Epoch 2/100\n","78836/78836 [==============================] - 20s 256us/step - loss: 0.8162 - cindex_score: 0.5919 - val_loss: 1.1839 - val_cindex_score: 0.6680\n","Epoch 3/100\n","78836/78836 [==============================] - 20s 256us/step - loss: 0.7874 - cindex_score: 0.6119 - val_loss: 0.7149 - val_cindex_score: 0.6737\n","Epoch 4/100\n","78836/78836 [==============================] - 20s 256us/step - loss: 0.8076 - cindex_score: 0.6185 - val_loss: 0.6776 - val_cindex_score: 0.6774\n","Epoch 5/100\n","78836/78836 [==============================] - 20s 257us/step - loss: 0.7681 - cindex_score: 0.6221 - val_loss: 0.7641 - val_cindex_score: 0.6771\n","Epoch 6/100\n","78836/78836 [==============================] - 20s 259us/step - loss: 0.7565 - cindex_score: 0.6262 - val_loss: 0.7683 - val_cindex_score: 0.6744\n","Epoch 7/100\n","78836/78836 [==============================] - 21s 263us/step - loss: 0.7687 - cindex_score: 0.6251 - val_loss: 1.1244 - val_cindex_score: 0.6761\n","Epoch 8/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.7602 - cindex_score: 0.6262 - val_loss: 0.9311 - val_cindex_score: 0.6779\n","Epoch 9/100\n","78836/78836 [==============================] - 21s 267us/step - loss: 0.7498 - cindex_score: 0.6269 - val_loss: 0.7791 - val_cindex_score: 0.6782\n","Epoch 10/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.7493 - cindex_score: 0.6287 - val_loss: 0.6442 - val_cindex_score: 0.6795\n","Epoch 11/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.7331 - cindex_score: 0.6269 - val_loss: 0.7018 - val_cindex_score: 0.6782\n","Epoch 12/100\n","78836/78836 [==============================] - 21s 271us/step - loss: 0.7468 - cindex_score: 0.6279 - val_loss: 0.7018 - val_cindex_score: 0.6775\n","Epoch 13/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.7310 - cindex_score: 0.6288 - val_loss: 0.6510 - val_cindex_score: 0.6791\n","Epoch 14/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.7242 - cindex_score: 0.6296 - val_loss: 0.6548 - val_cindex_score: 0.6777\n","Epoch 15/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.7324 - cindex_score: 0.6288 - val_loss: 0.8200 - val_cindex_score: 0.6780\n","Epoch 16/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.7278 - cindex_score: 0.6317 - val_loss: 0.7910 - val_cindex_score: 0.6788\n","Epoch 17/100\n","78836/78836 [==============================] - 21s 271us/step - loss: 0.7184 - cindex_score: 0.6332 - val_loss: 0.9232 - val_cindex_score: 0.6792\n","Epoch 18/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.7212 - cindex_score: 0.6329 - val_loss: 1.0660 - val_cindex_score: 0.6804\n","Epoch 19/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.7116 - cindex_score: 0.6372 - val_loss: 0.8930 - val_cindex_score: 0.6802\n","Epoch 20/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.6934 - cindex_score: 0.6398 - val_loss: 0.8645 - val_cindex_score: 0.6801\n","Epoch 21/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.6928 - cindex_score: 0.6430 - val_loss: 1.4625 - val_cindex_score: 0.6811\n","Epoch 22/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6860 - cindex_score: 0.6462 - val_loss: 1.6264 - val_cindex_score: 0.6806\n","Epoch 23/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.6858 - cindex_score: 0.6473 - val_loss: 0.9122 - val_cindex_score: 0.6800\n","Epoch 24/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.6770 - cindex_score: 0.6500 - val_loss: 1.4774 - val_cindex_score: 0.6831\n","Epoch 25/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6692 - cindex_score: 0.6521 - val_loss: 1.5277 - val_cindex_score: 0.6852\n","Epoch 26/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.6637 - cindex_score: 0.6532 - val_loss: 1.3159 - val_cindex_score: 0.6860\n","Epoch 27/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.6616 - cindex_score: 0.6553 - val_loss: 1.3198 - val_cindex_score: 0.6847\n","Epoch 28/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.6628 - cindex_score: 0.6551 - val_loss: 1.7185 - val_cindex_score: 0.6856\n","Epoch 29/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6577 - cindex_score: 0.6553 - val_loss: 1.5913 - val_cindex_score: 0.6839\n","Epoch 30/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6508 - cindex_score: 0.6582 - val_loss: 1.3854 - val_cindex_score: 0.6835\n","Epoch 31/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6512 - cindex_score: 0.6571 - val_loss: 1.4818 - val_cindex_score: 0.6855\n","Epoch 32/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6456 - cindex_score: 0.6588 - val_loss: 1.4307 - val_cindex_score: 0.6821\n","Epoch 33/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6468 - cindex_score: 0.6573 - val_loss: 1.3549 - val_cindex_score: 0.6822\n","Epoch 34/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6471 - cindex_score: 0.6580 - val_loss: 1.4554 - val_cindex_score: 0.6833\n","Epoch 35/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6409 - cindex_score: 0.6595 - val_loss: 1.5424 - val_cindex_score: 0.6828\n","Epoch 36/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6387 - cindex_score: 0.6606 - val_loss: 1.4298 - val_cindex_score: 0.6808\n","Epoch 37/100\n","78836/78836 [==============================] - 21s 268us/step - loss: 0.6374 - cindex_score: 0.6601 - val_loss: 1.7284 - val_cindex_score: 0.6848\n","Epoch 38/100\n","78836/78836 [==============================] - 21s 268us/step - loss: 0.6370 - cindex_score: 0.6599 - val_loss: 1.5930 - val_cindex_score: 0.6854\n","Epoch 39/100\n","78836/78836 [==============================] - 21s 268us/step - loss: 0.6316 - cindex_score: 0.6618 - val_loss: 1.6729 - val_cindex_score: 0.6851\n","Epoch 40/100\n","78836/78836 [==============================] - 21s 268us/step - loss: 0.6351 - cindex_score: 0.6613 - val_loss: 1.6989 - val_cindex_score: 0.6821\n","Epoch 41/100\n","78836/78836 [==============================] - 21s 268us/step - loss: 0.6301 - cindex_score: 0.6622 - val_loss: 1.6690 - val_cindex_score: 0.6838\n","Epoch 42/100\n","78836/78836 [==============================] - 21s 267us/step - loss: 0.6346 - cindex_score: 0.6610 - val_loss: 1.8341 - val_cindex_score: 0.6862\n","Epoch 43/100\n","78836/78836 [==============================] - 21s 267us/step - loss: 0.6280 - cindex_score: 0.6625 - val_loss: 1.7830 - val_cindex_score: 0.6779\n","Epoch 44/100\n","78836/78836 [==============================] - 21s 267us/step - loss: 0.6270 - cindex_score: 0.6622 - val_loss: 1.8960 - val_cindex_score: 0.6829\n","Epoch 45/100\n","78836/78836 [==============================] - 21s 267us/step - loss: 0.6267 - cindex_score: 0.6624 - val_loss: 1.7320 - val_cindex_score: 0.6852\n","Epoch 46/100\n","78836/78836 [==============================] - 21s 267us/step - loss: 0.6306 - cindex_score: 0.6624 - val_loss: 1.6333 - val_cindex_score: 0.6858\n","Epoch 47/100\n","78836/78836 [==============================] - 21s 267us/step - loss: 0.6243 - cindex_score: 0.6643 - val_loss: 1.7071 - val_cindex_score: 0.6796\n","Epoch 48/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.6207 - cindex_score: 0.6649 - val_loss: 1.4999 - val_cindex_score: 0.6844\n","Epoch 49/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.6232 - cindex_score: 0.6640 - val_loss: 1.4233 - val_cindex_score: 0.6841\n","Epoch 50/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.6215 - cindex_score: 0.6639 - val_loss: 1.5053 - val_cindex_score: 0.6835\n","Epoch 51/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.6219 - cindex_score: 0.6641 - val_loss: 1.5646 - val_cindex_score: 0.6802\n","Epoch 52/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.6255 - cindex_score: 0.6618 - val_loss: 1.5789 - val_cindex_score: 0.6840\n","Epoch 53/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.6219 - cindex_score: 0.6647 - val_loss: 1.4070 - val_cindex_score: 0.6832\n","Epoch 54/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.6171 - cindex_score: 0.6663 - val_loss: 1.2864 - val_cindex_score: 0.6826\n","Epoch 55/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.6138 - cindex_score: 0.6659 - val_loss: 1.2265 - val_cindex_score: 0.6831\n","Epoch 56/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.6126 - cindex_score: 0.6665 - val_loss: 1.1472 - val_cindex_score: 0.6811\n","Epoch 57/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.6110 - cindex_score: 0.6679 - val_loss: 1.1269 - val_cindex_score: 0.6844\n","Epoch 58/100\n","78836/78836 [==============================] - 21s 267us/step - loss: 0.6049 - cindex_score: 0.6686 - val_loss: 1.1759 - val_cindex_score: 0.6832\n","Epoch 59/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.6080 - cindex_score: 0.6693 - val_loss: 1.1934 - val_cindex_score: 0.6829\n","Epoch 60/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.6053 - cindex_score: 0.6698 - val_loss: 1.0481 - val_cindex_score: 0.6858\n","Epoch 61/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.6038 - cindex_score: 0.6710 - val_loss: 1.0628 - val_cindex_score: 0.6845\n","Epoch 62/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.6013 - cindex_score: 0.6721 - val_loss: 1.0441 - val_cindex_score: 0.6870\n","Epoch 63/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.6009 - cindex_score: 0.6720 - val_loss: 1.0791 - val_cindex_score: 0.6833\n","Epoch 64/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5980 - cindex_score: 0.6739 - val_loss: 1.0470 - val_cindex_score: 0.6812\n","Epoch 65/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5965 - cindex_score: 0.6747 - val_loss: 1.0056 - val_cindex_score: 0.6831\n","Epoch 66/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5939 - cindex_score: 0.6750 - val_loss: 1.0456 - val_cindex_score: 0.6839\n","Epoch 67/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5935 - cindex_score: 0.6751 - val_loss: 1.0401 - val_cindex_score: 0.6817\n","Epoch 68/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5918 - cindex_score: 0.6780 - val_loss: 0.9858 - val_cindex_score: 0.6815\n","Epoch 69/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5900 - cindex_score: 0.6783 - val_loss: 0.9917 - val_cindex_score: 0.6710\n","Epoch 70/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5911 - cindex_score: 0.6790 - val_loss: 1.0003 - val_cindex_score: 0.6769\n","Epoch 71/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5851 - cindex_score: 0.6807 - val_loss: 0.9500 - val_cindex_score: 0.6864\n","Epoch 72/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5854 - cindex_score: 0.6804 - val_loss: 0.9025 - val_cindex_score: 0.6736\n","Epoch 73/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5807 - cindex_score: 0.6818 - val_loss: 0.8994 - val_cindex_score: 0.6749\n","Epoch 74/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5809 - cindex_score: 0.6828 - val_loss: 0.8986 - val_cindex_score: 0.6706\n","Epoch 75/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5813 - cindex_score: 0.6836 - val_loss: 0.8264 - val_cindex_score: 0.6827\n","Epoch 76/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5793 - cindex_score: 0.6838 - val_loss: 0.8091 - val_cindex_score: 0.6797\n","Epoch 77/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5784 - cindex_score: 0.6852 - val_loss: 0.7816 - val_cindex_score: 0.6837\n","Epoch 78/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5757 - cindex_score: 0.6867 - val_loss: 0.8200 - val_cindex_score: 0.6718\n","Epoch 79/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5722 - cindex_score: 0.6881 - val_loss: 0.7844 - val_cindex_score: 0.6739\n","Epoch 80/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5717 - cindex_score: 0.6891 - val_loss: 0.7571 - val_cindex_score: 0.6785\n","Epoch 81/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5688 - cindex_score: 0.6895 - val_loss: 0.6926 - val_cindex_score: 0.6810\n","Epoch 82/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5680 - cindex_score: 0.6910 - val_loss: 0.6493 - val_cindex_score: 0.6833\n","Epoch 83/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5679 - cindex_score: 0.6914 - val_loss: 0.6526 - val_cindex_score: 0.6822\n","Epoch 84/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.5662 - cindex_score: 0.6915 - val_loss: 0.6173 - val_cindex_score: 0.6784\n","Epoch 85/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5643 - cindex_score: 0.6920 - val_loss: 0.6486 - val_cindex_score: 0.6737\n","Epoch 86/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5650 - cindex_score: 0.6920 - val_loss: 0.6226 - val_cindex_score: 0.6768\n","Epoch 87/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5627 - cindex_score: 0.6938 - val_loss: 0.6352 - val_cindex_score: 0.6689\n","Epoch 88/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5626 - cindex_score: 0.6937 - val_loss: 0.6025 - val_cindex_score: 0.6841\n","Epoch 89/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5587 - cindex_score: 0.6964 - val_loss: 0.6229 - val_cindex_score: 0.6708\n","Epoch 90/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5593 - cindex_score: 0.6951 - val_loss: 0.6216 - val_cindex_score: 0.6746\n","Epoch 91/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5583 - cindex_score: 0.6964 - val_loss: 0.6330 - val_cindex_score: 0.6759\n","Epoch 92/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5535 - cindex_score: 0.6976 - val_loss: 0.6252 - val_cindex_score: 0.6836\n","Epoch 93/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5530 - cindex_score: 0.6978 - val_loss: 0.6019 - val_cindex_score: 0.6821\n","Epoch 94/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5527 - cindex_score: 0.6976 - val_loss: 0.6429 - val_cindex_score: 0.6735\n","Epoch 95/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5538 - cindex_score: 0.6980 - val_loss: 0.6062 - val_cindex_score: 0.6853\n","Epoch 96/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5534 - cindex_score: 0.6985 - val_loss: 0.5989 - val_cindex_score: 0.6745\n","Epoch 97/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5492 - cindex_score: 0.6989 - val_loss: 0.6122 - val_cindex_score: 0.6698\n","Epoch 98/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5509 - cindex_score: 0.6984 - val_loss: 0.5976 - val_cindex_score: 0.6815\n","Epoch 99/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5480 - cindex_score: 0.6997 - val_loss: 0.5990 - val_cindex_score: 0.6773\n","Epoch 100/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5488 - cindex_score: 0.6988 - val_loss: 0.5928 - val_cindex_score: 0.6784\n","run_experiments.py:456: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:469: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:483: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","[[0, 0, 0, 0, 0]]\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","embedding_2 (Embedding)         (None, 1000, 128)    3328        input_4[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_4 (Conv1D)               (None, 993, 32)      32800       embedding_2[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_5 (Conv1D)               (None, 986, 64)      16448       conv1d_4[0][0]                   \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","conv1d_6 (Conv1D)               (None, 979, 96)      49248       conv1d_5[0][0]                   \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 1)            101         input_3[0][0]                    \n","__________________________________________________________________________________________________\n","global_max_pooling1d_2 (GlobalM (None, 96)           0           conv1d_6[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 97)           0           dense_6[0][0]                    \n","                                                                 global_max_pooling1d_2[0][0]     \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 1024)         100352      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 1024)         0           dense_7[0][0]                    \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 1024)         1049600     dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 512)          524800      dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","dense_10 (Dense)                (None, 1)            513         dense_9[0][0]                    \n","==================================================================================================\n","Total params: 1,777,190\n","Trainable params: 1,777,190\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Train on 78836 samples, validate on 19709 samples\n","Epoch 1/100\n","78836/78836 [==============================] - 22s 274us/step - loss: 3.3543 - cindex_score: 0.5445 - val_loss: 0.9951 - val_cindex_score: 0.6420\n","Epoch 2/100\n","78836/78836 [==============================] - 22s 274us/step - loss: 0.8071 - cindex_score: 0.6002 - val_loss: 0.9129 - val_cindex_score: 0.6592\n","Epoch 3/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.7917 - cindex_score: 0.6164 - val_loss: 0.9548 - val_cindex_score: 0.6625\n","Epoch 4/100\n","78836/78836 [==============================] - 21s 268us/step - loss: 0.7972 - cindex_score: 0.6208 - val_loss: 1.1096 - val_cindex_score: 0.6752\n","Epoch 5/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.7835 - cindex_score: 0.6239 - val_loss: 1.0582 - val_cindex_score: 0.6715\n","Epoch 6/100\n","78836/78836 [==============================] - 21s 271us/step - loss: 0.7544 - cindex_score: 0.6262 - val_loss: 0.9600 - val_cindex_score: 0.6763\n","Epoch 7/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.7544 - cindex_score: 0.6279 - val_loss: 1.1783 - val_cindex_score: 0.6747\n","Epoch 8/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.7548 - cindex_score: 0.6292 - val_loss: 1.1117 - val_cindex_score: 0.6705\n","Epoch 9/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.7523 - cindex_score: 0.6307 - val_loss: 1.2638 - val_cindex_score: 0.6721\n","Epoch 10/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.7423 - cindex_score: 0.6332 - val_loss: 1.1182 - val_cindex_score: 0.6750\n","Epoch 11/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.7339 - cindex_score: 0.6369 - val_loss: 1.0503 - val_cindex_score: 0.6762\n","Epoch 12/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.7143 - cindex_score: 0.6385 - val_loss: 1.1779 - val_cindex_score: 0.6738\n","Epoch 13/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.7076 - cindex_score: 0.6420 - val_loss: 1.6422 - val_cindex_score: 0.6782\n","Epoch 14/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6982 - cindex_score: 0.6453 - val_loss: 1.4098 - val_cindex_score: 0.6753\n","Epoch 15/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6945 - cindex_score: 0.6466 - val_loss: 1.6300 - val_cindex_score: 0.6773\n","Epoch 16/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.7032 - cindex_score: 0.6488 - val_loss: 2.1286 - val_cindex_score: 0.6784\n","Epoch 17/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6794 - cindex_score: 0.6508 - val_loss: 2.1508 - val_cindex_score: 0.6817\n","Epoch 18/100\n","78836/78836 [==============================] - 21s 270us/step - loss: 0.6837 - cindex_score: 0.6520 - val_loss: 1.4577 - val_cindex_score: 0.6858\n","Epoch 19/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6698 - cindex_score: 0.6541 - val_loss: 1.4755 - val_cindex_score: 0.6863\n","Epoch 20/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6637 - cindex_score: 0.6560 - val_loss: 1.4299 - val_cindex_score: 0.6856\n","Epoch 21/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6642 - cindex_score: 0.6548 - val_loss: 1.4301 - val_cindex_score: 0.6874\n","Epoch 22/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6568 - cindex_score: 0.6577 - val_loss: 1.8819 - val_cindex_score: 0.6870\n","Epoch 23/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6525 - cindex_score: 0.6585 - val_loss: 1.7311 - val_cindex_score: 0.6876\n","Epoch 24/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6511 - cindex_score: 0.6595 - val_loss: 1.5991 - val_cindex_score: 0.6878\n","Epoch 25/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6491 - cindex_score: 0.6601 - val_loss: 1.8887 - val_cindex_score: 0.6884\n","Epoch 26/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6411 - cindex_score: 0.6611 - val_loss: 1.7125 - val_cindex_score: 0.6872\n","Epoch 27/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6422 - cindex_score: 0.6631 - val_loss: 1.9164 - val_cindex_score: 0.6881\n","Epoch 28/100\n","78836/78836 [==============================] - 21s 268us/step - loss: 0.6436 - cindex_score: 0.6634 - val_loss: 1.6465 - val_cindex_score: 0.6879\n","Epoch 29/100\n","78836/78836 [==============================] - 21s 268us/step - loss: 0.6429 - cindex_score: 0.6655 - val_loss: 1.7265 - val_cindex_score: 0.6882\n","Epoch 30/100\n","78836/78836 [==============================] - 21s 268us/step - loss: 0.6406 - cindex_score: 0.6668 - val_loss: 1.8371 - val_cindex_score: 0.6896\n","Epoch 31/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6381 - cindex_score: 0.6686 - val_loss: 1.5987 - val_cindex_score: 0.6879\n","Epoch 32/100\n","78836/78836 [==============================] - 21s 268us/step - loss: 0.6334 - cindex_score: 0.6699 - val_loss: 1.4569 - val_cindex_score: 0.6871\n","Epoch 33/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6324 - cindex_score: 0.6699 - val_loss: 1.4091 - val_cindex_score: 0.6915\n","Epoch 34/100\n","78836/78836 [==============================] - 21s 268us/step - loss: 0.6244 - cindex_score: 0.6721 - val_loss: 1.2538 - val_cindex_score: 0.6886\n","Epoch 35/100\n","78836/78836 [==============================] - 21s 268us/step - loss: 0.6266 - cindex_score: 0.6724 - val_loss: 1.3726 - val_cindex_score: 0.6903\n","Epoch 36/100\n","78836/78836 [==============================] - 21s 268us/step - loss: 0.6200 - cindex_score: 0.6746 - val_loss: 1.3931 - val_cindex_score: 0.6907\n","Epoch 37/100\n","78836/78836 [==============================] - 21s 269us/step - loss: 0.6155 - cindex_score: 0.6747 - val_loss: 1.4533 - val_cindex_score: 0.6903\n","Epoch 38/100\n","78836/78836 [==============================] - 21s 268us/step - loss: 0.6161 - cindex_score: 0.6748 - val_loss: 1.3652 - val_cindex_score: 0.6907\n","Epoch 39/100\n","78836/78836 [==============================] - 21s 268us/step - loss: 0.6154 - cindex_score: 0.6766 - val_loss: 1.3468 - val_cindex_score: 0.6927\n","Epoch 40/100\n","78836/78836 [==============================] - 21s 268us/step - loss: 0.6134 - cindex_score: 0.6760 - val_loss: 1.2348 - val_cindex_score: 0.6912\n","Epoch 41/100\n","78836/78836 [==============================] - 21s 268us/step - loss: 0.6079 - cindex_score: 0.6790 - val_loss: 1.3511 - val_cindex_score: 0.6964\n","Epoch 42/100\n","78836/78836 [==============================] - 21s 268us/step - loss: 0.6071 - cindex_score: 0.6790 - val_loss: 1.2310 - val_cindex_score: 0.6948\n","Epoch 43/100\n","78836/78836 [==============================] - 21s 268us/step - loss: 0.6050 - cindex_score: 0.6799 - val_loss: 1.1973 - val_cindex_score: 0.6950\n","Epoch 44/100\n","78836/78836 [==============================] - 21s 268us/step - loss: 0.6030 - cindex_score: 0.6806 - val_loss: 1.2457 - val_cindex_score: 0.6984\n","Epoch 45/100\n","78836/78836 [==============================] - 21s 267us/step - loss: 0.6022 - cindex_score: 0.6805 - val_loss: 1.2708 - val_cindex_score: 0.6973\n","Epoch 46/100\n","78836/78836 [==============================] - 21s 267us/step - loss: 0.6014 - cindex_score: 0.6812 - val_loss: 1.3103 - val_cindex_score: 0.7018\n","Epoch 47/100\n","78836/78836 [==============================] - 21s 267us/step - loss: 0.6012 - cindex_score: 0.6815 - val_loss: 1.3439 - val_cindex_score: 0.7021\n","Epoch 48/100\n","78836/78836 [==============================] - 21s 267us/step - loss: 0.5958 - cindex_score: 0.6826 - val_loss: 1.3018 - val_cindex_score: 0.7022\n","Epoch 49/100\n","78836/78836 [==============================] - 21s 267us/step - loss: 0.5972 - cindex_score: 0.6831 - val_loss: 1.3711 - val_cindex_score: 0.7010\n","Epoch 50/100\n","78836/78836 [==============================] - 21s 267us/step - loss: 0.5983 - cindex_score: 0.6834 - val_loss: 1.4306 - val_cindex_score: 0.7033\n","Epoch 51/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.5966 - cindex_score: 0.6837 - val_loss: 1.4051 - val_cindex_score: 0.7035\n","Epoch 52/100\n","78836/78836 [==============================] - 21s 267us/step - loss: 0.5937 - cindex_score: 0.6841 - val_loss: 1.4602 - val_cindex_score: 0.7028\n","Epoch 53/100\n","78836/78836 [==============================] - 21s 267us/step - loss: 0.5913 - cindex_score: 0.6851 - val_loss: 1.4486 - val_cindex_score: 0.7019\n","Epoch 54/100\n","78836/78836 [==============================] - 21s 267us/step - loss: 0.5929 - cindex_score: 0.6859 - val_loss: 1.4094 - val_cindex_score: 0.7029\n","Epoch 55/100\n","78836/78836 [==============================] - 21s 267us/step - loss: 0.5916 - cindex_score: 0.6855 - val_loss: 1.6374 - val_cindex_score: 0.7044\n","Epoch 56/100\n","78836/78836 [==============================] - 21s 267us/step - loss: 0.5930 - cindex_score: 0.6853 - val_loss: 1.6160 - val_cindex_score: 0.7029\n","Epoch 57/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.5895 - cindex_score: 0.6873 - val_loss: 1.4841 - val_cindex_score: 0.7052\n","Epoch 58/100\n","78836/78836 [==============================] - 21s 267us/step - loss: 0.5874 - cindex_score: 0.6876 - val_loss: 1.4053 - val_cindex_score: 0.7014\n","Epoch 59/100\n","78836/78836 [==============================] - 21s 267us/step - loss: 0.5867 - cindex_score: 0.6869 - val_loss: 1.5198 - val_cindex_score: 0.7039\n","Epoch 60/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.5849 - cindex_score: 0.6882 - val_loss: 1.2421 - val_cindex_score: 0.7019\n","Epoch 61/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.5855 - cindex_score: 0.6888 - val_loss: 1.1597 - val_cindex_score: 0.7038\n","Epoch 62/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5838 - cindex_score: 0.6890 - val_loss: 1.1873 - val_cindex_score: 0.7025\n","Epoch 63/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.5824 - cindex_score: 0.6894 - val_loss: 1.1044 - val_cindex_score: 0.7008\n","Epoch 64/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.5830 - cindex_score: 0.6889 - val_loss: 1.3362 - val_cindex_score: 0.7017\n","Epoch 65/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.5787 - cindex_score: 0.6911 - val_loss: 1.0895 - val_cindex_score: 0.7026\n","Epoch 66/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.5785 - cindex_score: 0.6913 - val_loss: 1.0506 - val_cindex_score: 0.7031\n","Epoch 67/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.5774 - cindex_score: 0.6924 - val_loss: 1.0100 - val_cindex_score: 0.7007\n","Epoch 68/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.5770 - cindex_score: 0.6925 - val_loss: 0.9759 - val_cindex_score: 0.7004\n","Epoch 69/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5748 - cindex_score: 0.6929 - val_loss: 0.9572 - val_cindex_score: 0.7020\n","Epoch 70/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5740 - cindex_score: 0.6933 - val_loss: 0.9680 - val_cindex_score: 0.7025\n","Epoch 71/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5691 - cindex_score: 0.6947 - val_loss: 0.8908 - val_cindex_score: 0.7013\n","Epoch 72/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5729 - cindex_score: 0.6943 - val_loss: 0.9056 - val_cindex_score: 0.7014\n","Epoch 73/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.5704 - cindex_score: 0.6955 - val_loss: 0.8717 - val_cindex_score: 0.6993\n","Epoch 74/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.5686 - cindex_score: 0.6963 - val_loss: 0.8368 - val_cindex_score: 0.6988\n","Epoch 75/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.5667 - cindex_score: 0.6966 - val_loss: 0.8217 - val_cindex_score: 0.7020\n","Epoch 76/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5678 - cindex_score: 0.6967 - val_loss: 0.8187 - val_cindex_score: 0.6961\n","Epoch 77/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5663 - cindex_score: 0.6980 - val_loss: 0.7920 - val_cindex_score: 0.7006\n","Epoch 78/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5676 - cindex_score: 0.6988 - val_loss: 0.8041 - val_cindex_score: 0.7001\n","Epoch 79/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5643 - cindex_score: 0.6992 - val_loss: 0.7213 - val_cindex_score: 0.7011\n","Epoch 80/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.5613 - cindex_score: 0.6998 - val_loss: 0.7070 - val_cindex_score: 0.7019\n","Epoch 81/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.5617 - cindex_score: 0.7000 - val_loss: 0.6954 - val_cindex_score: 0.6956\n","Epoch 82/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5597 - cindex_score: 0.7017 - val_loss: 0.6912 - val_cindex_score: 0.6978\n","Epoch 83/100\n","78836/78836 [==============================] - 21s 266us/step - loss: 0.5566 - cindex_score: 0.7020 - val_loss: 0.6572 - val_cindex_score: 0.7009\n","Epoch 84/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5568 - cindex_score: 0.7022 - val_loss: 0.6183 - val_cindex_score: 0.7031\n","Epoch 85/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5560 - cindex_score: 0.7034 - val_loss: 0.6511 - val_cindex_score: 0.6970\n","Epoch 86/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5548 - cindex_score: 0.7038 - val_loss: 0.5835 - val_cindex_score: 0.6921\n","Epoch 87/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5519 - cindex_score: 0.7051 - val_loss: 0.6073 - val_cindex_score: 0.7026\n","Epoch 88/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5502 - cindex_score: 0.7054 - val_loss: 0.5538 - val_cindex_score: 0.7012\n","Epoch 89/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5526 - cindex_score: 0.7050 - val_loss: 0.5636 - val_cindex_score: 0.6958\n","Epoch 90/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5523 - cindex_score: 0.7049 - val_loss: 0.5503 - val_cindex_score: 0.7004\n","Epoch 91/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5492 - cindex_score: 0.7066 - val_loss: 0.5548 - val_cindex_score: 0.7006\n","Epoch 92/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5516 - cindex_score: 0.7056 - val_loss: 0.5532 - val_cindex_score: 0.7026\n","Epoch 93/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5510 - cindex_score: 0.7061 - val_loss: 0.5450 - val_cindex_score: 0.7037\n","Epoch 94/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5480 - cindex_score: 0.7070 - val_loss: 0.5358 - val_cindex_score: 0.7057\n","Epoch 95/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5468 - cindex_score: 0.7072 - val_loss: 0.5461 - val_cindex_score: 0.7049\n","Epoch 96/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5482 - cindex_score: 0.7073 - val_loss: 0.5434 - val_cindex_score: 0.7010\n","Epoch 97/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5474 - cindex_score: 0.7081 - val_loss: 0.5477 - val_cindex_score: 0.6996\n","Epoch 98/100\n","78836/78836 [==============================] - 21s 264us/step - loss: 0.5455 - cindex_score: 0.7076 - val_loss: 0.5463 - val_cindex_score: 0.7040\n","Epoch 99/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5491 - cindex_score: 0.7059 - val_loss: 0.5474 - val_cindex_score: 0.6998\n","Epoch 100/100\n","78836/78836 [==============================] - 21s 265us/step - loss: 0.5515 - cindex_score: 0.7057 - val_loss: 0.5408 - val_cindex_score: 0.7015\n","run_experiments.py:456: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:469: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:483: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n"]}]},{"cell_type":"markdown","source":["### Single Drug"],"metadata":{"id":"H32bm3knvuM2"}},{"cell_type":"markdown","source":["#### KIBA"],"metadata":{"id":"t4E0I8AYeQMO"}},{"cell_type":"code","source":["!./go.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D3_DykefeMqu","executionInfo":{"status":"ok","timestamp":1651592925920,"user_tz":300,"elapsed":1847590,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"}},"outputId":"05e1c223-4194-4c55-e33e-fab5dffdf1bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From run_experiments.py:16: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","Using TensorFlow backend.\n","WARNING:tensorflow:From run_experiments.py:19: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","2022-05-03 15:17:59.678006: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n","2022-05-03 15:17:59.678169: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x15f92c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2022-05-03 15:17:59.678201: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2022-05-03 15:17:59.679823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2022-05-03 15:17:59.897862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 15:17:59.898719: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x15f9640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2022-05-03 15:17:59.898757: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2022-05-03 15:17:59.898997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 15:17:59.899564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2022-05-03 15:17:59.899940: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-05-03 15:17:59.901480: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-05-03 15:17:59.902398: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2022-05-03 15:17:59.902761: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2022-05-03 15:17:59.904396: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2022-05-03 15:17:59.905120: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2022-05-03 15:17:59.908329: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-05-03 15:17:59.908442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 15:17:59.909019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 15:17:59.909513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2022-05-03 15:17:59.909572: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-05-03 15:17:59.910532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-05-03 15:17:59.910557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2022-05-03 15:17:59.910568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2022-05-03 15:17:59.910672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 15:17:59.911269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-03 15:17:59.911783: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-05-03 15:17:59.911822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","Read data/kiba/ start\n","2111\n","229\n","logs/1651591080.6003575/\n","Reading data/kiba/ start\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","[[0, 0, 0, 0, 0]]\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From run_experiments.py:435: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n","\n","WARNING:tensorflow:From run_experiments.py:440: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 100, 128)     8320        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_1 (Conv1D)               (None, 95, 32)       24608       embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_2 (Conv1D)               (None, 90, 64)       12352       conv1d_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_3 (Conv1D)               (None, 85, 96)       36960       conv1d_2[0][0]                   \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","global_max_pooling1d_1 (GlobalM (None, 96)           0           conv1d_3[0][0]                   \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1)            1001        input_2[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 97)           0           global_max_pooling1d_1[0][0]     \n","                                                                 dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1024)         100352      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 1024)         1049600     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 1024)         0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 512)          524800      dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 1)            513         dense_4[0][0]                    \n","==================================================================================================\n","Total params: 1,758,506\n","Trainable params: 1,758,506\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 78836 samples, validate on 19709 samples\n","Epoch 1/100\n","2022-05-03 15:18:03.555070: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-05-03 15:18:03.804852: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","78836/78836 [==============================] - 7s 93us/step - loss: 2.8216 - cindex_score: 0.5651 - val_loss: 0.7107 - val_cindex_score: 0.6370\n","Epoch 2/100\n","78836/78836 [==============================] - 3s 42us/step - loss: 0.7273 - cindex_score: 0.6095 - val_loss: 0.6372 - val_cindex_score: 0.6612\n","Epoch 3/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.6659 - cindex_score: 0.6320 - val_loss: 0.9196 - val_cindex_score: 0.6739\n","Epoch 4/100\n","78836/78836 [==============================] - 3s 42us/step - loss: 0.6425 - cindex_score: 0.6457 - val_loss: 0.7812 - val_cindex_score: 0.6862\n","Epoch 5/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.6248 - cindex_score: 0.6574 - val_loss: 0.8155 - val_cindex_score: 0.6926\n","Epoch 6/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.6050 - cindex_score: 0.6649 - val_loss: 0.7825 - val_cindex_score: 0.6974\n","Epoch 7/100\n","78836/78836 [==============================] - 3s 42us/step - loss: 0.5848 - cindex_score: 0.6719 - val_loss: 0.5568 - val_cindex_score: 0.7039\n","Epoch 8/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.5804 - cindex_score: 0.6774 - val_loss: 0.4563 - val_cindex_score: 0.7074\n","Epoch 9/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.5714 - cindex_score: 0.6806 - val_loss: 0.5062 - val_cindex_score: 0.7107\n","Epoch 10/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.5463 - cindex_score: 0.6858 - val_loss: 0.5340 - val_cindex_score: 0.7036\n","Epoch 11/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.5334 - cindex_score: 0.6873 - val_loss: 0.4451 - val_cindex_score: 0.7090\n","Epoch 12/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.5173 - cindex_score: 0.6928 - val_loss: 0.6812 - val_cindex_score: 0.7120\n","Epoch 13/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.5171 - cindex_score: 0.6997 - val_loss: 0.5841 - val_cindex_score: 0.7278\n","Epoch 14/100\n","78836/78836 [==============================] - 4s 48us/step - loss: 0.4855 - cindex_score: 0.7098 - val_loss: 0.6427 - val_cindex_score: 0.7408\n","Epoch 15/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4713 - cindex_score: 0.7178 - val_loss: 0.6750 - val_cindex_score: 0.7492\n","Epoch 16/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4737 - cindex_score: 0.7230 - val_loss: 0.7177 - val_cindex_score: 0.7544\n","Epoch 17/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4595 - cindex_score: 0.7269 - val_loss: 1.0133 - val_cindex_score: 0.7528\n","Epoch 18/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4664 - cindex_score: 0.7277 - val_loss: 0.7458 - val_cindex_score: 0.7513\n","Epoch 19/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4445 - cindex_score: 0.7303 - val_loss: 0.8700 - val_cindex_score: 0.7451\n","Epoch 20/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4267 - cindex_score: 0.7354 - val_loss: 1.2107 - val_cindex_score: 0.7511\n","Epoch 21/100\n","78836/78836 [==============================] - 4s 49us/step - loss: 0.4247 - cindex_score: 0.7363 - val_loss: 1.1925 - val_cindex_score: 0.7439\n","Epoch 22/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.4171 - cindex_score: 0.7365 - val_loss: 1.4049 - val_cindex_score: 0.7458\n","Epoch 23/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4304 - cindex_score: 0.7308 - val_loss: 1.2660 - val_cindex_score: 0.7450\n","Epoch 24/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4222 - cindex_score: 0.7399 - val_loss: 0.9224 - val_cindex_score: 0.7579\n","Epoch 25/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4065 - cindex_score: 0.7430 - val_loss: 0.9402 - val_cindex_score: 0.7615\n","Epoch 26/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3988 - cindex_score: 0.7457 - val_loss: 1.0489 - val_cindex_score: 0.7612\n","Epoch 27/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3962 - cindex_score: 0.7472 - val_loss: 1.5854 - val_cindex_score: 0.7546\n","Epoch 28/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3934 - cindex_score: 0.7459 - val_loss: 1.5625 - val_cindex_score: 0.7608\n","Epoch 29/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3906 - cindex_score: 0.7497 - val_loss: 1.3868 - val_cindex_score: 0.7617\n","Epoch 30/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3848 - cindex_score: 0.7512 - val_loss: 1.6673 - val_cindex_score: 0.7558\n","Epoch 31/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3794 - cindex_score: 0.7528 - val_loss: 1.4310 - val_cindex_score: 0.7676\n","Epoch 32/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3787 - cindex_score: 0.7511 - val_loss: 1.5245 - val_cindex_score: 0.7548\n","Epoch 33/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3821 - cindex_score: 0.7504 - val_loss: 1.2502 - val_cindex_score: 0.7610\n","Epoch 34/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3792 - cindex_score: 0.7524 - val_loss: 1.1126 - val_cindex_score: 0.7628\n","Epoch 35/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3721 - cindex_score: 0.7546 - val_loss: 1.3614 - val_cindex_score: 0.7645\n","Epoch 36/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3691 - cindex_score: 0.7555 - val_loss: 1.0762 - val_cindex_score: 0.7597\n","Epoch 37/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3759 - cindex_score: 0.7530 - val_loss: 1.0949 - val_cindex_score: 0.7567\n","Epoch 38/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3738 - cindex_score: 0.7561 - val_loss: 1.2810 - val_cindex_score: 0.7621\n","Epoch 39/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3725 - cindex_score: 0.7544 - val_loss: 1.4656 - val_cindex_score: 0.7612\n","Epoch 40/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3663 - cindex_score: 0.7574 - val_loss: 1.3493 - val_cindex_score: 0.7554\n","Epoch 41/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3640 - cindex_score: 0.7574 - val_loss: 1.3609 - val_cindex_score: 0.7642\n","Epoch 42/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3624 - cindex_score: 0.7586 - val_loss: 1.3747 - val_cindex_score: 0.7615\n","Epoch 43/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.3573 - cindex_score: 0.7608 - val_loss: 1.2553 - val_cindex_score: 0.7615\n","Epoch 44/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3585 - cindex_score: 0.7593 - val_loss: 1.2350 - val_cindex_score: 0.7659\n","Epoch 45/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3611 - cindex_score: 0.7588 - val_loss: 1.2649 - val_cindex_score: 0.7658\n","Epoch 46/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3569 - cindex_score: 0.7602 - val_loss: 1.2461 - val_cindex_score: 0.7635\n","Epoch 47/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3515 - cindex_score: 0.7627 - val_loss: 1.1791 - val_cindex_score: 0.7621\n","Epoch 48/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3534 - cindex_score: 0.7637 - val_loss: 1.5216 - val_cindex_score: 0.7601\n","Epoch 49/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3511 - cindex_score: 0.7630 - val_loss: 1.4761 - val_cindex_score: 0.7612\n","Epoch 50/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3481 - cindex_score: 0.7656 - val_loss: 1.0242 - val_cindex_score: 0.7645\n","Epoch 51/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3536 - cindex_score: 0.7610 - val_loss: 1.4020 - val_cindex_score: 0.7609\n","Epoch 52/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3515 - cindex_score: 0.7622 - val_loss: 1.3566 - val_cindex_score: 0.7591\n","Epoch 53/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3436 - cindex_score: 0.7659 - val_loss: 1.2080 - val_cindex_score: 0.7586\n","Epoch 54/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3438 - cindex_score: 0.7654 - val_loss: 1.1240 - val_cindex_score: 0.7655\n","Epoch 55/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3401 - cindex_score: 0.7663 - val_loss: 1.1526 - val_cindex_score: 0.7633\n","Epoch 56/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3342 - cindex_score: 0.7675 - val_loss: 1.2711 - val_cindex_score: 0.7627\n","Epoch 57/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3388 - cindex_score: 0.7674 - val_loss: 1.0656 - val_cindex_score: 0.7648\n","Epoch 58/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3312 - cindex_score: 0.7692 - val_loss: 1.2545 - val_cindex_score: 0.7583\n","Epoch 59/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3362 - cindex_score: 0.7676 - val_loss: 1.0575 - val_cindex_score: 0.7562\n","Epoch 60/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3339 - cindex_score: 0.7681 - val_loss: 0.9139 - val_cindex_score: 0.7631\n","Epoch 61/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3342 - cindex_score: 0.7694 - val_loss: 1.0593 - val_cindex_score: 0.7580\n","Epoch 62/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3484 - cindex_score: 0.7639 - val_loss: 0.7705 - val_cindex_score: 0.7567\n","Epoch 63/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3316 - cindex_score: 0.7702 - val_loss: 0.8861 - val_cindex_score: 0.7585\n","Epoch 64/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3302 - cindex_score: 0.7715 - val_loss: 0.7724 - val_cindex_score: 0.7553\n","Epoch 65/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3281 - cindex_score: 0.7696 - val_loss: 0.7231 - val_cindex_score: 0.7517\n","Epoch 66/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3302 - cindex_score: 0.7704 - val_loss: 0.7359 - val_cindex_score: 0.7565\n","Epoch 67/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3268 - cindex_score: 0.7710 - val_loss: 0.6105 - val_cindex_score: 0.7589\n","Epoch 68/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3213 - cindex_score: 0.7730 - val_loss: 0.6079 - val_cindex_score: 0.7647\n","Epoch 69/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3190 - cindex_score: 0.7751 - val_loss: 0.6447 - val_cindex_score: 0.7650\n","Epoch 70/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3217 - cindex_score: 0.7740 - val_loss: 0.5566 - val_cindex_score: 0.7622\n","Epoch 71/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3180 - cindex_score: 0.7754 - val_loss: 0.5925 - val_cindex_score: 0.7613\n","Epoch 72/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3172 - cindex_score: 0.7754 - val_loss: 0.5415 - val_cindex_score: 0.7586\n","Epoch 73/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3180 - cindex_score: 0.7744 - val_loss: 0.4840 - val_cindex_score: 0.7534\n","Epoch 74/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3143 - cindex_score: 0.7761 - val_loss: 0.4976 - val_cindex_score: 0.7591\n","Epoch 75/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3132 - cindex_score: 0.7758 - val_loss: 0.4440 - val_cindex_score: 0.7589\n","Epoch 76/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3222 - cindex_score: 0.7719 - val_loss: 0.4472 - val_cindex_score: 0.7617\n","Epoch 77/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3166 - cindex_score: 0.7749 - val_loss: 0.4557 - val_cindex_score: 0.7613\n","Epoch 78/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3192 - cindex_score: 0.7761 - val_loss: 0.4382 - val_cindex_score: 0.7638\n","Epoch 79/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3205 - cindex_score: 0.7777 - val_loss: 0.4287 - val_cindex_score: 0.7629\n","Epoch 80/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3188 - cindex_score: 0.7789 - val_loss: 0.4251 - val_cindex_score: 0.7595\n","Epoch 81/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3188 - cindex_score: 0.7773 - val_loss: 0.4015 - val_cindex_score: 0.7641\n","Epoch 82/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3117 - cindex_score: 0.7798 - val_loss: 0.4263 - val_cindex_score: 0.7609\n","Epoch 83/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3115 - cindex_score: 0.7799 - val_loss: 0.3941 - val_cindex_score: 0.7655\n","Epoch 84/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3068 - cindex_score: 0.7813 - val_loss: 0.3871 - val_cindex_score: 0.7669\n","Epoch 85/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3047 - cindex_score: 0.7814 - val_loss: 0.4062 - val_cindex_score: 0.7638\n","Epoch 86/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3070 - cindex_score: 0.7805 - val_loss: 0.4352 - val_cindex_score: 0.7509\n","Epoch 87/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3095 - cindex_score: 0.7780 - val_loss: 0.3813 - val_cindex_score: 0.7653\n","Epoch 88/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3036 - cindex_score: 0.7813 - val_loss: 0.3935 - val_cindex_score: 0.7587\n","Epoch 89/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3081 - cindex_score: 0.7793 - val_loss: 0.3976 - val_cindex_score: 0.7590\n","Epoch 90/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3049 - cindex_score: 0.7815 - val_loss: 0.3769 - val_cindex_score: 0.7619\n","Epoch 91/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3080 - cindex_score: 0.7795 - val_loss: 0.3915 - val_cindex_score: 0.7609\n","Epoch 92/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3044 - cindex_score: 0.7811 - val_loss: 0.3871 - val_cindex_score: 0.7562\n","Epoch 93/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3024 - cindex_score: 0.7826 - val_loss: 0.4042 - val_cindex_score: 0.7526\n","Epoch 94/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3126 - cindex_score: 0.7785 - val_loss: 0.3794 - val_cindex_score: 0.7611\n","Epoch 95/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3016 - cindex_score: 0.7830 - val_loss: 0.3938 - val_cindex_score: 0.7637\n","Epoch 96/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3004 - cindex_score: 0.7836 - val_loss: 0.3844 - val_cindex_score: 0.7621\n","Epoch 97/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3047 - cindex_score: 0.7819 - val_loss: 0.3754 - val_cindex_score: 0.7575\n","Epoch 98/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.2989 - cindex_score: 0.7850 - val_loss: 0.3913 - val_cindex_score: 0.7627\n","Epoch 99/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3015 - cindex_score: 0.7836 - val_loss: 0.3880 - val_cindex_score: 0.7563\n","Epoch 100/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.2963 - cindex_score: 0.7860 - val_loss: 0.4019 - val_cindex_score: 0.7586\n","run_experiments.py:456: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:469: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:483: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","[[0, 0, 0, 0, 0]]\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","embedding_2 (Embedding)         (None, 100, 128)     8320        input_3[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_4 (Conv1D)               (None, 95, 32)       24608       embedding_2[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_5 (Conv1D)               (None, 90, 64)       12352       conv1d_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_6 (Conv1D)               (None, 85, 96)       36960       conv1d_5[0][0]                   \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","global_max_pooling1d_2 (GlobalM (None, 96)           0           conv1d_6[0][0]                   \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 1)            1001        input_4[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 97)           0           global_max_pooling1d_2[0][0]     \n","                                                                 dense_6[0][0]                    \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 1024)         100352      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 1024)         0           dense_7[0][0]                    \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 1024)         1049600     dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 512)          524800      dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","dense_10 (Dense)                (None, 1)            513         dense_9[0][0]                    \n","==================================================================================================\n","Total params: 1,758,506\n","Trainable params: 1,758,506\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Train on 78836 samples, validate on 19709 samples\n","Epoch 1/100\n","78836/78836 [==============================] - 4s 49us/step - loss: 3.3978 - cindex_score: 0.5535 - val_loss: 0.7201 - val_cindex_score: 0.6184\n","Epoch 2/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.7378 - cindex_score: 0.5940 - val_loss: 0.8157 - val_cindex_score: 0.6399\n","Epoch 3/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.6988 - cindex_score: 0.6154 - val_loss: 0.7540 - val_cindex_score: 0.6548\n","Epoch 4/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.7003 - cindex_score: 0.6304 - val_loss: 0.5049 - val_cindex_score: 0.6658\n","Epoch 5/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.6471 - cindex_score: 0.6438 - val_loss: 0.5082 - val_cindex_score: 0.6766\n","Epoch 6/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.6124 - cindex_score: 0.6566 - val_loss: 0.5475 - val_cindex_score: 0.6897\n","Epoch 7/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.6056 - cindex_score: 0.6674 - val_loss: 0.5689 - val_cindex_score: 0.6984\n","Epoch 8/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.5917 - cindex_score: 0.6795 - val_loss: 0.4434 - val_cindex_score: 0.7114\n","Epoch 9/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.5403 - cindex_score: 0.6940 - val_loss: 0.5140 - val_cindex_score: 0.7288\n","Epoch 10/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.5440 - cindex_score: 0.7025 - val_loss: 0.4344 - val_cindex_score: 0.7241\n","Epoch 11/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.5356 - cindex_score: 0.7094 - val_loss: 0.4948 - val_cindex_score: 0.7410\n","Epoch 12/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.5191 - cindex_score: 0.7154 - val_loss: 0.5048 - val_cindex_score: 0.7415\n","Epoch 13/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.5086 - cindex_score: 0.7193 - val_loss: 0.6165 - val_cindex_score: 0.7468\n","Epoch 14/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.5134 - cindex_score: 0.7201 - val_loss: 0.6458 - val_cindex_score: 0.7482\n","Epoch 15/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4976 - cindex_score: 0.7209 - val_loss: 0.5023 - val_cindex_score: 0.7494\n","Epoch 16/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.5049 - cindex_score: 0.7187 - val_loss: 0.5091 - val_cindex_score: 0.7430\n","Epoch 17/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4941 - cindex_score: 0.7211 - val_loss: 0.4275 - val_cindex_score: 0.7482\n","Epoch 18/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4872 - cindex_score: 0.7215 - val_loss: 0.4781 - val_cindex_score: 0.7504\n","Epoch 19/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4844 - cindex_score: 0.7219 - val_loss: 0.5082 - val_cindex_score: 0.7271\n","Epoch 20/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4815 - cindex_score: 0.7220 - val_loss: 0.4412 - val_cindex_score: 0.7506\n","Epoch 21/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4868 - cindex_score: 0.7166 - val_loss: 0.5712 - val_cindex_score: 0.7222\n","Epoch 22/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4844 - cindex_score: 0.7194 - val_loss: 0.3973 - val_cindex_score: 0.7382\n","Epoch 23/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4704 - cindex_score: 0.7236 - val_loss: 0.3798 - val_cindex_score: 0.7524\n","Epoch 24/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4824 - cindex_score: 0.7175 - val_loss: 0.4502 - val_cindex_score: 0.7200\n","Epoch 25/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4808 - cindex_score: 0.7165 - val_loss: 0.4240 - val_cindex_score: 0.7147\n","Epoch 26/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4594 - cindex_score: 0.7260 - val_loss: 0.4157 - val_cindex_score: 0.7521\n","Epoch 27/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4514 - cindex_score: 0.7273 - val_loss: 0.4056 - val_cindex_score: 0.7518\n","Epoch 28/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4357 - cindex_score: 0.7333 - val_loss: 0.4989 - val_cindex_score: 0.7334\n","Epoch 29/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4303 - cindex_score: 0.7332 - val_loss: 0.7382 - val_cindex_score: 0.7328\n","Epoch 30/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.4202 - cindex_score: 0.7405 - val_loss: 0.5995 - val_cindex_score: 0.7594\n","Epoch 31/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.4202 - cindex_score: 0.7399 - val_loss: 0.6650 - val_cindex_score: 0.7476\n","Epoch 32/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.4125 - cindex_score: 0.7412 - val_loss: 0.6551 - val_cindex_score: 0.7614\n","Epoch 33/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3983 - cindex_score: 0.7470 - val_loss: 0.7267 - val_cindex_score: 0.7506\n","Epoch 34/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4046 - cindex_score: 0.7420 - val_loss: 0.6381 - val_cindex_score: 0.7469\n","Epoch 35/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3926 - cindex_score: 0.7465 - val_loss: 0.6425 - val_cindex_score: 0.7508\n","Epoch 36/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.4006 - cindex_score: 0.7440 - val_loss: 0.9720 - val_cindex_score: 0.7501\n","Epoch 37/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3985 - cindex_score: 0.7463 - val_loss: 0.7709 - val_cindex_score: 0.7608\n","Epoch 38/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3951 - cindex_score: 0.7481 - val_loss: 0.4936 - val_cindex_score: 0.7635\n","Epoch 39/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3931 - cindex_score: 0.7490 - val_loss: 0.7548 - val_cindex_score: 0.7484\n","Epoch 40/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3902 - cindex_score: 0.7476 - val_loss: 0.6014 - val_cindex_score: 0.7514\n","Epoch 41/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3834 - cindex_score: 0.7518 - val_loss: 0.8877 - val_cindex_score: 0.7531\n","Epoch 42/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3882 - cindex_score: 0.7479 - val_loss: 0.6218 - val_cindex_score: 0.7485\n","Epoch 43/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3778 - cindex_score: 0.7521 - val_loss: 0.7686 - val_cindex_score: 0.7623\n","Epoch 44/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3774 - cindex_score: 0.7513 - val_loss: 0.8087 - val_cindex_score: 0.7590\n","Epoch 45/100\n","78836/78836 [==============================] - 4s 44us/step - loss: 0.3714 - cindex_score: 0.7543 - val_loss: 0.7008 - val_cindex_score: 0.7610\n","Epoch 46/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3718 - cindex_score: 0.7530 - val_loss: 0.5637 - val_cindex_score: 0.7357\n","Epoch 47/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3863 - cindex_score: 0.7509 - val_loss: 0.6260 - val_cindex_score: 0.7568\n","Epoch 48/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3883 - cindex_score: 0.7504 - val_loss: 0.7269 - val_cindex_score: 0.7556\n","Epoch 49/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3765 - cindex_score: 0.7538 - val_loss: 0.9065 - val_cindex_score: 0.7484\n","Epoch 50/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3837 - cindex_score: 0.7499 - val_loss: 1.0138 - val_cindex_score: 0.7587\n","Epoch 51/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3798 - cindex_score: 0.7505 - val_loss: 0.8263 - val_cindex_score: 0.7583\n","Epoch 52/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3862 - cindex_score: 0.7433 - val_loss: 0.8309 - val_cindex_score: 0.7579\n","Epoch 53/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3740 - cindex_score: 0.7538 - val_loss: 0.7726 - val_cindex_score: 0.7595\n","Epoch 54/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3719 - cindex_score: 0.7530 - val_loss: 0.7069 - val_cindex_score: 0.7640\n","Epoch 55/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3805 - cindex_score: 0.7475 - val_loss: 0.7830 - val_cindex_score: 0.7600\n","Epoch 56/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3737 - cindex_score: 0.7532 - val_loss: 0.8648 - val_cindex_score: 0.7562\n","Epoch 57/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3651 - cindex_score: 0.7557 - val_loss: 0.8172 - val_cindex_score: 0.7575\n","Epoch 58/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3601 - cindex_score: 0.7578 - val_loss: 0.9073 - val_cindex_score: 0.7532\n","Epoch 59/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3506 - cindex_score: 0.7621 - val_loss: 0.8749 - val_cindex_score: 0.7457\n","Epoch 60/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3480 - cindex_score: 0.7629 - val_loss: 0.8217 - val_cindex_score: 0.7521\n","Epoch 61/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3508 - cindex_score: 0.7627 - val_loss: 0.7948 - val_cindex_score: 0.7486\n","Epoch 62/100\n","78836/78836 [==============================] - 4s 45us/step - loss: 0.3416 - cindex_score: 0.7661 - val_loss: 0.8238 - val_cindex_score: 0.7481\n","Epoch 63/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3444 - cindex_score: 0.7655 - val_loss: 0.7273 - val_cindex_score: 0.7438\n","Epoch 64/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3501 - cindex_score: 0.7624 - val_loss: 0.9154 - val_cindex_score: 0.7358\n","Epoch 65/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3451 - cindex_score: 0.7660 - val_loss: 0.9545 - val_cindex_score: 0.7424\n","Epoch 66/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3375 - cindex_score: 0.7681 - val_loss: 0.7727 - val_cindex_score: 0.7480\n","Epoch 67/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3343 - cindex_score: 0.7688 - val_loss: 0.7409 - val_cindex_score: 0.7500\n","Epoch 68/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3404 - cindex_score: 0.7654 - val_loss: 0.8086 - val_cindex_score: 0.7391\n","Epoch 69/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3288 - cindex_score: 0.7695 - val_loss: 0.6601 - val_cindex_score: 0.7520\n","Epoch 70/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3351 - cindex_score: 0.7664 - val_loss: 0.6129 - val_cindex_score: 0.7421\n","Epoch 71/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3386 - cindex_score: 0.7655 - val_loss: 0.6785 - val_cindex_score: 0.7371\n","Epoch 72/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3419 - cindex_score: 0.7645 - val_loss: 0.8034 - val_cindex_score: 0.7600\n","Epoch 73/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3298 - cindex_score: 0.7697 - val_loss: 0.7636 - val_cindex_score: 0.7587\n","Epoch 74/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3273 - cindex_score: 0.7703 - val_loss: 0.6967 - val_cindex_score: 0.7424\n","Epoch 75/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3306 - cindex_score: 0.7695 - val_loss: 0.6007 - val_cindex_score: 0.7450\n","Epoch 76/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3263 - cindex_score: 0.7705 - val_loss: 0.5820 - val_cindex_score: 0.7503\n","Epoch 77/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3268 - cindex_score: 0.7719 - val_loss: 0.5208 - val_cindex_score: 0.7455\n","Epoch 78/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3183 - cindex_score: 0.7768 - val_loss: 0.4165 - val_cindex_score: 0.7465\n","Epoch 79/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3180 - cindex_score: 0.7770 - val_loss: 0.4013 - val_cindex_score: 0.7552\n","Epoch 80/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3154 - cindex_score: 0.7789 - val_loss: 0.3770 - val_cindex_score: 0.7629\n","Epoch 81/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3104 - cindex_score: 0.7802 - val_loss: 0.4052 - val_cindex_score: 0.7636\n","Epoch 82/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3226 - cindex_score: 0.7719 - val_loss: 0.4477 - val_cindex_score: 0.7338\n","Epoch 83/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3115 - cindex_score: 0.7789 - val_loss: 0.4262 - val_cindex_score: 0.7498\n","Epoch 84/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3097 - cindex_score: 0.7792 - val_loss: 0.3755 - val_cindex_score: 0.7647\n","Epoch 85/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3076 - cindex_score: 0.7794 - val_loss: 0.4042 - val_cindex_score: 0.7594\n","Epoch 86/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3031 - cindex_score: 0.7822 - val_loss: 0.3659 - val_cindex_score: 0.7612\n","Epoch 87/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3008 - cindex_score: 0.7834 - val_loss: 0.3602 - val_cindex_score: 0.7635\n","Epoch 88/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3067 - cindex_score: 0.7804 - val_loss: 0.3806 - val_cindex_score: 0.7495\n","Epoch 89/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3048 - cindex_score: 0.7813 - val_loss: 0.3639 - val_cindex_score: 0.7622\n","Epoch 90/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3036 - cindex_score: 0.7805 - val_loss: 0.3491 - val_cindex_score: 0.7599\n","Epoch 91/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3046 - cindex_score: 0.7794 - val_loss: 0.3622 - val_cindex_score: 0.7531\n","Epoch 92/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.3025 - cindex_score: 0.7816 - val_loss: 0.3482 - val_cindex_score: 0.7636\n","Epoch 93/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.2978 - cindex_score: 0.7847 - val_loss: 0.3460 - val_cindex_score: 0.7654\n","Epoch 94/100\n","78836/78836 [==============================] - 3s 43us/step - loss: 0.3039 - cindex_score: 0.7833 - val_loss: 0.3461 - val_cindex_score: 0.7607\n","Epoch 95/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.2958 - cindex_score: 0.7867 - val_loss: 0.3546 - val_cindex_score: 0.7631\n","Epoch 96/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.2898 - cindex_score: 0.7882 - val_loss: 0.3369 - val_cindex_score: 0.7674\n","Epoch 97/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.2873 - cindex_score: 0.7893 - val_loss: 0.3509 - val_cindex_score: 0.7631\n","Epoch 98/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.2886 - cindex_score: 0.7888 - val_loss: 0.3447 - val_cindex_score: 0.7652\n","Epoch 99/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.2877 - cindex_score: 0.7895 - val_loss: 0.3450 - val_cindex_score: 0.7659\n","Epoch 100/100\n","78836/78836 [==============================] - 3s 44us/step - loss: 0.2868 - cindex_score: 0.7890 - val_loss: 0.3550 - val_cindex_score: 0.7588\n","run_experiments.py:456: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:469: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:483: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n"]}]}],"metadata":{"colab":{"collapsed_sections":[],"name":"DeepDTA.ipynb","provenance":[],"mount_file_id":"1bdWOCz5ATzaIqtqb_FOufh6BVxiSSUzZ","authorship_tag":"ABX9TyOpOL/cvUF4DWteLFMGYQ9P"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}