{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":68,"status":"ok","timestamp":1650118002020,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"},"user_tz":300},"id":"Xs22x0M_voz0","outputId":"70387c36-7121-45e1-8ef4-ea623802b7d0"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/DL4H_Spring2022/DeepDTA/source\n"]}],"source":["%cd drive/MyDrive/DL4H_Spring2022/DeepDTA/source/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":249,"status":"ok","timestamp":1650118003490,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"},"user_tz":300},"id":"1TzHAo4jy7aD","outputId":"b9a9d8b4-aadb-4ded-871d-dcbc8457cc57"},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow 1.x selected.\n"]}],"source":["%tensorflow_version 1.x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":633},"executionInfo":{"elapsed":14935,"status":"ok","timestamp":1650117972789,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"},"user_tz":300},"id":"gKx1882yl8tU","outputId":"b4c94b38-c217-4b58-8270-cec324d77a70"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting h5py==2.10.0\n","  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 5.3 MB/s \n","\u001b[?25hCollecting six\n","  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Collecting numpy>=1.7\n","  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n","\u001b[K     |████████████████████████████████| 15.7 MB 48.2 MB/s \n","\u001b[?25hInstalling collected packages: six, numpy, h5py\n","  Attempting uninstall: six\n","    Found existing installation: six 1.15.0\n","    Uninstalling six-1.15.0:\n","      Successfully uninstalled six-1.15.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.5\n","    Uninstalling numpy-1.21.5:\n","      Successfully uninstalled numpy-1.21.5\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lucid 0.3.10 requires umap-learn, which is not installed.\n","tensorflow 1.15.2 requires gast==0.2.2, but you have gast 0.5.3 which is incompatible.\n","lucid 0.3.10 requires numpy<=1.19, but you have numpy 1.21.6 which is incompatible.\n","kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\n","google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed h5py-2.10.0 numpy-1.21.6 six-1.16.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy","six"]}}},"metadata":{},"output_type":"display_data"}],"source":["pip install 'h5py==2.10.0' --force-reinstall"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":190,"status":"ok","timestamp":1650118008119,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"},"user_tz":300},"id":"BVkSCdWcvz7b","outputId":"02e42443-ea4e-4957-c606-cacaebec44ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["arguments.py\t   data\t\t  emetrics.py  logs\t    run_experiments.py\n","auc.jar\t\t   datahelper.py  figures      pretrained\n","combined_davis.h5  DeepDTA.ipynb  go.sh        __pycache__\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":183,"status":"ok","timestamp":1650118031362,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"},"user_tz":300},"id":"-jfEsExzv6We","outputId":"af17f6f8-eac7-4edc-f0ec-93582b0d8d26"},"outputs":[{"name":"stdout","output_type":"stream","text":["total 23992\n","-rwx------ 1 root root     2797 Apr  9 19:05 arguments.py\n","-rwx------ 1 root root    10869 Apr  9 19:05 auc.jar\n","-rwx------ 1 root root 24452560 Apr 15 01:51 combined_davis.h5\n","drwx------ 4 root root     4096 Apr  9 19:08 data\n","-rwx------ 1 root root     5356 Apr  9 19:05 datahelper.py\n","-rwx------ 1 root root    47588 Apr 16 14:06 DeepDTA.ipynb\n","-rwx------ 1 root root     2099 Apr  9 19:05 emetrics.py\n","drwx------ 3 root root     4096 Apr  9 19:27 figures\n","-rwx------ 1 root root      513 Apr 14 19:34 go.sh\n","drwx------ 6 root root     4096 Apr  9 19:27 logs\n","drwx------ 2 root root     4096 Apr 14 15:47 pretrained\n","drwx------ 2 root root     4096 Apr  9 19:24 __pycache__\n","-rwx------ 1 root root    22867 Apr 15 02:44 run_experiments.py\n"]}],"source":["!ls -l"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":99,"status":"ok","timestamp":1650118023275,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"},"user_tz":300},"id":"EJkMGNQsT4CI","outputId":"a197ee9a-641a-4921-905a-8439bc382d75"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/DL4H_Spring2022/DeepDTA\n"]}],"source":["%cd .."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sscXM6hww35Q"},"outputs":[],"source":["!chmod -R 777 source/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":84,"status":"ok","timestamp":1650118028752,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"},"user_tz":300},"id":"Mb-MNJ4gvAOn","outputId":"4f7dd7d1-feb4-405c-b66e-43fb9ac1b1a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/DL4H_Spring2022/DeepDTA/source\n"]}],"source":["%cd source"]},{"cell_type":"markdown","metadata":{"id":"nkNZwVYdM-hC"},"source":["## Davis"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1226331,"status":"ok","timestamp":1650125935278,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"},"user_tz":300},"id":"sew1uA20xB5Q","outputId":"264209b3-4f41-472a-d1b1-da425c148057"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From run_experiments.py:16: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","Using TensorFlow backend.\n","WARNING:tensorflow:From run_experiments.py:19: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","2022-04-16 15:45:53.653761: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2022-04-16 15:45:53.654001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563ecd5412c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2022-04-16 15:45:53.654037: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2022-04-16 15:45:53.655709: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2022-04-16 15:45:53.783313: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 15:45:53.784161: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563ecd541800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2022-04-16 15:45:53.784228: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n","2022-04-16 15:45:53.784432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 15:45:53.785238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2022-04-16 15:45:53.785579: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-04-16 15:45:53.787529: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-04-16 15:45:53.788670: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2022-04-16 15:45:53.789042: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2022-04-16 15:45:53.790936: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2022-04-16 15:45:53.792128: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2022-04-16 15:45:53.795843: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-16 15:45:53.795993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 15:45:53.796757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 15:45:53.797525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2022-04-16 15:45:53.797600: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-04-16 15:45:53.798812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-16 15:45:53.798844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2022-04-16 15:45:53.798862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2022-04-16 15:45:53.799002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 15:45:53.799796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 15:45:53.800502: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-04-16 15:45:53.800558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","Read data/davis/ start\n","68\n","442\n","logs/1650123954.7126462/\n","Reading data/davis/ start\n","val set 5010\n","train set 20036\n","val set 5009\n","train set 20037\n","val set 5009\n","train set 20037\n","val set 5009\n","train set 20037\n","val set 5009\n","train set 20037\n","[[0, 0, 0, 0, 0]]\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From run_experiments.py:432: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n","\n","WARNING:tensorflow:From run_experiments.py:437: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 100, 128)     8320        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_2 (Embedding)         (None, 1000, 128)    3328        input_2[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_1 (Conv1D)               (None, 95, 32)       24608       embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_4 (Conv1D)               (None, 993, 32)      32800       embedding_2[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_2 (Conv1D)               (None, 90, 64)       12352       conv1d_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_5 (Conv1D)               (None, 986, 64)      16448       conv1d_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_3 (Conv1D)               (None, 85, 96)       36960       conv1d_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_6 (Conv1D)               (None, 979, 96)      49248       conv1d_5[0][0]                   \n","__________________________________________________________________________________________________\n","global_max_pooling1d_1 (GlobalM (None, 96)           0           conv1d_3[0][0]                   \n","__________________________________________________________________________________________________\n","global_max_pooling1d_2 (GlobalM (None, 96)           0           conv1d_6[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 192)          0           global_max_pooling1d_1[0][0]     \n","                                                                 global_max_pooling1d_2[0][0]     \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1024)         197632      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1024)         1049600     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 512)          524800      dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 1)            513         dense_3[0][0]                    \n","==================================================================================================\n","Total params: 1,956,609\n","Trainable params: 1,956,609\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 20036 samples, validate on 5010 samples\n","Epoch 1/100\n","2022-04-16 15:45:57.864262: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-04-16 15:45:58.022152: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","20036/20036 [==============================] - 17s 828us/step - loss: 2.4771 - cindex_score: 0.6596 - val_loss: 0.6304 - val_cindex_score: 0.7573\n","Epoch 2/100\n","20036/20036 [==============================] - 13s 630us/step - loss: 0.6163 - cindex_score: 0.7567 - val_loss: 0.5842 - val_cindex_score: 0.7844\n","Epoch 3/100\n","20036/20036 [==============================] - 13s 628us/step - loss: 0.5796 - cindex_score: 0.7757 - val_loss: 0.6169 - val_cindex_score: 0.7938\n","Epoch 4/100\n","20036/20036 [==============================] - 13s 627us/step - loss: 0.5682 - cindex_score: 0.7830 - val_loss: 0.6020 - val_cindex_score: 0.7965\n","Epoch 5/100\n","20036/20036 [==============================] - 13s 626us/step - loss: 0.5617 - cindex_score: 0.7880 - val_loss: 0.5494 - val_cindex_score: 0.7980\n","Epoch 6/100\n","20036/20036 [==============================] - 13s 625us/step - loss: 0.5668 - cindex_score: 0.7878 - val_loss: 0.5737 - val_cindex_score: 0.7982\n","Epoch 7/100\n","20036/20036 [==============================] - 13s 625us/step - loss: 0.5620 - cindex_score: 0.7902 - val_loss: 0.5369 - val_cindex_score: 0.7992\n","Epoch 8/100\n","20036/20036 [==============================] - 13s 626us/step - loss: 0.5658 - cindex_score: 0.7892 - val_loss: 0.5415 - val_cindex_score: 0.8009\n","Epoch 9/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.5643 - cindex_score: 0.7919 - val_loss: 0.5391 - val_cindex_score: 0.8011\n","Epoch 10/100\n","20036/20036 [==============================] - 13s 624us/step - loss: 0.5597 - cindex_score: 0.7937 - val_loss: 0.5338 - val_cindex_score: 0.8028\n","Epoch 11/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.5527 - cindex_score: 0.7958 - val_loss: 0.5218 - val_cindex_score: 0.8033\n","Epoch 12/100\n","20036/20036 [==============================] - 13s 625us/step - loss: 0.5367 - cindex_score: 0.8013 - val_loss: 0.4901 - val_cindex_score: 0.8167\n","Epoch 13/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.5212 - cindex_score: 0.8063 - val_loss: 0.4742 - val_cindex_score: 0.8219\n","Epoch 14/100\n","20036/20036 [==============================] - 13s 625us/step - loss: 0.5090 - cindex_score: 0.8079 - val_loss: 0.4667 - val_cindex_score: 0.8255\n","Epoch 15/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.5059 - cindex_score: 0.8124 - val_loss: 0.4633 - val_cindex_score: 0.8266\n","Epoch 16/100\n","20036/20036 [==============================] - 12s 624us/step - loss: 0.4942 - cindex_score: 0.8164 - val_loss: 0.4816 - val_cindex_score: 0.8319\n","Epoch 17/100\n","20036/20036 [==============================] - 12s 623us/step - loss: 0.4771 - cindex_score: 0.8216 - val_loss: 0.4617 - val_cindex_score: 0.8281\n","Epoch 18/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.4718 - cindex_score: 0.8204 - val_loss: 0.4603 - val_cindex_score: 0.8314\n","Epoch 19/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.4667 - cindex_score: 0.8251 - val_loss: 0.4450 - val_cindex_score: 0.8349\n","Epoch 20/100\n","20036/20036 [==============================] - 13s 624us/step - loss: 0.4449 - cindex_score: 0.8280 - val_loss: 0.4108 - val_cindex_score: 0.8403\n","Epoch 21/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.4161 - cindex_score: 0.8315 - val_loss: 0.3967 - val_cindex_score: 0.8447\n","Epoch 22/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.3921 - cindex_score: 0.8365 - val_loss: 0.3798 - val_cindex_score: 0.8472\n","Epoch 23/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.3788 - cindex_score: 0.8428 - val_loss: 0.3836 - val_cindex_score: 0.8465\n","Epoch 24/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.3685 - cindex_score: 0.8427 - val_loss: 0.3824 - val_cindex_score: 0.8546\n","Epoch 25/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.3568 - cindex_score: 0.8474 - val_loss: 0.3624 - val_cindex_score: 0.8535\n","Epoch 26/100\n","20036/20036 [==============================] - 12s 623us/step - loss: 0.3532 - cindex_score: 0.8527 - val_loss: 0.3489 - val_cindex_score: 0.8587\n","Epoch 27/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.3428 - cindex_score: 0.8527 - val_loss: 0.3905 - val_cindex_score: 0.8575\n","Epoch 28/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.3302 - cindex_score: 0.8569 - val_loss: 0.3454 - val_cindex_score: 0.8634\n","Epoch 29/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.3220 - cindex_score: 0.8598 - val_loss: 0.3335 - val_cindex_score: 0.8613\n","Epoch 30/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.3154 - cindex_score: 0.8621 - val_loss: 0.3253 - val_cindex_score: 0.8591\n","Epoch 31/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.3027 - cindex_score: 0.8647 - val_loss: 0.3308 - val_cindex_score: 0.8593\n","Epoch 32/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.2982 - cindex_score: 0.8648 - val_loss: 0.3144 - val_cindex_score: 0.8633\n","Epoch 33/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.2920 - cindex_score: 0.8674 - val_loss: 0.3241 - val_cindex_score: 0.8606\n","Epoch 34/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.2911 - cindex_score: 0.8692 - val_loss: 0.3136 - val_cindex_score: 0.8677\n","Epoch 35/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.2778 - cindex_score: 0.8713 - val_loss: 0.3763 - val_cindex_score: 0.8658\n","Epoch 36/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.2749 - cindex_score: 0.8718 - val_loss: 0.3756 - val_cindex_score: 0.8624\n","Epoch 37/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.2641 - cindex_score: 0.8753 - val_loss: 0.3364 - val_cindex_score: 0.8639\n","Epoch 38/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.2531 - cindex_score: 0.8766 - val_loss: 0.3263 - val_cindex_score: 0.8675\n","Epoch 39/100\n","20036/20036 [==============================] - 12s 617us/step - loss: 0.2406 - cindex_score: 0.8774 - val_loss: 0.3396 - val_cindex_score: 0.8693\n","Epoch 40/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.2385 - cindex_score: 0.8824 - val_loss: 0.3659 - val_cindex_score: 0.8693\n","Epoch 41/100\n","20036/20036 [==============================] - 12s 617us/step - loss: 0.2304 - cindex_score: 0.8830 - val_loss: 0.3232 - val_cindex_score: 0.8685\n","Epoch 42/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.2275 - cindex_score: 0.8819 - val_loss: 0.3206 - val_cindex_score: 0.8675\n","Epoch 43/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.2242 - cindex_score: 0.8822 - val_loss: 0.3669 - val_cindex_score: 0.8704\n","Epoch 44/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.2135 - cindex_score: 0.8873 - val_loss: 0.3014 - val_cindex_score: 0.8716\n","Epoch 45/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.2018 - cindex_score: 0.8879 - val_loss: 0.3174 - val_cindex_score: 0.8688\n","Epoch 46/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.1988 - cindex_score: 0.8906 - val_loss: 0.2927 - val_cindex_score: 0.8670\n","Epoch 47/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1942 - cindex_score: 0.8911 - val_loss: 0.2822 - val_cindex_score: 0.8684\n","Epoch 48/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1855 - cindex_score: 0.8917 - val_loss: 0.2983 - val_cindex_score: 0.8715\n","Epoch 49/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.1908 - cindex_score: 0.8910 - val_loss: 0.2831 - val_cindex_score: 0.8712\n","Epoch 50/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1948 - cindex_score: 0.8899 - val_loss: 0.2912 - val_cindex_score: 0.8599\n","Epoch 51/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1901 - cindex_score: 0.8938 - val_loss: 0.2748 - val_cindex_score: 0.8733\n","Epoch 52/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1709 - cindex_score: 0.8959 - val_loss: 0.2734 - val_cindex_score: 0.8741\n","Epoch 53/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.1642 - cindex_score: 0.9012 - val_loss: 0.2762 - val_cindex_score: 0.8740\n","Epoch 54/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1566 - cindex_score: 0.9020 - val_loss: 0.2712 - val_cindex_score: 0.8742\n","Epoch 55/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.1533 - cindex_score: 0.9042 - val_loss: 0.2701 - val_cindex_score: 0.8708\n","Epoch 56/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.1473 - cindex_score: 0.9068 - val_loss: 0.2536 - val_cindex_score: 0.8752\n","Epoch 57/100\n","20036/20036 [==============================] - 12s 617us/step - loss: 0.1464 - cindex_score: 0.9054 - val_loss: 0.2776 - val_cindex_score: 0.8748\n","Epoch 58/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1426 - cindex_score: 0.9085 - val_loss: 0.2680 - val_cindex_score: 0.8734\n","Epoch 59/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.1407 - cindex_score: 0.9108 - val_loss: 0.2583 - val_cindex_score: 0.8718\n","Epoch 60/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1418 - cindex_score: 0.9088 - val_loss: 0.2542 - val_cindex_score: 0.8706\n","Epoch 61/100\n","20036/20036 [==============================] - 12s 617us/step - loss: 0.1353 - cindex_score: 0.9114 - val_loss: 0.2604 - val_cindex_score: 0.8793\n","Epoch 62/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.1290 - cindex_score: 0.9133 - val_loss: 0.2541 - val_cindex_score: 0.8722\n","Epoch 63/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.1279 - cindex_score: 0.9155 - val_loss: 0.2671 - val_cindex_score: 0.8753\n","Epoch 64/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1286 - cindex_score: 0.9159 - val_loss: 0.2542 - val_cindex_score: 0.8743\n","Epoch 65/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1218 - cindex_score: 0.9187 - val_loss: 0.2634 - val_cindex_score: 0.8724\n","Epoch 66/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1196 - cindex_score: 0.9194 - val_loss: 0.2677 - val_cindex_score: 0.8680\n","Epoch 67/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.1190 - cindex_score: 0.9215 - val_loss: 0.2669 - val_cindex_score: 0.8729\n","Epoch 68/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1172 - cindex_score: 0.9236 - val_loss: 0.2750 - val_cindex_score: 0.8769\n","Epoch 69/100\n","20036/20036 [==============================] - 12s 617us/step - loss: 0.1152 - cindex_score: 0.9227 - val_loss: 0.2796 - val_cindex_score: 0.8753\n","Epoch 70/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.1161 - cindex_score: 0.9230 - val_loss: 0.2922 - val_cindex_score: 0.8759\n","Epoch 71/100\n","20036/20036 [==============================] - 12s 617us/step - loss: 0.1178 - cindex_score: 0.9269 - val_loss: 0.2950 - val_cindex_score: 0.8728\n","Epoch 00071: early stopping\n","run_experiments.py:453: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:466: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:480: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","[[0, 0, 0, 0, 0]]\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","embedding_3 (Embedding)         (None, 100, 128)     8320        input_3[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_4 (Embedding)         (None, 1000, 128)    3328        input_4[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_7 (Conv1D)               (None, 95, 32)       24608       embedding_3[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_10 (Conv1D)              (None, 993, 32)      32800       embedding_4[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_8 (Conv1D)               (None, 90, 64)       12352       conv1d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_11 (Conv1D)              (None, 986, 64)      16448       conv1d_10[0][0]                  \n","__________________________________________________________________________________________________\n","conv1d_9 (Conv1D)               (None, 85, 96)       36960       conv1d_8[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_12 (Conv1D)              (None, 979, 96)      49248       conv1d_11[0][0]                  \n","__________________________________________________________________________________________________\n","global_max_pooling1d_3 (GlobalM (None, 96)           0           conv1d_9[0][0]                   \n","__________________________________________________________________________________________________\n","global_max_pooling1d_4 (GlobalM (None, 96)           0           conv1d_12[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 192)          0           global_max_pooling1d_3[0][0]     \n","                                                                 global_max_pooling1d_4[0][0]     \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 1024)         197632      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 1024)         0           dense_5[0][0]                    \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 1024)         1049600     dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 1024)         0           dense_6[0][0]                    \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 512)          524800      dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 1)            513         dense_7[0][0]                    \n","==================================================================================================\n","Total params: 1,956,609\n","Trainable params: 1,956,609\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Train on 20036 samples, validate on 5010 samples\n","Epoch 1/100\n","20036/20036 [==============================] - 13s 658us/step - loss: 2.7358 - cindex_score: 0.6436 - val_loss: 0.6552 - val_cindex_score: 0.7505\n","Epoch 2/100\n","20036/20036 [==============================] - 13s 628us/step - loss: 0.6263 - cindex_score: 0.7490 - val_loss: 0.6406 - val_cindex_score: 0.7776\n","Epoch 3/100\n","20036/20036 [==============================] - 13s 626us/step - loss: 0.5839 - cindex_score: 0.7732 - val_loss: 0.5982 - val_cindex_score: 0.7868\n","Epoch 4/100\n","20036/20036 [==============================] - 13s 625us/step - loss: 0.5691 - cindex_score: 0.7813 - val_loss: 0.6482 - val_cindex_score: 0.7908\n","Epoch 5/100\n","20036/20036 [==============================] - 13s 627us/step - loss: 0.5617 - cindex_score: 0.7857 - val_loss: 0.6125 - val_cindex_score: 0.7924\n","Epoch 6/100\n","20036/20036 [==============================] - 13s 626us/step - loss: 0.5570 - cindex_score: 0.7896 - val_loss: 0.6088 - val_cindex_score: 0.7951\n","Epoch 7/100\n","20036/20036 [==============================] - 13s 626us/step - loss: 0.5523 - cindex_score: 0.7917 - val_loss: 0.5691 - val_cindex_score: 0.7963\n","Epoch 8/100\n","20036/20036 [==============================] - 13s 627us/step - loss: 0.5423 - cindex_score: 0.7922 - val_loss: 0.5382 - val_cindex_score: 0.8006\n","Epoch 9/100\n","20036/20036 [==============================] - 13s 625us/step - loss: 0.5332 - cindex_score: 0.7966 - val_loss: 0.5281 - val_cindex_score: 0.8020\n","Epoch 10/100\n","20036/20036 [==============================] - 13s 625us/step - loss: 0.5237 - cindex_score: 0.7997 - val_loss: 0.5256 - val_cindex_score: 0.8046\n","Epoch 11/100\n","20036/20036 [==============================] - 13s 625us/step - loss: 0.5218 - cindex_score: 0.7990 - val_loss: 0.5133 - val_cindex_score: 0.8076\n","Epoch 12/100\n","20036/20036 [==============================] - 13s 626us/step - loss: 0.5106 - cindex_score: 0.8039 - val_loss: 0.5048 - val_cindex_score: 0.8094\n","Epoch 13/100\n","20036/20036 [==============================] - 13s 626us/step - loss: 0.5050 - cindex_score: 0.8087 - val_loss: 0.4938 - val_cindex_score: 0.8153\n","Epoch 14/100\n","20036/20036 [==============================] - 13s 625us/step - loss: 0.4926 - cindex_score: 0.8142 - val_loss: 0.4824 - val_cindex_score: 0.8157\n","Epoch 15/100\n","20036/20036 [==============================] - 13s 625us/step - loss: 0.4847 - cindex_score: 0.8175 - val_loss: 0.4905 - val_cindex_score: 0.8185\n","Epoch 16/100\n","20036/20036 [==============================] - 12s 623us/step - loss: 0.4730 - cindex_score: 0.8184 - val_loss: 0.4712 - val_cindex_score: 0.8203\n","Epoch 17/100\n","20036/20036 [==============================] - 13s 626us/step - loss: 0.4668 - cindex_score: 0.8206 - val_loss: 0.4677 - val_cindex_score: 0.8202\n","Epoch 18/100\n","20036/20036 [==============================] - 13s 625us/step - loss: 0.4671 - cindex_score: 0.8198 - val_loss: 0.4718 - val_cindex_score: 0.8198\n","Epoch 19/100\n","20036/20036 [==============================] - 13s 624us/step - loss: 0.4560 - cindex_score: 0.8232 - val_loss: 0.4645 - val_cindex_score: 0.8219\n","Epoch 20/100\n","20036/20036 [==============================] - 12s 623us/step - loss: 0.4423 - cindex_score: 0.8242 - val_loss: 0.4484 - val_cindex_score: 0.8255\n","Epoch 21/100\n","20036/20036 [==============================] - 12s 624us/step - loss: 0.4269 - cindex_score: 0.8291 - val_loss: 0.4299 - val_cindex_score: 0.8282\n","Epoch 22/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.4095 - cindex_score: 0.8345 - val_loss: 0.4211 - val_cindex_score: 0.8329\n","Epoch 23/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.3991 - cindex_score: 0.8359 - val_loss: 0.4204 - val_cindex_score: 0.8377\n","Epoch 24/100\n","20036/20036 [==============================] - 12s 623us/step - loss: 0.3770 - cindex_score: 0.8402 - val_loss: 0.3966 - val_cindex_score: 0.8412\n","Epoch 25/100\n","20036/20036 [==============================] - 12s 623us/step - loss: 0.3707 - cindex_score: 0.8483 - val_loss: 0.4412 - val_cindex_score: 0.8527\n","Epoch 26/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.3404 - cindex_score: 0.8522 - val_loss: 0.3861 - val_cindex_score: 0.8511\n","Epoch 27/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.3270 - cindex_score: 0.8540 - val_loss: 0.3762 - val_cindex_score: 0.8509\n","Epoch 28/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.3279 - cindex_score: 0.8554 - val_loss: 0.3646 - val_cindex_score: 0.8595\n","Epoch 29/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.3242 - cindex_score: 0.8574 - val_loss: 0.3848 - val_cindex_score: 0.8594\n","Epoch 30/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.3166 - cindex_score: 0.8624 - val_loss: 0.3621 - val_cindex_score: 0.8621\n","Epoch 31/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.3018 - cindex_score: 0.8651 - val_loss: 0.3425 - val_cindex_score: 0.8632\n","Epoch 32/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.2973 - cindex_score: 0.8678 - val_loss: 0.3487 - val_cindex_score: 0.8653\n","Epoch 33/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.2838 - cindex_score: 0.8698 - val_loss: 0.3405 - val_cindex_score: 0.8656\n","Epoch 34/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.2771 - cindex_score: 0.8694 - val_loss: 0.3447 - val_cindex_score: 0.8665\n","Epoch 35/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.2681 - cindex_score: 0.8718 - val_loss: 0.3825 - val_cindex_score: 0.8641\n","Epoch 36/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.2581 - cindex_score: 0.8770 - val_loss: 0.4038 - val_cindex_score: 0.8632\n","Epoch 37/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.2554 - cindex_score: 0.8783 - val_loss: 0.3693 - val_cindex_score: 0.8650\n","Epoch 38/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.2335 - cindex_score: 0.8803 - val_loss: 0.3306 - val_cindex_score: 0.8611\n","Epoch 39/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.2330 - cindex_score: 0.8813 - val_loss: 0.3436 - val_cindex_score: 0.8596\n","Epoch 40/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.2260 - cindex_score: 0.8825 - val_loss: 0.3264 - val_cindex_score: 0.8610\n","Epoch 41/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.2181 - cindex_score: 0.8838 - val_loss: 0.3127 - val_cindex_score: 0.8658\n","Epoch 42/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.2106 - cindex_score: 0.8847 - val_loss: 0.3192 - val_cindex_score: 0.8741\n","Epoch 43/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.2033 - cindex_score: 0.8838 - val_loss: 0.2891 - val_cindex_score: 0.8743\n","Epoch 44/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.1972 - cindex_score: 0.8884 - val_loss: 0.2958 - val_cindex_score: 0.8699\n","Epoch 45/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1923 - cindex_score: 0.8907 - val_loss: 0.2957 - val_cindex_score: 0.8734\n","Epoch 46/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1868 - cindex_score: 0.8916 - val_loss: 0.2845 - val_cindex_score: 0.8694\n","Epoch 47/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.1796 - cindex_score: 0.8938 - val_loss: 0.2863 - val_cindex_score: 0.8681\n","Epoch 48/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.1778 - cindex_score: 0.8946 - val_loss: 0.2922 - val_cindex_score: 0.8650\n","Epoch 49/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.1791 - cindex_score: 0.8935 - val_loss: 0.2888 - val_cindex_score: 0.8676\n","Epoch 50/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.1718 - cindex_score: 0.8957 - val_loss: 0.3016 - val_cindex_score: 0.8713\n","Epoch 51/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.1676 - cindex_score: 0.8939 - val_loss: 0.2848 - val_cindex_score: 0.8728\n","Epoch 52/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.1638 - cindex_score: 0.8990 - val_loss: 0.2912 - val_cindex_score: 0.8755\n","Epoch 53/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1598 - cindex_score: 0.9025 - val_loss: 0.2856 - val_cindex_score: 0.8717\n","Epoch 54/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1543 - cindex_score: 0.9040 - val_loss: 0.2851 - val_cindex_score: 0.8698\n","Epoch 55/100\n","20036/20036 [==============================] - 12s 621us/step - loss: 0.1514 - cindex_score: 0.9048 - val_loss: 0.2800 - val_cindex_score: 0.8716\n","Epoch 56/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1549 - cindex_score: 0.9049 - val_loss: 0.3029 - val_cindex_score: 0.8695\n","Epoch 57/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1517 - cindex_score: 0.9088 - val_loss: 0.2858 - val_cindex_score: 0.8731\n","Epoch 58/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1428 - cindex_score: 0.9083 - val_loss: 0.2844 - val_cindex_score: 0.8690\n","Epoch 59/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1455 - cindex_score: 0.9089 - val_loss: 0.2729 - val_cindex_score: 0.8710\n","Epoch 60/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1390 - cindex_score: 0.9118 - val_loss: 0.2725 - val_cindex_score: 0.8654\n","Epoch 61/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1343 - cindex_score: 0.9129 - val_loss: 0.2652 - val_cindex_score: 0.8685\n","Epoch 62/100\n","20036/20036 [==============================] - 12s 622us/step - loss: 0.1342 - cindex_score: 0.9141 - val_loss: 0.2957 - val_cindex_score: 0.8737\n","Epoch 63/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1288 - cindex_score: 0.9159 - val_loss: 0.3277 - val_cindex_score: 0.8727\n","Epoch 64/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1317 - cindex_score: 0.9161 - val_loss: 0.3041 - val_cindex_score: 0.8737\n","Epoch 65/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.1295 - cindex_score: 0.9186 - val_loss: 0.3026 - val_cindex_score: 0.8763\n","Epoch 66/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1324 - cindex_score: 0.9184 - val_loss: 0.2975 - val_cindex_score: 0.8784\n","Epoch 67/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1267 - cindex_score: 0.9187 - val_loss: 0.2686 - val_cindex_score: 0.8756\n","Epoch 68/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.1277 - cindex_score: 0.9213 - val_loss: 0.2723 - val_cindex_score: 0.8756\n","Epoch 69/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1248 - cindex_score: 0.9205 - val_loss: 0.2762 - val_cindex_score: 0.8743\n","Epoch 70/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1298 - cindex_score: 0.9222 - val_loss: 0.2737 - val_cindex_score: 0.8645\n","Epoch 71/100\n","20036/20036 [==============================] - 12s 618us/step - loss: 0.1421 - cindex_score: 0.9201 - val_loss: 0.3069 - val_cindex_score: 0.8727\n","Epoch 72/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1424 - cindex_score: 0.9214 - val_loss: 0.2758 - val_cindex_score: 0.8674\n","Epoch 73/100\n","20036/20036 [==============================] - 12s 620us/step - loss: 0.1301 - cindex_score: 0.9251 - val_loss: 0.2721 - val_cindex_score: 0.8670\n","Epoch 74/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1292 - cindex_score: 0.9256 - val_loss: 0.3148 - val_cindex_score: 0.8615\n","Epoch 75/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1462 - cindex_score: 0.9255 - val_loss: 0.3460 - val_cindex_score: 0.8609\n","Epoch 76/100\n","20036/20036 [==============================] - 12s 619us/step - loss: 0.1394 - cindex_score: 0.9242 - val_loss: 0.2766 - val_cindex_score: 0.8678\n","Epoch 00076: early stopping\n","run_experiments.py:453: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:466: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:480: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n"]}],"source":["!./go.sh"]},{"cell_type":"markdown","metadata":{"id":"Xf8UvjPtNCAI"},"source":["## KIBA"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"JwmWBSkhNDUE","outputId":"4760c728-1b73-45e2-891e-7d3fb25b379a"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From run_experiments.py:16: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","Using TensorFlow backend.\n","WARNING:tensorflow:From run_experiments.py:19: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From run_experiments.py:20: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","2022-04-16 17:06:31.808102: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2022-04-16 17:06:31.808309: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563e6618b2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2022-04-16 17:06:31.808346: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2022-04-16 17:06:31.810031: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2022-04-16 17:06:31.941740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 17:06:31.942855: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563e6618b800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2022-04-16 17:06:31.942909: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n","2022-04-16 17:06:31.943166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 17:06:31.944052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2022-04-16 17:06:31.944511: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-04-16 17:06:31.946264: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-04-16 17:06:31.947335: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2022-04-16 17:06:31.947698: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2022-04-16 17:06:31.949799: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2022-04-16 17:06:31.950893: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2022-04-16 17:06:31.954924: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-16 17:06:31.955032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 17:06:31.955777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 17:06:31.956407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2022-04-16 17:06:31.956475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2022-04-16 17:06:31.957685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-16 17:06:31.957719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2022-04-16 17:06:31.957739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2022-04-16 17:06:31.957904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 17:06:31.958747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-16 17:06:31.959581: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-04-16 17:06:31.959640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","Read data/kiba/ start\n","2111\n","229\n","logs/1650128792.872829/\n","Reading data/kiba/ start\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","val set 19709\n","train set 78836\n","[[0, 0, 0, 0, 0]]\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From run_experiments.py:432: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n","\n","WARNING:tensorflow:From run_experiments.py:437: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 100, 128)     8320        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_2 (Embedding)         (None, 1000, 128)    3328        input_2[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_1 (Conv1D)               (None, 95, 32)       24608       embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_4 (Conv1D)               (None, 993, 32)      32800       embedding_2[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_2 (Conv1D)               (None, 90, 64)       12352       conv1d_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_5 (Conv1D)               (None, 986, 64)      16448       conv1d_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_3 (Conv1D)               (None, 85, 96)       36960       conv1d_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_6 (Conv1D)               (None, 979, 96)      49248       conv1d_5[0][0]                   \n","__________________________________________________________________________________________________\n","global_max_pooling1d_1 (GlobalM (None, 96)           0           conv1d_3[0][0]                   \n","__________________________________________________________________________________________________\n","global_max_pooling1d_2 (GlobalM (None, 96)           0           conv1d_6[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 192)          0           global_max_pooling1d_1[0][0]     \n","                                                                 global_max_pooling1d_2[0][0]     \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1024)         197632      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1024)         1049600     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 512)          524800      dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 1)            513         dense_3[0][0]                    \n","==================================================================================================\n","Total params: 1,956,609\n","Trainable params: 1,956,609\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 78836 samples, validate on 19709 samples\n","Epoch 1/100\n","2022-04-16 17:06:36.983235: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2022-04-16 17:06:37.133268: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","78836/78836 [==============================] - 54s 689us/step - loss: 3.0435 - cindex_score: 0.6089 - val_loss: 0.5205 - val_cindex_score: 0.7141\n","Epoch 2/100\n","78836/78836 [==============================] - 49s 627us/step - loss: 0.6050 - cindex_score: 0.6782 - val_loss: 0.4630 - val_cindex_score: 0.7340\n","Epoch 3/100\n","78836/78836 [==============================] - 49s 623us/step - loss: 0.5470 - cindex_score: 0.7042 - val_loss: 0.4565 - val_cindex_score: 0.7452\n","Epoch 4/100\n","78836/78836 [==============================] - 49s 625us/step - loss: 0.5232 - cindex_score: 0.7166 - val_loss: 0.4698 - val_cindex_score: 0.7510\n","Epoch 5/100\n","78836/78836 [==============================] - 49s 621us/step - loss: 0.5195 - cindex_score: 0.7238 - val_loss: 0.6212 - val_cindex_score: 0.7505\n","Epoch 6/100\n","78836/78836 [==============================] - 49s 625us/step - loss: 0.5015 - cindex_score: 0.7281 - val_loss: 0.6286 - val_cindex_score: 0.7527\n","Epoch 7/100\n","78836/78836 [==============================] - 49s 622us/step - loss: 0.4966 - cindex_score: 0.7304 - val_loss: 0.4692 - val_cindex_score: 0.7542\n","Epoch 8/100\n","78836/78836 [==============================] - 49s 625us/step - loss: 0.4879 - cindex_score: 0.7331 - val_loss: 0.4023 - val_cindex_score: 0.7543\n","Epoch 9/100\n","78836/78836 [==============================] - 49s 620us/step - loss: 0.4672 - cindex_score: 0.7342 - val_loss: 0.4072 - val_cindex_score: 0.7557\n","Epoch 10/100\n","78836/78836 [==============================] - 49s 623us/step - loss: 0.4589 - cindex_score: 0.7372 - val_loss: 0.3942 - val_cindex_score: 0.7564\n","Epoch 11/100\n","78836/78836 [==============================] - 49s 619us/step - loss: 0.4531 - cindex_score: 0.7403 - val_loss: 0.3762 - val_cindex_score: 0.7668\n","Epoch 12/100\n","78836/78836 [==============================] - 49s 623us/step - loss: 0.4293 - cindex_score: 0.7447 - val_loss: 0.3792 - val_cindex_score: 0.7723\n","Epoch 13/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.4103 - cindex_score: 0.7492 - val_loss: 0.3521 - val_cindex_score: 0.7743\n","Epoch 14/100\n","78836/78836 [==============================] - 49s 622us/step - loss: 0.3987 - cindex_score: 0.7534 - val_loss: 0.3781 - val_cindex_score: 0.7701\n","Epoch 15/100\n","78836/78836 [==============================] - 49s 619us/step - loss: 0.3885 - cindex_score: 0.7567 - val_loss: 0.3648 - val_cindex_score: 0.7785\n","Epoch 16/100\n","78836/78836 [==============================] - 49s 621us/step - loss: 0.3774 - cindex_score: 0.7612 - val_loss: 0.3251 - val_cindex_score: 0.7824\n","Epoch 17/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.3704 - cindex_score: 0.7643 - val_loss: 0.3240 - val_cindex_score: 0.7845\n","Epoch 18/100\n","78836/78836 [==============================] - 49s 620us/step - loss: 0.3563 - cindex_score: 0.7671 - val_loss: 0.3249 - val_cindex_score: 0.7890\n","Epoch 19/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.3466 - cindex_score: 0.7714 - val_loss: 0.3123 - val_cindex_score: 0.7929\n","Epoch 20/100\n","78836/78836 [==============================] - 49s 621us/step - loss: 0.3415 - cindex_score: 0.7747 - val_loss: 0.3391 - val_cindex_score: 0.7893\n","Epoch 21/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.3339 - cindex_score: 0.7764 - val_loss: 0.3315 - val_cindex_score: 0.7906\n","Epoch 22/100\n","78836/78836 [==============================] - 49s 619us/step - loss: 0.3217 - cindex_score: 0.7798 - val_loss: 0.3149 - val_cindex_score: 0.7973\n","Epoch 23/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.3139 - cindex_score: 0.7826 - val_loss: 0.3067 - val_cindex_score: 0.7998\n","Epoch 24/100\n","78836/78836 [==============================] - 49s 619us/step - loss: 0.3120 - cindex_score: 0.7844 - val_loss: 0.3000 - val_cindex_score: 0.8013\n","Epoch 25/100\n","78836/78836 [==============================] - 49s 615us/step - loss: 0.2972 - cindex_score: 0.7888 - val_loss: 0.3058 - val_cindex_score: 0.8049\n","Epoch 26/100\n","78836/78836 [==============================] - 49s 618us/step - loss: 0.2929 - cindex_score: 0.7906 - val_loss: 0.2901 - val_cindex_score: 0.8074\n","Epoch 27/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.2790 - cindex_score: 0.7955 - val_loss: 0.2814 - val_cindex_score: 0.8074\n","Epoch 28/100\n","78836/78836 [==============================] - 49s 618us/step - loss: 0.2739 - cindex_score: 0.7975 - val_loss: 0.2784 - val_cindex_score: 0.8103\n","Epoch 29/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.2682 - cindex_score: 0.8004 - val_loss: 0.2728 - val_cindex_score: 0.8103\n","Epoch 30/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2638 - cindex_score: 0.8035 - val_loss: 0.2677 - val_cindex_score: 0.8137\n","Epoch 31/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.2453 - cindex_score: 0.8095 - val_loss: 0.2563 - val_cindex_score: 0.8158\n","Epoch 32/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2385 - cindex_score: 0.8129 - val_loss: 0.2563 - val_cindex_score: 0.8181\n","Epoch 33/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.2297 - cindex_score: 0.8158 - val_loss: 0.2599 - val_cindex_score: 0.8192\n","Epoch 34/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2221 - cindex_score: 0.8201 - val_loss: 0.2630 - val_cindex_score: 0.8195\n","Epoch 35/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.2193 - cindex_score: 0.8221 - val_loss: 0.2547 - val_cindex_score: 0.8166\n","Epoch 36/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2107 - cindex_score: 0.8251 - val_loss: 0.2622 - val_cindex_score: 0.8193\n","Epoch 37/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.2042 - cindex_score: 0.8277 - val_loss: 0.2483 - val_cindex_score: 0.8262\n","Epoch 38/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.2063 - cindex_score: 0.8310 - val_loss: 0.2395 - val_cindex_score: 0.8270\n","Epoch 39/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.2028 - cindex_score: 0.8327 - val_loss: 0.2481 - val_cindex_score: 0.8206\n","Epoch 40/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.1913 - cindex_score: 0.8364 - val_loss: 0.2636 - val_cindex_score: 0.8264\n","Epoch 41/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.1830 - cindex_score: 0.8401 - val_loss: 0.2383 - val_cindex_score: 0.8284\n","Epoch 42/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.1719 - cindex_score: 0.8426 - val_loss: 0.2321 - val_cindex_score: 0.8282\n","Epoch 43/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.1725 - cindex_score: 0.8430 - val_loss: 0.2344 - val_cindex_score: 0.8285\n","Epoch 44/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.1616 - cindex_score: 0.8464 - val_loss: 0.2381 - val_cindex_score: 0.8304\n","Epoch 45/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.1546 - cindex_score: 0.8502 - val_loss: 0.2298 - val_cindex_score: 0.8320\n","Epoch 46/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.1503 - cindex_score: 0.8524 - val_loss: 0.2280 - val_cindex_score: 0.8299\n","Epoch 47/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.1419 - cindex_score: 0.8567 - val_loss: 0.2351 - val_cindex_score: 0.8335\n","Epoch 48/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.1459 - cindex_score: 0.8566 - val_loss: 0.2288 - val_cindex_score: 0.8296\n","Epoch 49/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.1376 - cindex_score: 0.8609 - val_loss: 0.2272 - val_cindex_score: 0.8321\n","Epoch 50/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.1336 - cindex_score: 0.8635 - val_loss: 0.2194 - val_cindex_score: 0.8358\n","Epoch 51/100\n","78836/78836 [==============================] - 48s 611us/step - loss: 0.1318 - cindex_score: 0.8666 - val_loss: 0.2267 - val_cindex_score: 0.8381\n","Epoch 52/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.1285 - cindex_score: 0.8684 - val_loss: 0.2247 - val_cindex_score: 0.8326\n","Epoch 53/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.1286 - cindex_score: 0.8701 - val_loss: 0.2196 - val_cindex_score: 0.8378\n","Epoch 54/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.1219 - cindex_score: 0.8742 - val_loss: 0.2505 - val_cindex_score: 0.8390\n","Epoch 55/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.1267 - cindex_score: 0.8740 - val_loss: 0.2230 - val_cindex_score: 0.8382\n","Epoch 56/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.1245 - cindex_score: 0.8757 - val_loss: 0.2408 - val_cindex_score: 0.8374\n","Epoch 57/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.1131 - cindex_score: 0.8793 - val_loss: 0.2442 - val_cindex_score: 0.8402\n","Epoch 58/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.1046 - cindex_score: 0.8828 - val_loss: 0.2136 - val_cindex_score: 0.8436\n","Epoch 59/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.1021 - cindex_score: 0.8851 - val_loss: 0.2118 - val_cindex_score: 0.8449\n","Epoch 60/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.1019 - cindex_score: 0.8861 - val_loss: 0.2157 - val_cindex_score: 0.8436\n","Epoch 61/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.1080 - cindex_score: 0.8866 - val_loss: 0.2212 - val_cindex_score: 0.8421\n","Epoch 62/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1046 - cindex_score: 0.8878 - val_loss: 0.2107 - val_cindex_score: 0.8446\n","Epoch 63/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.0973 - cindex_score: 0.8908 - val_loss: 0.2193 - val_cindex_score: 0.8446\n","Epoch 64/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0944 - cindex_score: 0.8925 - val_loss: 0.2074 - val_cindex_score: 0.8482\n","Epoch 65/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0919 - cindex_score: 0.8939 - val_loss: 0.2105 - val_cindex_score: 0.8493\n","Epoch 66/100\n","78836/78836 [==============================] - 49s 615us/step - loss: 0.0860 - cindex_score: 0.8971 - val_loss: 0.2094 - val_cindex_score: 0.8519\n","Epoch 67/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.0848 - cindex_score: 0.8986 - val_loss: 0.2071 - val_cindex_score: 0.8532\n","Epoch 68/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0814 - cindex_score: 0.9009 - val_loss: 0.2093 - val_cindex_score: 0.8502\n","Epoch 69/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.0790 - cindex_score: 0.9027 - val_loss: 0.2104 - val_cindex_score: 0.8517\n","Epoch 70/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0809 - cindex_score: 0.9026 - val_loss: 0.2098 - val_cindex_score: 0.8505\n","Epoch 71/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.0834 - cindex_score: 0.9026 - val_loss: 0.2120 - val_cindex_score: 0.8503\n","Epoch 72/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0877 - cindex_score: 0.9027 - val_loss: 0.2158 - val_cindex_score: 0.8502\n","Epoch 73/100\n","78836/78836 [==============================] - 48s 611us/step - loss: 0.0861 - cindex_score: 0.9028 - val_loss: 0.2101 - val_cindex_score: 0.8522\n","Epoch 74/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0815 - cindex_score: 0.9052 - val_loss: 0.2398 - val_cindex_score: 0.8522\n","Epoch 75/100\n","78836/78836 [==============================] - 48s 611us/step - loss: 0.0801 - cindex_score: 0.9062 - val_loss: 0.2376 - val_cindex_score: 0.8548\n","Epoch 76/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0786 - cindex_score: 0.9065 - val_loss: 0.2302 - val_cindex_score: 0.8545\n","Epoch 77/100\n","78836/78836 [==============================] - 48s 611us/step - loss: 0.0739 - cindex_score: 0.9098 - val_loss: 0.2203 - val_cindex_score: 0.8533\n","Epoch 78/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0662 - cindex_score: 0.9124 - val_loss: 0.2226 - val_cindex_score: 0.8548\n","Epoch 79/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.0670 - cindex_score: 0.9126 - val_loss: 0.2117 - val_cindex_score: 0.8572\n","Epoch 80/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0627 - cindex_score: 0.9152 - val_loss: 0.2099 - val_cindex_score: 0.8565\n","Epoch 81/100\n","78836/78836 [==============================] - 48s 611us/step - loss: 0.0619 - cindex_score: 0.9157 - val_loss: 0.2057 - val_cindex_score: 0.8549\n","Epoch 82/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0619 - cindex_score: 0.9162 - val_loss: 0.2083 - val_cindex_score: 0.8583\n","Epoch 83/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.0628 - cindex_score: 0.9151 - val_loss: 0.2082 - val_cindex_score: 0.8550\n","Epoch 84/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.0619 - cindex_score: 0.9161 - val_loss: 0.2056 - val_cindex_score: 0.8548\n","Epoch 85/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.0614 - cindex_score: 0.9166 - val_loss: 0.2039 - val_cindex_score: 0.8583\n","Epoch 86/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.0602 - cindex_score: 0.9182 - val_loss: 0.2028 - val_cindex_score: 0.8584\n","Epoch 87/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0623 - cindex_score: 0.9165 - val_loss: 0.1988 - val_cindex_score: 0.8589\n","Epoch 88/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.0595 - cindex_score: 0.9181 - val_loss: 0.1975 - val_cindex_score: 0.8581\n","Epoch 89/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.0579 - cindex_score: 0.9194 - val_loss: 0.2089 - val_cindex_score: 0.8580\n","Epoch 90/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.0593 - cindex_score: 0.9191 - val_loss: 0.2091 - val_cindex_score: 0.8579\n","Epoch 91/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0596 - cindex_score: 0.9194 - val_loss: 0.2043 - val_cindex_score: 0.8570\n","Epoch 92/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.0678 - cindex_score: 0.9163 - val_loss: 0.2090 - val_cindex_score: 0.8552\n","Epoch 93/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0591 - cindex_score: 0.9195 - val_loss: 0.2027 - val_cindex_score: 0.8587\n","Epoch 94/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0531 - cindex_score: 0.9239 - val_loss: 0.1991 - val_cindex_score: 0.8589\n","Epoch 95/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.0539 - cindex_score: 0.9247 - val_loss: 0.1943 - val_cindex_score: 0.8615\n","Epoch 96/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.0522 - cindex_score: 0.9255 - val_loss: 0.1945 - val_cindex_score: 0.8607\n","Epoch 97/100\n","78836/78836 [==============================] - 48s 612us/step - loss: 0.0507 - cindex_score: 0.9264 - val_loss: 0.1987 - val_cindex_score: 0.8622\n","Epoch 98/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0552 - cindex_score: 0.9233 - val_loss: 0.2064 - val_cindex_score: 0.8551\n","Epoch 99/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0566 - cindex_score: 0.9214 - val_loss: 0.1979 - val_cindex_score: 0.8604\n","Epoch 100/100\n","78836/78836 [==============================] - 49s 615us/step - loss: 0.0533 - cindex_score: 0.9249 - val_loss: 0.1986 - val_cindex_score: 0.8605\n","run_experiments.py:453: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:466: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:480: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","[[0, 0, 0, 0, 0]]\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","embedding_3 (Embedding)         (None, 100, 128)     8320        input_3[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_4 (Embedding)         (None, 1000, 128)    3328        input_4[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_7 (Conv1D)               (None, 95, 32)       24608       embedding_3[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_10 (Conv1D)              (None, 993, 32)      32800       embedding_4[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_8 (Conv1D)               (None, 90, 64)       12352       conv1d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_11 (Conv1D)              (None, 986, 64)      16448       conv1d_10[0][0]                  \n","__________________________________________________________________________________________________\n","conv1d_9 (Conv1D)               (None, 85, 96)       36960       conv1d_8[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_12 (Conv1D)              (None, 979, 96)      49248       conv1d_11[0][0]                  \n","__________________________________________________________________________________________________\n","global_max_pooling1d_3 (GlobalM (None, 96)           0           conv1d_9[0][0]                   \n","__________________________________________________________________________________________________\n","global_max_pooling1d_4 (GlobalM (None, 96)           0           conv1d_12[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 192)          0           global_max_pooling1d_3[0][0]     \n","                                                                 global_max_pooling1d_4[0][0]     \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 1024)         197632      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 1024)         0           dense_5[0][0]                    \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 1024)         1049600     dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 1024)         0           dense_6[0][0]                    \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 512)          524800      dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 1)            513         dense_7[0][0]                    \n","==================================================================================================\n","Total params: 1,956,609\n","Trainable params: 1,956,609\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Train on 78836 samples, validate on 19709 samples\n","Epoch 1/100\n","78836/78836 [==============================] - 50s 639us/step - loss: 3.2802 - cindex_score: 0.6018 - val_loss: 0.5002 - val_cindex_score: 0.7097\n","Epoch 2/100\n","78836/78836 [==============================] - 49s 627us/step - loss: 0.5835 - cindex_score: 0.6790 - val_loss: 0.4769 - val_cindex_score: 0.7362\n","Epoch 3/100\n","78836/78836 [==============================] - 49s 626us/step - loss: 0.5322 - cindex_score: 0.7066 - val_loss: 0.4253 - val_cindex_score: 0.7449\n","Epoch 4/100\n","78836/78836 [==============================] - 49s 626us/step - loss: 0.5216 - cindex_score: 0.7177 - val_loss: 0.4939 - val_cindex_score: 0.7502\n","Epoch 5/100\n","78836/78836 [==============================] - 49s 625us/step - loss: 0.5034 - cindex_score: 0.7257 - val_loss: 0.5142 - val_cindex_score: 0.7541\n","Epoch 6/100\n","78836/78836 [==============================] - 49s 626us/step - loss: 0.4999 - cindex_score: 0.7284 - val_loss: 0.4837 - val_cindex_score: 0.7510\n","Epoch 7/100\n","78836/78836 [==============================] - 49s 626us/step - loss: 0.4880 - cindex_score: 0.7311 - val_loss: 0.5418 - val_cindex_score: 0.7504\n","Epoch 8/100\n","78836/78836 [==============================] - 49s 624us/step - loss: 0.4817 - cindex_score: 0.7337 - val_loss: 0.5110 - val_cindex_score: 0.7520\n","Epoch 9/100\n","78836/78836 [==============================] - 49s 624us/step - loss: 0.4757 - cindex_score: 0.7363 - val_loss: 0.3910 - val_cindex_score: 0.7532\n","Epoch 10/100\n","78836/78836 [==============================] - 49s 625us/step - loss: 0.4657 - cindex_score: 0.7377 - val_loss: 0.3880 - val_cindex_score: 0.7546\n","Epoch 11/100\n","78836/78836 [==============================] - 49s 623us/step - loss: 0.4501 - cindex_score: 0.7425 - val_loss: 0.4266 - val_cindex_score: 0.7604\n","Epoch 12/100\n","78836/78836 [==============================] - 49s 623us/step - loss: 0.4269 - cindex_score: 0.7477 - val_loss: 0.3837 - val_cindex_score: 0.7676\n","Epoch 13/100\n","78836/78836 [==============================] - 49s 622us/step - loss: 0.4040 - cindex_score: 0.7509 - val_loss: 0.3463 - val_cindex_score: 0.7658\n","Epoch 14/100\n","78836/78836 [==============================] - 49s 623us/step - loss: 0.3951 - cindex_score: 0.7539 - val_loss: 0.3631 - val_cindex_score: 0.7729\n","Epoch 15/100\n","78836/78836 [==============================] - 49s 622us/step - loss: 0.3804 - cindex_score: 0.7596 - val_loss: 0.3502 - val_cindex_score: 0.7782\n","Epoch 16/100\n","78836/78836 [==============================] - 49s 621us/step - loss: 0.3675 - cindex_score: 0.7641 - val_loss: 0.3126 - val_cindex_score: 0.7858\n","Epoch 17/100\n","78836/78836 [==============================] - 49s 621us/step - loss: 0.3605 - cindex_score: 0.7685 - val_loss: 0.3341 - val_cindex_score: 0.7813\n","Epoch 18/100\n","78836/78836 [==============================] - 49s 622us/step - loss: 0.3504 - cindex_score: 0.7726 - val_loss: 0.3026 - val_cindex_score: 0.7894\n","Epoch 19/100\n","78836/78836 [==============================] - 49s 620us/step - loss: 0.3410 - cindex_score: 0.7747 - val_loss: 0.3236 - val_cindex_score: 0.7905\n","Epoch 20/100\n","78836/78836 [==============================] - 49s 620us/step - loss: 0.3387 - cindex_score: 0.7773 - val_loss: 0.3086 - val_cindex_score: 0.7940\n","Epoch 21/100\n","78836/78836 [==============================] - 49s 619us/step - loss: 0.3256 - cindex_score: 0.7818 - val_loss: 0.2937 - val_cindex_score: 0.7982\n","Epoch 22/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.3134 - cindex_score: 0.7844 - val_loss: 0.2935 - val_cindex_score: 0.7965\n","Epoch 23/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.3028 - cindex_score: 0.7867 - val_loss: 0.3129 - val_cindex_score: 0.8003\n","Epoch 24/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2913 - cindex_score: 0.7907 - val_loss: 0.3006 - val_cindex_score: 0.8036\n","Epoch 25/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.2869 - cindex_score: 0.7933 - val_loss: 0.2801 - val_cindex_score: 0.8017\n","Epoch 26/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2798 - cindex_score: 0.7968 - val_loss: 0.2696 - val_cindex_score: 0.8081\n","Epoch 27/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2695 - cindex_score: 0.8007 - val_loss: 0.2997 - val_cindex_score: 0.8105\n","Epoch 28/100\n","78836/78836 [==============================] - 49s 615us/step - loss: 0.2647 - cindex_score: 0.8030 - val_loss: 0.2590 - val_cindex_score: 0.8105\n","Epoch 29/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.2557 - cindex_score: 0.8059 - val_loss: 0.2674 - val_cindex_score: 0.8069\n","Epoch 30/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2434 - cindex_score: 0.8097 - val_loss: 0.2758 - val_cindex_score: 0.8093\n","Epoch 31/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2363 - cindex_score: 0.8141 - val_loss: 0.2610 - val_cindex_score: 0.8162\n","Epoch 32/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2361 - cindex_score: 0.8135 - val_loss: 0.2551 - val_cindex_score: 0.8118\n","Epoch 33/100\n","78836/78836 [==============================] - 49s 615us/step - loss: 0.2215 - cindex_score: 0.8184 - val_loss: 0.2494 - val_cindex_score: 0.8139\n","Epoch 34/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2155 - cindex_score: 0.8216 - val_loss: 0.2492 - val_cindex_score: 0.8194\n","Epoch 35/100\n","78836/78836 [==============================] - 49s 617us/step - loss: 0.2055 - cindex_score: 0.8253 - val_loss: 0.2485 - val_cindex_score: 0.8186\n","Epoch 36/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.2029 - cindex_score: 0.8278 - val_loss: 0.2461 - val_cindex_score: 0.8177\n","Epoch 37/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.2027 - cindex_score: 0.8281 - val_loss: 0.2462 - val_cindex_score: 0.8163\n","Epoch 38/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1924 - cindex_score: 0.8324 - val_loss: 0.2340 - val_cindex_score: 0.8226\n","Epoch 39/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1888 - cindex_score: 0.8354 - val_loss: 0.2311 - val_cindex_score: 0.8249\n","Epoch 40/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.1936 - cindex_score: 0.8367 - val_loss: 0.2379 - val_cindex_score: 0.8276\n","Epoch 41/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.1887 - cindex_score: 0.8391 - val_loss: 0.2468 - val_cindex_score: 0.8263\n","Epoch 42/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1740 - cindex_score: 0.8430 - val_loss: 0.2270 - val_cindex_score: 0.8286\n","Epoch 43/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.1646 - cindex_score: 0.8473 - val_loss: 0.2379 - val_cindex_score: 0.8264\n","Epoch 44/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1591 - cindex_score: 0.8484 - val_loss: 0.2298 - val_cindex_score: 0.8292\n","Epoch 45/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.1521 - cindex_score: 0.8516 - val_loss: 0.2251 - val_cindex_score: 0.8303\n","Epoch 46/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.1464 - cindex_score: 0.8536 - val_loss: 0.2337 - val_cindex_score: 0.8279\n","Epoch 47/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.1401 - cindex_score: 0.8575 - val_loss: 0.2190 - val_cindex_score: 0.8338\n","Epoch 48/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1386 - cindex_score: 0.8591 - val_loss: 0.2310 - val_cindex_score: 0.8314\n","Epoch 49/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1357 - cindex_score: 0.8610 - val_loss: 0.2212 - val_cindex_score: 0.8310\n","Epoch 50/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1535 - cindex_score: 0.8546 - val_loss: 0.2415 - val_cindex_score: 0.8338\n","Epoch 51/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.1340 - cindex_score: 0.8643 - val_loss: 0.2241 - val_cindex_score: 0.8360\n","Epoch 52/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.1246 - cindex_score: 0.8687 - val_loss: 0.2132 - val_cindex_score: 0.8360\n","Epoch 53/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1232 - cindex_score: 0.8711 - val_loss: 0.2352 - val_cindex_score: 0.8352\n","Epoch 54/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.1236 - cindex_score: 0.8727 - val_loss: 0.2385 - val_cindex_score: 0.8359\n","Epoch 55/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.1254 - cindex_score: 0.8743 - val_loss: 0.2143 - val_cindex_score: 0.8375\n","Epoch 56/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1213 - cindex_score: 0.8762 - val_loss: 0.2140 - val_cindex_score: 0.8379\n","Epoch 57/100\n","78836/78836 [==============================] - 49s 615us/step - loss: 0.1202 - cindex_score: 0.8783 - val_loss: 0.2339 - val_cindex_score: 0.8384\n","Epoch 58/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.1066 - cindex_score: 0.8825 - val_loss: 0.2168 - val_cindex_score: 0.8413\n","Epoch 59/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0974 - cindex_score: 0.8865 - val_loss: 0.2073 - val_cindex_score: 0.8414\n","Epoch 60/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1021 - cindex_score: 0.8846 - val_loss: 0.2053 - val_cindex_score: 0.8446\n","Epoch 61/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.1050 - cindex_score: 0.8870 - val_loss: 0.2107 - val_cindex_score: 0.8428\n","Epoch 62/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.1012 - cindex_score: 0.8885 - val_loss: 0.2101 - val_cindex_score: 0.8463\n","Epoch 63/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0924 - cindex_score: 0.8913 - val_loss: 0.2117 - val_cindex_score: 0.8456\n","Epoch 64/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0898 - cindex_score: 0.8933 - val_loss: 0.2032 - val_cindex_score: 0.8484\n","Epoch 65/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0864 - cindex_score: 0.8952 - val_loss: 0.2121 - val_cindex_score: 0.8475\n","Epoch 66/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0897 - cindex_score: 0.8957 - val_loss: 0.2110 - val_cindex_score: 0.8474\n","Epoch 67/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0979 - cindex_score: 0.8948 - val_loss: 0.2229 - val_cindex_score: 0.8471\n","Epoch 68/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0960 - cindex_score: 0.8948 - val_loss: 0.2300 - val_cindex_score: 0.8478\n","Epoch 69/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0880 - cindex_score: 0.8987 - val_loss: 0.2114 - val_cindex_score: 0.8489\n","Epoch 70/100\n","78836/78836 [==============================] - 49s 615us/step - loss: 0.0823 - cindex_score: 0.9012 - val_loss: 0.2098 - val_cindex_score: 0.8481\n","Epoch 71/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0770 - cindex_score: 0.9042 - val_loss: 0.2070 - val_cindex_score: 0.8502\n","Epoch 72/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0748 - cindex_score: 0.9045 - val_loss: 0.2003 - val_cindex_score: 0.8532\n","Epoch 73/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0741 - cindex_score: 0.9068 - val_loss: 0.2038 - val_cindex_score: 0.8538\n","Epoch 74/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0725 - cindex_score: 0.9072 - val_loss: 0.1999 - val_cindex_score: 0.8540\n","Epoch 75/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0785 - cindex_score: 0.9044 - val_loss: 0.2013 - val_cindex_score: 0.8526\n","Epoch 76/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0729 - cindex_score: 0.9076 - val_loss: 0.2040 - val_cindex_score: 0.8528\n","Epoch 77/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0719 - cindex_score: 0.9086 - val_loss: 0.2075 - val_cindex_score: 0.8527\n","Epoch 78/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0717 - cindex_score: 0.9094 - val_loss: 0.2134 - val_cindex_score: 0.8521\n","Epoch 79/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0720 - cindex_score: 0.9089 - val_loss: 0.2039 - val_cindex_score: 0.8541\n","Epoch 80/100\n","78836/78836 [==============================] - 49s 616us/step - loss: 0.0707 - cindex_score: 0.9093 - val_loss: 0.2009 - val_cindex_score: 0.8558\n","Epoch 81/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0697 - cindex_score: 0.9110 - val_loss: 0.2032 - val_cindex_score: 0.8529\n","Epoch 82/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0715 - cindex_score: 0.9116 - val_loss: 0.2060 - val_cindex_score: 0.8558\n","Epoch 83/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0739 - cindex_score: 0.9097 - val_loss: 0.2124 - val_cindex_score: 0.8539\n","Epoch 84/100\n","78836/78836 [==============================] - 48s 615us/step - loss: 0.0693 - cindex_score: 0.9124 - val_loss: 0.2046 - val_cindex_score: 0.8554\n","Epoch 85/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0798 - cindex_score: 0.9070 - val_loss: 0.2073 - val_cindex_score: 0.8515\n","Epoch 86/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0727 - cindex_score: 0.9112 - val_loss: 0.2008 - val_cindex_score: 0.8559\n","Epoch 87/100\n","78836/78836 [==============================] - 48s 614us/step - loss: 0.0715 - cindex_score: 0.9146 - val_loss: 0.2042 - val_cindex_score: 0.8551\n","Epoch 88/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0712 - cindex_score: 0.9147 - val_loss: 0.2181 - val_cindex_score: 0.8561\n","Epoch 89/100\n","78836/78836 [==============================] - 48s 613us/step - loss: 0.0663 - cindex_score: 0.9162 - val_loss: 0.2106 - val_cindex_score: 0.8559\n","Epoch 00089: early stopping\n","run_experiments.py:453: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:466: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n","run_experiments.py:480: MatplotlibDeprecationWarning: \n","The frameon kwarg was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use facecolor instead.\n","  papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n"]}],"source":["!./go.sh"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":453,"status":"ok","timestamp":1650121181329,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"},"user_tz":300},"id":"tvrbMkse4scA","outputId":"1ea8590b-7a1b-40c5-85ec-f6c2c8f967da"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["!rm figures/b0*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xg09XNlZpO8v"},"outputs":[],"source":["def cindex_score(y_true, y_pred):\n","\n","    g = tf.subtract(tf.expand_dims(y_pred, -1), y_pred)\n","    g = tf.cast(g == 0.0, tf.float32) * 0.5 + tf.cast(g > 0.0, tf.float32)\n","\n","    f = tf.subtract(tf.expand_dims(y_true, -1), y_true) > 0.0\n","    f = tf.matrix_band_part(tf.cast(f, tf.float32), -1, 0)\n","\n","    g = tf.reduce_sum(tf.multiply(g, f))\n","    f = tf.reduce_sum(f)\n","\n","    return tf.where(tf.equal(g, 0), 0.0, g/f) #select"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6tWE13p2lBAP"},"outputs":[],"source":["from keras.models import load_model\n","model = load_model('combined_davis.01-0.66.h5', custom_objects={\"cindex_score\": cindex_score})"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":452,"status":"ok","timestamp":1649983021156,"user":{"displayName":"Yasamin Tabatabaee","userId":"07445355406834081164"},"user_tz":300},"id":"it7MuSWlpXIl","outputId":"41d71cd5-0822-4aa6-967d-08c851e421b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_7\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_13 (InputLayer)          [(None, 100)]        0           []                               \n","                                                                                                  \n"," input_14 (InputLayer)          [(None, 1000)]       0           []                               \n","                                                                                                  \n"," embedding_13 (Embedding)       (None, 100, 128)     8320        ['input_13[0][0]']               \n","                                                                                                  \n"," embedding_14 (Embedding)       (None, 1000, 128)    3328        ['input_14[0][0]']               \n","                                                                                                  \n"," conv1d_37 (Conv1D)             (None, 93, 32)       32800       ['embedding_13[0][0]']           \n","                                                                                                  \n"," conv1d_40 (Conv1D)             (None, 989, 32)      49184       ['embedding_14[0][0]']           \n","                                                                                                  \n"," conv1d_38 (Conv1D)             (None, 86, 64)       16448       ['conv1d_37[0][0]']              \n","                                                                                                  \n"," conv1d_41 (Conv1D)             (None, 978, 64)      24640       ['conv1d_40[0][0]']              \n","                                                                                                  \n"," conv1d_39 (Conv1D)             (None, 79, 96)       49248       ['conv1d_38[0][0]']              \n","                                                                                                  \n"," conv1d_42 (Conv1D)             (None, 967, 96)      73824       ['conv1d_41[0][0]']              \n","                                                                                                  \n"," global_max_pooling1d_13 (Globa  (None, 96)          0           ['conv1d_39[0][0]']              \n"," lMaxPooling1D)                                                                                   \n","                                                                                                  \n"," global_max_pooling1d_14 (Globa  (None, 96)          0           ['conv1d_42[0][0]']              \n"," lMaxPooling1D)                                                                                   \n","                                                                                                  \n"," concatenate_7 (Concatenate)    (None, 192)          0           ['global_max_pooling1d_13[0][0]',\n","                                                                  'global_max_pooling1d_14[0][0]']\n","                                                                                                  \n"," dense_25 (Dense)               (None, 1024)         197632      ['concatenate_7[0][0]']          \n","                                                                                                  \n"," dropout_13 (Dropout)           (None, 1024)         0           ['dense_25[0][0]']               \n","                                                                                                  \n"," dense_26 (Dense)               (None, 1024)         1049600     ['dropout_13[0][0]']             \n","                                                                                                  \n"," dropout_14 (Dropout)           (None, 1024)         0           ['dense_26[0][0]']               \n","                                                                                                  \n"," dense_27 (Dense)               (None, 512)          524800      ['dropout_14[0][0]']             \n","                                                                                                  \n"," dense_28 (Dense)               (None, 1)            513         ['dense_27[0][0]']               \n","                                                                                                  \n","==================================================================================================\n","Total params: 2,030,337\n","Trainable params: 2,030,337\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"22ZQKxHMqIvQ"},"outputs":[],"source":["model.predict()"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"DeepDTA.ipynb","provenance":[],"mount_file_id":"1bdWOCz5ATzaIqtqb_FOufh6BVxiSSUzZ","authorship_tag":"ABX9TyPZzyFzs03weZOSBQgUBxkJ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}